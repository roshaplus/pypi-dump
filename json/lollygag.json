{
  "info": {
    "author": "Daniel Kiss",
    "author_email": "littlesnorrboy@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Lollygag\n========\n\nAbout\n-----\n\n-  Travis CI: |Build Status|\n-  Supported Python versions:\n\n   -  Python 2.7\n   -  Python 3.6\n   -  Pypy\n   -  Pypy 3\n\nInstallation\n------------\n\n``pip install lollygag``\n\nUsage\n-----\n\nExample code\n~~~~~~~~~~~~\n\n.. code:: python\n\n    #!/usr/bin/python\n\n    from lollygag import run\n    from lollygag.services import SERVICES\n    from lollygag.crawler.link_crawler import LinkCrawler\n\n    class MyCrawler(LinkCrawler):\n        # This is a custom crawler to handle a single webpage\n        # If you wish to preserve existing functionality when overriding methods,\n        # do not forget to call the super method aswell\n        def feed(self, data):\n            # Override the feed method to customize handling the whole page data\n            self.log_service.info(\"Yeah boi, a page!\")\n            return LinkCrawler.feed(self, data)\n\n        def handle_starttag(self, tag, attrs):\n            # Override HTMLParser methods for custom behaviour\n            # Call the super method to return links on the page\n            # The default DomainCrawler class will continue crawling if crawl() returns a \n            # CrawlResult with links\n            super(MyCrawler, self).handle_starttag(tag, attrs)\n            if(tag == 'img'):\n                self.log_service.info(\"Yeeeeaaaah boiiiiiii, I found an %s\" % (tag))\n            if(tag == 'a'):\n                self.log_service.debug(\"Boi, I found a link!\")\n\n    def main():\n        # Override crawler_factory with my own implementation\n        SERVICES['crawler_factory'] = MyCrawler \n        run()\n\n    if __name__ == '__main__':\n        main()\n\n.. code:: bash\n\n    python crawler_example.py -u snorrwe.github.io/crawler_test\n\n    [Info]Thread=[MainThread]        ----------Crawl starting----------\n    [Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[1]\n    [Info]Thread=[WSc--0]    Yeah boi, a page!\n    [Debug]Thread=[WSc--0]   Boi, I found a link!\n    [Debug]Thread=[WSc--0]   Boi, I found a link!\n    [Info]Thread=[WSc--0]    Yeeeeaaaah boiiiiiii, I found an img\n    [Info]Thread=[WSc--0]    Link=[http://snorrwe.github.io/crawler_test] StatusCode=[200] Size=[310]\n    [Debug]Thread=[WSc--0]\n        Urls visited=[1]\n        Urls in progess=[0]\n        Urls left=[2]\n    [Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[2]\n    [Info]Thread=[WSc--4]    Link=[http://snorrwe.github.io/crawler_test/kanga2.html] StatusCode=[404] Size=[9340]\n    [Debug]Thread=[WSc--4]\n        Urls visited=[2]\n        Urls in progess=[1]\n        Urls left=[0]\n    [Info]Thread=[WSc--2]    Yeah boi, a page!\n    [Debug]Thread=[WSc--2]   Boi, I found a link!\n    [Info]Thread=[WSc--2]    Link=[http://snorrwe.github.io/crawler_test/kanga.html] StatusCode=[200] Size=[220]\n    [Debug]Thread=[WSc--2]\n        Urls visited=[3]\n        Urls in progess=[0]\n        Urls left=[0]\n    [Info]Thread=[MainThread]\n        Urls visited=[3]\n        Urls in progess=[0]\n        Urls left=[0]\n    [Info]Thread=[MainThread]        ----------Crawl finished----------\n\nCommand line arguments\n~~~~~~~~~~~~~~~~~~~~~~\n\n.. raw:: html\n\n   <table>\n       <thead>\n           <tr>\n               <th>\n\nName\n\n.. raw:: html\n\n   </th>\n               <th>\n\nShort\n\n.. raw:: html\n\n   </th>\n               <th>\n\nDescription\n\n.. raw:: html\n\n   </th>\n           </tr>\n       </thead>\n       <tbody>\n           <div>\n               <tr>\n                   <td>\n\n--help\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-h\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nShow the help and exit\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--url\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-u\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nBase url you wish to crawl. Note that if you pass the url argument to\nrun() or crawl() this option will be ignored.\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--threads\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-t\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nMaximum number of concurrent threads\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--loglevel\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-l\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nLevel of logging, possible values = [all, info, debug, warn, error,\nnone]\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n       </tbody>\n   </table>\n\nTesting\n-------\n\nRunning the unit tests\n~~~~~~~~~~~~~~~~~~~~~~\n\nRunning the unit tests with the **pytest** package. To install pytest\nvia pip run ``pip install pytest``.\n\nTo run the tests run ``pytest`` in the root folder.\n\nTest code\n~~~~~~~~~\n\nUnit testing\n^^^^^^^^^^^^\n\nTest files are located next to the files they meant to test. Test files\nhave the same base name, and end with **test\\ * For example: tests for\nfile *\\ some*\\ source.py* are in the file *some\\_source\\_test.py*\n\nEnd-to-end testing\n^^^^^^^^^^^^^^^^^^\n\nTest files are located in the *e2e* directory.\n\nLicense\n-------\n\n`MIT <https://github.com/snorrwe/Crawler/blob/master/LICENSE>`__\n\n.. |Build Status| image:: https://travis-ci.org/snorrwe/lollygag.svg?branch=master\n   :target: https://travis-ci.org/snorrwe/lollygag",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/snorrwe/lollygag",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "lollygag",
    "platform": "",
    "project_url": "https://pypi.org/project/lollygag/",
    "release_url": "https://pypi.org/project/lollygag/0.0.4/",
    "requires_dist": [],
    "requires_python": ">=2.7, >=3.4",
    "summary": "A simple web crawling module",
    "version": "0.0.4"
  },
  "releases": {
    "0.0.4": [
      {
        "comment_text": "",
        "digests": {
          "md5": "85181063b2b80066a50dcfa429b3e512",
          "sha256": "a0b640bea82d6e67b6e75599d58d33a673dfe72e7808e1789d1421aa140a1e32"
        },
        "downloads": 0,
        "filename": "lollygag-0.0.4.tar.gz",
        "has_sig": false,
        "md5_digest": "85181063b2b80066a50dcfa429b3e512",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 10833,
        "upload_time": "2017-08-29T17:13:12",
        "url": "https://files.pythonhosted.org/packages/87/e3/6c8348e913d78395af7856c0ccf4bb3183991a86fe5c9b2fef47afa83a10/lollygag-0.0.4.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "85181063b2b80066a50dcfa429b3e512",
        "sha256": "a0b640bea82d6e67b6e75599d58d33a673dfe72e7808e1789d1421aa140a1e32"
      },
      "downloads": 0,
      "filename": "lollygag-0.0.4.tar.gz",
      "has_sig": false,
      "md5_digest": "85181063b2b80066a50dcfa429b3e512",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 10833,
      "upload_time": "2017-08-29T17:13:12",
      "url": "https://files.pythonhosted.org/packages/87/e3/6c8348e913d78395af7856c0ccf4bb3183991a86fe5c9b2fef47afa83a10/lollygag-0.0.4.tar.gz"
    }
  ]
}