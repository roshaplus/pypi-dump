{
  "info": {
    "author": "H2O.ai",
    "author_email": "support@h2o.ai",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.2",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Topic :: Software Development :: Build Tools"
    ],
    "description": "PySparkling and Spark Version\n=============================\nThere are multiple PySparkling packages, each is intended to be used with different Spark version.\n\n - h2o_pysparkling_2.2 - for Spark 2.2.x\n - h2o_pysparkling_2.1 - for Spark 2.1.x\n - h2o_pysparkling_2.0 - for Spark 2.0.x\n - h2o_pysparkling_1.6 - for Spark 1.6.x  (Only critical fixes)\n\nSo for example, to install PySparkling for Spark 2.2, the command would look like:\n\n.. code-block:: bash\n\n    pip install h2o_pysparkling_2.2\n\nSetup and Installation\n======================\n\nPrerequisites:\n    \n  - Python 2.7 or 3+\n  - Numpy 1.9.2\n\nFor windows users, please grab a .whl from http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy\n\nIn order to use PySparkling, it requires the following runtime python dependencies to be available on the system: *requests*, *tabulate*, *six* and *future* modules, all of which are available on PyPI:\n\n.. code-block:: bash\n\n  $ pip install requests\n  $ pip install tabulate\n  $ pip install six\n  $ pip install future\n  \nThe required packages are installed automatically in case when PySparkling is installed from PyPI.\n\n\nBuilding PySparkling with Non-Default Spark Version\n===================================================\n\nPySparkling is built for Spark built with default Scala version for that Spark. If you would like to use PySparkling\nwith Spark built with non-default Scala version, you have to build PySparkling manually.\n\nThe default Scala versions for supported Spark versions are:\n\n- Spark 2.2.x - Scala 2.11\n- Spark 2.1.x - Scala 2.11\n- Spark 2.0.1 - Scala 2.11\n- Spark 1.6.x - Scala 2.10\n\nTo build PySparkling for Spark with specific Scala version:\n\n1. Clone Sparkling Water Repo\n\n.. code-block:: bash\n\n    git clone http://github.com/h2oai/sparkling-water\n    cd sparkling-water\n\n2. Point ``$SPARK_HOME`` environmental variable to Spark you want to build PySparkling for.\n3. Build PySparkling with the Scala version your Spark is built with. The supported Scala versions are 2.11 and 2.10. To build it, for example, with Scala 2.11, use:\n\n.. code-block:: bash\n\n    ./gradlew build -x check -PscalaBaseVersion=2.11\n\n4. The final PySparkling zip file is located in the ``py/build/dist`` directory of the Sparkling Water project.\n\nThe Sparkling-Water Python Module\n=================================\n\nPrepare the environment\n-----------------------\n1. Either clone and build Sparkling Water project\n\n.. code-block:: bash\n\n    git clone http://github.com/h2oai/sparkling-water\n    cd sparkling-water\n    ./gradlew build -x check\n\n\nor download and unpack sparkling water release from  `here\n<http://www.h2o.ai/download/sparkling-water/choose>`_.\n\n2. Configure the location of Spark distribution and cluster:\n\n.. code-block:: bash\n\n    export SPARK_HOME=\"/path/to/spark/installation\"\n    export MASTER='local[*]'\n\n\nRun PySparkling interactive shell\n---------------------------------\n\n1. Ensure you are in the Sparkling Water project directory and run PySparkling shell:\n\n.. code-block:: bash\n\n    bin/pysparkling\n\n\nThe *pysparkling* shell accepts common *pyspark* arguments.\n\n\nFor running on YARN and other supported platforms please see `Running Sparkling Water on supported platforms\n<https://github.com/h2oai/sparkling-water/blob/master/DEVEL.md#TargetPlatforms>`_.\n\n\n2. Initialize H2OContext\n\n.. code:: python\n\n      from pysparkling import *\n      import h2o\n      hc = H2OContext.getOrCreate(spark)\n\n\nRun IPython Notebook with PySparkling\n-------------------------------------\n.. code-block:: bash\n\n    PYSPARK_DRIVER_PYTHON=\"ipython\" PYSPARK_DRIVER_PYTHON_OPTS=\"notebook\" bin/pysparkling\n\nFor running on Windows, the syntax would be: \n\n.. code-block:: bash\n\n    SET PYSPARK_DRIVER_PYTHON=ipython \n    SET PYSPARK_DRIVER_PYTHON_OPTS=notebook \n    bin/pysparkling\n\n\nRun IPython with PySparkling\n----------------------------\n.. code-block:: bash\n\n    PYSPARK_DRIVER_PYTHON=\"ipython\" bin/pysparkling\n\nUse PySparkling in Databricks Cloud\n-----------------------------------\nIn order to use PySparkling in Databricks cloud, PySparkling module has to be added as a library to current cluster.  PySparkling can be added as library in two ways. You can either upload the PySparkling source zip file or add the PySparkling module from PyPI.\nIf you choose to upload PySparkling zip file, don't forget to add libraries for following python modules:\nrequest, tabulate and future. The PySparkling zip file is available in *py/dist* directory in both built Sparkling Water project and downloaded Sparkling Water release.\n\n\t\nAn Introduction to PySparkling\n==============================\n\nWhat is H2O?\n------------\n\nH2O is an open-source, in-memory, distributed, fast and scalable machine learning and predictive analytics platform that provides capability to build machine learning models on big data and allow easy productionalization of them in an enterprise environment. \n\nH2O core code is in Java. Inside H2O, a Distributed Key/Value (DKV) store is used to access and reference data, models, objects, etc., across all nodes/machines, has a non blocking hashmap and a memory manager. The algoritms are implemented in a map reduce style and utilize the Java Fork/Join framework.\nThe data is read in parallel and is distributed across the cluster, stored in memory in a columnar format in a compressed way. H2O's data parser has built-in intelligence to guess the schema of the incoming dataset and supports data ingest from multiple sources in various formats.\n\nH2O's REST API allows access to all the capabilities of H2O from an external program or script, via JSON over HTTP. The REST API is used by H2O's web interface (Flow UI), the R binding (H2O-R) and the Python binding (H2O-Python).\n\nThe speed, quality and ease of use and model-deployment, for the various cutting-edge supervised and unsupervised algorithms like Deep Learning, Tree Ensembles and Generalized Low Rank Models, makes H2O a highly sought after API for big data analytics.\n\nWhat is Spark?\n--------------\n\nSpark is an open-source, in-memory, distributed cluster computing framework that provides a comprehensive capability of building efficient big data pipelines.\n\nSpark core implements a distributed memory abstraction, called Resilient Distributed Datasets (RDDs) and manages distributed task dispatching and scheduling. An RDD is a logical collection of data. The actual data sits on disk. RDDs can be cashed for interactive data analysis. Operations on an RDD are lazy and are only executed when a user calls an action on an RDD. \n\nSpark provides APIs in Java, Python, Scala, and R for building and manipulating RDDs. It also supports SQL queries, streaming data, MLlib and graph data processing.\n\nThe fast and unified framework to manage data processing, makes Spark a preferred solution for big data analysis.\n\nWhat is Sparkling Water?\n------------------------\n\nSparkling Water is an integration of H2O into the Spark ecosystem. It facilitates the use of H2O algorithms in Spark workflows. It is designed as a regular Spark application and provides a way to start H2O services on each node of a Spark cluster and access data stored in data structures of Spark and H2O.\n\nA Spark cluster is composed of one Driver JVM and one or many Executor JVMs. A Spark Context is a connection to a Spark cluster. Each Spark application creates a `SparkContext`. The machine where the Spark application process, that creates a `SparkContext` (sc), is running, is the Driver node. The Spark Context connects to the cluster manager (either Spark standalone cluster manager, Mesos or YARN), that allocates executors to spark cluster for the application. Then, Spark sends the application code (defined by JAR or Python files) to the executors. Finally, the Spark Context sends tasks to the executors to run.\n\nThe driver program in Sparkling Water, creates a `SparkContext` (sc) which in turn is used to create an `H2OContext` (hc) that is used to start H2O services on the spark executors. An H2O Context is a connection to H2O cluster and  also facilitates communication between H2O and Spark. When an H2O cluster starts, it has the same topology as the Spark cluster and H2O nodes shares the same JVMs as the Spark Executors.\n\nTo leverage H2O's algorithms, data in Spark cluster, stored as an RDD, needs to be converted to an H2OFrame (H2O's distributed data frame). This requires a data copy because of the difference in data layout in Spark (blocks/rows) and H2O (columns). But as data is stored in H2O in a highly compressed format, the overhead of making a data copy is low. When converting an H2OFrame to RDD, Sparkling Water creates a wrapper around the H2OFrame to provide an RDD-like API. In this case, no data is duplicated and data is served directly from the underlying H2OFrame. As H2O runs in the same JVMs as the Spark Executors, moving data from Spark to H2O or vice-versa requires a simple in memory, in process call.\n\n\nWhat is PySparkling?\n--------------------\n\nPySparkling is an integration of Python with Sparkling Water. It allows user to start H2O services on a Spark cluster from Python API.\n\t\nIn the PySparkling driver program, the Spark Context, which uses Py4J to start the driver JVM and the Java Spark Context, is used to create the H2O Context (hc).  That in turn starts an H2O cloud (cluster) in the Spark ecosystem. Once the H2O cluster is up, the H2O Python package is used to interact with it and run H2O algorithms. All pure H2O calls are executed via H2O's REST API interface. Users can easily integrate their regular PySpark workflow with H2O algorithms using PySparkling.\n\t\nPySparkling programs can be launched as an application or in an interactive shell or notebook environment. \n\t\n",
    "docs_url": null,
    "download_url": "https://github.com/h2oai/sparkling-water/",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/h2oai/sparkling-water",
    "keywords": "machine learning",
    "license": "Apache v2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "h2o_pysparkling_2.2",
    "platform": "",
    "project_url": "https://pypi.org/project/h2o_pysparkling_2.2/",
    "release_url": "https://pypi.org/project/h2o_pysparkling_2.2/2.2.2/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Sparkling Water integrates H2O's Fast Scalable Machine Learning with Spark",
    "version": "2.2.2"
  },
  "releases": {
    "2.2.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "a768f03a1b6fc7fb9e3d5182f90eaa46",
          "sha256": "6ff3d3a128b52b691115545d6bb3e39d29abfc3f8c87199021709ee73294a533"
        },
        "downloads": -1,
        "filename": "h2o_pysparkling_2.2-2.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "a768f03a1b6fc7fb9e3d5182f90eaa46",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 38605447,
        "upload_time": "2017-08-25T16:43:27",
        "url": "https://files.pythonhosted.org/packages/9a/53/d2f2baaacd4aeaefcdd15e8c8b16b30c407cb7495ed4cef99782c060dea9/h2o_pysparkling_2.2-2.2.0.tar.gz"
      }
    ],
    "2.2.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b29af0003a71cca79cdd7172d9ccefc3",
          "sha256": "8796af4a3fc6cd061728574dd12cb6ee220db6a346c1d9b548810708b1cdfa37"
        },
        "downloads": -1,
        "filename": "h2o_pysparkling_2.2-2.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b29af0003a71cca79cdd7172d9ccefc3",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 39628576,
        "upload_time": "2017-10-10T14:13:32",
        "url": "https://files.pythonhosted.org/packages/2d/61/b63cd7c039f671b311054399e52d1dae1ea888264f5a2bbc4c786e7a54f4/h2o_pysparkling_2.2-2.2.1.tar.gz"
      }
    ],
    "2.2.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "e184d14171771011762e5fab50763fab",
          "sha256": "98d57281a7298db2aae732e099c7202ce566691edfe94061e071d9e94ae51a74"
        },
        "downloads": -1,
        "filename": "h2o_pysparkling_2.2-2.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "e184d14171771011762e5fab50763fab",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 39684171,
        "upload_time": "2017-10-23T15:51:07",
        "url": "https://files.pythonhosted.org/packages/87/01/6fd3e0043014f44a5b822063014fdf7bdde6d3a08df81cce4c66634de27a/h2o_pysparkling_2.2-2.2.2.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "e184d14171771011762e5fab50763fab",
        "sha256": "98d57281a7298db2aae732e099c7202ce566691edfe94061e071d9e94ae51a74"
      },
      "downloads": -1,
      "filename": "h2o_pysparkling_2.2-2.2.2.tar.gz",
      "has_sig": false,
      "md5_digest": "e184d14171771011762e5fab50763fab",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 39684171,
      "upload_time": "2017-10-23T15:51:07",
      "url": "https://files.pythonhosted.org/packages/87/01/6fd3e0043014f44a5b822063014fdf7bdde6d3a08df81cce4c66634de27a/h2o_pysparkling_2.2-2.2.2.tar.gz"
    }
  ]
}