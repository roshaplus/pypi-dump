{
  "info": {
    "author": "",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "==========\nscrapy_rss\n==========\n\n.. image:: https://img.shields.io/pypi/v/scrapy_rss.svg\n   :target: https://pypi.python.org/pypi/scrapy_rss\n   :alt: PyPI Version\n\n.. image:: https://img.shields.io/travis/woxcab/scrapy_rss/master.svg\n   :target: http://travis-ci.org/woxcab/scrapy_rss\n   :alt: Build Status\n\n.. image:: https://img.shields.io/badge/wheel-yes-brightgreen.svg\n   :target: https://pypi.python.org/pypi/scrapy_rss\n   :alt: Wheel Status\n\n.. image:: https://img.shields.io/codecov/c/github/woxcab/scrapy_rss/master.svg\n   :target: http://codecov.io/github/woxcab/scrapy_rss?branch=master\n   :alt: Coverage report\n\nTools for easy RSS feed generating that contains each scraped item using `Scrapy framework <https://github.com/scrapy/scrapy>`_.\n\nPackage works with Python 2.7, 3.3, 3.4, 3.5 and 3.6.\n\n\n`Installation <https://packaging.python.org/installing/>`_\n==========================================================\n* Install :code:`scrapy_rss` using pip\n\n  .. code:: bash\n\n       pip install scrapy_rss\n\n  or using pip for specific interpreter, e.g.:\n\n  .. code:: bash\n\n      pip3 install scrapy_rss\n\n* or using directly setuptools:\n\n  .. code:: bash\n\n      cd path/to/root/of/scrapy_rss\n      python setup.py install\n\n  or using setuptools for specific interpreter, e.g.:\n\n  .. code:: bash\n\n      cd path/to/root/of/scrapy_rss\n      python3 setup.py install\n\n\nHow To Use\n==========\n\nAdd parameters to the Scrapy project settings (settings.py file)\nor to the :code:`custom_settings` attribute of the spider:\n\n1. Add item pipeline that export items to rss feed:\n\n   .. code:: python\n\n     ITEM_PIPELINES = {\n         # ...\n         'scrapy_rss.pipelines.RssExportPipeline': 900,  # or another priority\n         # ...\n     }\n\n\n2. Add required feed parameters:\n\n   FEED_FILE\n       absolute or relative file path where the result RSS feed will be saved.\n       For example, :code:`feed.rss` or :code:`output/feed.rss`.\n   FEED_TITLE\n       the name of the channel (feed),\n   FEED_DESCRIPTION\n       phrase or sentence describing the channel (feed),\n   FEED_LINK\n       the URL to the HTML website corresponding to the channel (feed)\n\n   .. code:: python\n\n     FEED_FILE = 'path/to/feed.rss'\n     FEED_TITLE = 'Some title of the channel'\n     FEED_LINK = 'http://example.com/rss'\n     FEED_DESCRIPTION = 'About channel'\n\n\nDeclare your item directly as RssItem():\n\n.. code:: python\n\n  import scrapy_rss\n\n  item1 = scrapy_rss.RssItem()\n\nOr use predefined item class :code:`RssedItem` with RSS field named as :code:`rss`\nthat's instance of :code:`RssItem`:\n\n.. code:: python\n\n  import scrapy_rss\n\n  class MyItem(scrapy_rss.RssedItem):\n      # scrapy.Field() and/or another fields definitions\n      # ...\n      field1 = scrapy.Field()\n      field2 = scrapy.Field()\n\n  item2 = MyItem()\n\n\nSet/get item fields. Case sensitive attributes of :code:`RssItem()` are appropriate to RSS elements,\nAttributes of RSS elements are case sensitive too.\nIf editor is allowed autocompletion then it suggests attributes for instances of :code:`RssItem`.\nIt's allowed to set **any** subset of RSS elements (e.g. only title). For example:\n\n.. code:: python\n\n  from datetime import datetime\n\n  item1.title = 'RSS item title'  # set value of <title> element\n  title = item1.title.title  # get value of <title> element\n  item1.description = 'description'\n\n  item1.guid = 'item identifier'\n  item1.guid.isPermaLink = True  # set value of attribute isPermalink of <guid> element,\n                                 # isPermaLink is False by default\n  is_permalink = item1.guid.isPermaLink  # get value of attribute isPermalink of <guid> element\n  guid = item1.guid.guid  # get value of element <guid>\n\n  item1.category = 'single category'\n  category = item1.category\n  item1.category = ['first category', 'second category']\n  first_category = item1.category[0].category # get value of the element <category> with multiple values\n  all_categories = [cat.category for cat in item1.category]\n\n  # direct attributes setting\n  item1.enclosure.url = 'http://example.com/file'\n  item1.enclosure.length = 0\n  item1.enclosure.type = 'text/plain'\n\n  # or dict based attributes setting\n  item1.enclosure = {'url': 'http://example.com/file', 'length': 0, 'type': 'text/plain'}\n  item1.guid = {'guid': 'item identifier', 'isPermaLink': True}\n\n  item1.pubDate = datetime.now()  # correctly works with Python' datetimes\n\n\n  item2.rss.title = 'Item title'\n  item2.rss.guid = 'identifier'\n  item2.rss.enclosure = {'url': 'http://example.com/file', 'length': 0, 'type': 'text/plain'}\n\n\nAll allowed elements are listed in the `scrapy_rss/items.py <https://github.com/woxcab/scrapy_rss/blob/master/scrapy_rss/items.py>`_.\nAll allowed attributes of each element with constraints and default values\nare listed in the `scrapy_rss/elements.py <https://github.com/woxcab/scrapy_rss/blob/master/scrapy_rss/elements.py>`_.\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/woxcab/scrapy_rss",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-rss",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-rss/",
    "release_url": "https://pypi.org/project/scrapy-rss/0.1.3/",
    "requires_python": "",
    "summary": "RSS Tools for Scrapy Framework",
    "version": "0.1.3"
  },
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0b90d9344898dcad48fca61785d31e06",
          "sha256": "75dec407fd68a6cc472522e17d3a5e4498b8b0b0041778ff2fc52fe4fe34d3a3"
        },
        "downloads": 6,
        "filename": "scrapy_rss-0.1.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0b90d9344898dcad48fca61785d31e06",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 12671,
        "upload_time": "2017-02-02T08:18:30",
        "url": "https://files.pythonhosted.org/packages/65/e2/f89d780ab496c95ded1edcccec5561d78ff1d54eeeffba17bbae6a4e5e7f/scrapy_rss-0.1.0-py2.py3-none-any.whl"
      }
    ],
    "0.1.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "90d01588be0fcbfa6a94c0cae7e86b90",
          "sha256": "9fa39f687481ed74f141f493ca371a3d28f9531df652746dace3cba7b8c7ae5f"
        },
        "downloads": 8,
        "filename": "scrapy_rss-0.1.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "90d01588be0fcbfa6a94c0cae7e86b90",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 12851,
        "upload_time": "2017-02-02T10:16:45",
        "url": "https://files.pythonhosted.org/packages/45/66/0d9898555b12030992e82c543031c3239f8bca88105558c6322587eec1b2/scrapy_rss-0.1.1-py2.py3-none-any.whl"
      }
    ],
    "0.1.2": [],
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b41cf6e7c0c30ad8f7eade64f67cb6ea",
          "sha256": "79d8d44696d813f653b62ba8634af0036a0a723404570e9406dfe63b902c8869"
        },
        "downloads": 0,
        "filename": "scrapy_rss-0.1.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "b41cf6e7c0c30ad8f7eade64f67cb6ea",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 13093,
        "upload_time": "2017-06-19T19:30:46",
        "url": "https://files.pythonhosted.org/packages/e3/5c/62007ae82d01a47b118cc1fb663ef0003d7be694d44e907ec4219624f01e/scrapy_rss-0.1.3-py2.py3-none-any.whl"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "b41cf6e7c0c30ad8f7eade64f67cb6ea",
        "sha256": "79d8d44696d813f653b62ba8634af0036a0a723404570e9406dfe63b902c8869"
      },
      "downloads": 0,
      "filename": "scrapy_rss-0.1.3-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "b41cf6e7c0c30ad8f7eade64f67cb6ea",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 13093,
      "upload_time": "2017-06-19T19:30:46",
      "url": "https://files.pythonhosted.org/packages/e3/5c/62007ae82d01a47b118cc1fb663ef0003d7be694d44e907ec4219624f01e/scrapy_rss-0.1.3-py2.py3-none-any.whl"
    }
  ]
}