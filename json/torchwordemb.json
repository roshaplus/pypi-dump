{
  "info": {
    "author": "WenLiZhuang",
    "author_email": "wlzhuang@nlg.csie.ntu.edu.tw",
    "bugtrack_url": "",
    "classifiers": [
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 3",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "pytorch-wordemb\r\n===============\r\n\r\nLoad pretrained word embeddings (word2vec, glove format) into\r\ntorch.FloatTensor for PyTorch\r\n\r\nInstall\r\n-------\r\n\r\nPyTorch required.\r\n\r\n::\r\n\r\n    pip install torchwordemb\r\n\r\nUsage\r\n-----\r\n\r\n.. code:: python\r\n\r\n    import torchwordemb\r\n\r\ntorchwordemb.load\\_word2vec\\_bin(path)\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nread word2vec binary-format model from ``path``.\r\n\r\nreturns ``(vocab, vec)``\r\n\r\n-  ``vocab`` is a ``dict`` mapping a word to its index.\r\n-  ``vec`` is a ``torch.FloatTensor`` of size ``V x D``, where ``V`` is\r\n   the vocabulary size and ``D`` is the dimension of word2vec.\r\n\r\n.. code:: python\r\n\r\n    vocab, vec = torchwordemb.load_word2vec_bin(\"/path/to/word2vec/model.bin\")\r\n    print(vec.size())\r\n    print(vec[ w2v.vocab[\"apple\"] ] )\r\n\r\ntorchwordemb.load\\_word2vec\\_text(path)\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nread word2vec text-format model from ``path``.\r\n\r\ntorchwordemb.load\\_glove\\_text(path)\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nread GloVe text-format model from ``path``.",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/iamalbert/pytorch-wordemb",
    "keywords": "pytorch torch wordvectors nlp",
    "license": "GPL",
    "maintainer": "",
    "maintainer_email": "",
    "name": "torchwordemb",
    "platform": "",
    "project_url": "https://pypi.org/project/torchwordemb/",
    "release_url": "https://pypi.org/project/torchwordemb/0.0.7/",
    "requires_python": "",
    "summary": "Load pretrained word embeddings (word2vec, glove format) into torch.FloatTensor for PyTorch",
    "version": "0.0.7"
  },
  "releases": {
    "0.0.7": [
      {
        "comment_text": "",
        "digests": {
          "md5": "6f5e64725ce028809b65aca1173e3af2",
          "sha256": "4171baed14b7953eb9370b62bf4cdb908056681d09713067976411b298ac26d1"
        },
        "downloads": 0,
        "filename": "torchwordemb-0.0.7.tar.gz",
        "has_sig": false,
        "md5_digest": "6f5e64725ce028809b65aca1173e3af2",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 3744,
        "upload_time": "2017-04-22T15:36:11",
        "url": "https://files.pythonhosted.org/packages/95/c1/32ecdedf11c66363cd0c22e7e4152f8f007e55a230b01246635e40613d6c/torchwordemb-0.0.7.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "6f5e64725ce028809b65aca1173e3af2",
        "sha256": "4171baed14b7953eb9370b62bf4cdb908056681d09713067976411b298ac26d1"
      },
      "downloads": 0,
      "filename": "torchwordemb-0.0.7.tar.gz",
      "has_sig": false,
      "md5_digest": "6f5e64725ce028809b65aca1173e3af2",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 3744,
      "upload_time": "2017-04-22T15:36:11",
      "url": "https://files.pythonhosted.org/packages/95/c1/32ecdedf11c66363cd0c22e7e4152f8f007e55a230b01246635e40613d6c/torchwordemb-0.0.7.tar.gz"
    }
  ]
}