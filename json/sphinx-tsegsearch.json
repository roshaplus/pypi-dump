{
  "info": {
    "author": "Yasushi Masuda",
    "author_email": "whosaysni@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Environment :: Plugins",
      "Framework :: Sphinx :: Extension",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Topic :: Documentation :: Sphinx"
    ],
    "description": "sphinx-tsegsearch\n===================\n\nA Sphinx extension for tokenize japanese query word with TinySegmenter.js\n\nThis extension tweaks searchtools.js of sphinx-generated html document\nto tokenize Japanese composite words.\n\nSince Japanese is an agglutinative language, query word for document search\nusually becomes composite form like '\u30b7\u30b9\u30c6\u30e0\u6a19\u6e96' (system standard).\nThis makes difficult to search pages containing phrase such as\n'\u30b7\u30b9\u30c6\u30e0\u306e\u6a19\u6e96', '\u6a19\u6e96\u30b7\u30b9\u30c6\u30e0', because TinySegmenter.py (Sphinx's default\nJapanese index tokenizer) tokenizes '\u30b7\u30b9\u30c6\u30e0' and '\u6a19\u6e96' as indexes.\n\nsphinx-tsegsearch patches searchtools.js to override query tokinization\nstep so that query input is re-tokenized by TinySegmenter.js (original\nJavaScript implementation of TinySegmenter).\nAs a result, roughly say, this tiny hack improves recall of Japanese\ndocument search in exchange of precision.\n\nUsage:\n\n#. Add 'sphinx_tsegsearch' in conf.extensions\n#. Rebuild document.",
    "docs_url": null,
    "download_url": "UNKNOWN",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/whosaysni/sphinx-tsegsearch",
    "keywords": "sphinx,japanese,word segmentation,search",
    "license": "MIT",
    "maintainer": null,
    "maintainer_email": null,
    "name": "sphinx-tsegsearch",
    "platform": "any",
    "project_url": "https://pypi.org/project/sphinx-tsegsearch/",
    "release_url": "https://pypi.org/project/sphinx-tsegsearch/1.0/",
    "requires_python": null,
    "summary": "Sphinx extension to split searchword with TinySegmenter",
    "version": "1.0"
  },
  "releases": {
    "1.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "5c741ac28cbad823eb2797d55841515d",
          "sha256": "cae632b6e20356da0d8bbeaa4fbd526357df44f70f239da947ef70e3be8aa379"
        },
        "downloads": 17,
        "filename": "sphinx-tsegsearch-1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "5c741ac28cbad823eb2797d55841515d",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 10832,
        "upload_time": "2017-03-26T11:39:06",
        "url": "https://files.pythonhosted.org/packages/ea/c1/a7e9b57d255aa331c7855cbd4e3b60e4c45f224d36b84855ab0c6abb0eb3/sphinx-tsegsearch-1.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "5c741ac28cbad823eb2797d55841515d",
        "sha256": "cae632b6e20356da0d8bbeaa4fbd526357df44f70f239da947ef70e3be8aa379"
      },
      "downloads": 17,
      "filename": "sphinx-tsegsearch-1.0.tar.gz",
      "has_sig": false,
      "md5_digest": "5c741ac28cbad823eb2797d55841515d",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 10832,
      "upload_time": "2017-03-26T11:39:06",
      "url": "https://files.pythonhosted.org/packages/ea/c1/a7e9b57d255aa331c7855cbd4e3b60e4c45f224d36b84855ab0c6abb0eb3/sphinx-tsegsearch-1.0.tar.gz"
    }
  ]
}