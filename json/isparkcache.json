{
  "info": {
    "author": "Bataev Evgeny",
    "author_email": "bataev.evgeny@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Defines a **%%sparkcache** cell magic in the IPython notebook to cache\nDataFrame and outputs of long-lasting computations in a persistent\nParquet file in Hadoop. Useful when some computations in a notebook are\nlong and you want to easily save the results in a file.\n\n\nBased on `ipycache <https://github.com/rossant/ipycache>`__ module.\n\nInstallation\n------------\n\n-  ``pip install isparkcache``\n\nUsage\n-----\n\n-  In IPython/Jupyter:\n\n    .. code:: python\n\n        %load_ext isparkcache\n\n-  Then, create a cell with:\n\n    .. code:: python\n\n        %%sparkcache df1 df2\n\n        df = ...\n        df1 = sql.createDataFrame(df)\n        df2 = sql.createDataFrame(df)\n\n-  When you execute this cell the first time, the code is executed, and\n   the dataframes ``df1`` and ``df2`` are saved in\n   ``/user/$USER/sparkcache/mysparkapplication/df1`` and\n   ``/user/$USER/sparkcache/mysparkapplication/df2``. When you execute\n   this cell again, the code is skipped, the dataframes are loaded from\n   the Parquet and injected into the namespace, and the outputs are\n   restored in the notebook.\n\n-  Use the ``--force`` or ``-f`` option to force the cell's execution\n   and overwrite the file.\n\n-  Use the ``--read`` or ``-r`` option to prevent the cell's execution\n   and always load the variables from the cache. An exception is raised\n   if the file does not exist.\n\n-  Use the ``--cachedir`` or ``-d`` option to specify the cache\n   directory. Default directory: ``/user/$USER/sparkcache``. You can\n   specify a default directory in the IPython configuration file in your\n   profile (typically in\n   ``~\\.ipython\\profile_default\\ipython_config.py``) by adding the\n   following line:\n\n        c.SparkCacheMagics.cachedir = \"/path/to/mycache\"\n\nIf both a default cache directory and the ``--cachedir`` option are\ngiven, the latter is used.",
    "docs_url": null,
    "download_url": "https://github.com/bataeves/isparkcache/archive/0.1.11.tar.gz",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/bataeves/isparkcache",
    "keywords": "spark,jupyter,ipython",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "isparkcache",
    "platform": "",
    "project_url": "https://pypi.org/project/isparkcache/",
    "release_url": "https://pypi.org/project/isparkcache/0.1.11/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Cache Spark Dataframes for Jupyter",
    "version": "0.1.11"
  },
  "releases": {
    "0.1.10": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0c4784f840890f795fdb51417f338674",
          "sha256": "1ec20779f2d43353c85647a8fe417b28e9e3ac67ed5ab824a3d6fd2e4dbbdc84"
        },
        "downloads": 0,
        "filename": "isparkcache-0.1.10.tar.gz",
        "has_sig": false,
        "md5_digest": "0c4784f840890f795fdb51417f338674",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 18196,
        "upload_time": "2017-07-20T10:25:33",
        "url": "https://files.pythonhosted.org/packages/be/6c/e91e3aa335e0e61a4b157e2107d352b9c716dae97f0d89f0c10901051751/isparkcache-0.1.10.tar.gz"
      }
    ],
    "0.1.11": [
      {
        "comment_text": "",
        "digests": {
          "md5": "abd9cef6b0636c534a3273f5b39e0d12",
          "sha256": "667a59a7d9557f248103b3bc0a75c5f392ddb5bf7bb13bc73fd8c3065f6b4fe4"
        },
        "downloads": 0,
        "filename": "isparkcache-0.1.11.tar.gz",
        "has_sig": false,
        "md5_digest": "abd9cef6b0636c534a3273f5b39e0d12",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 18195,
        "upload_time": "2017-07-20T10:29:11",
        "url": "https://files.pythonhosted.org/packages/43/ae/3879d103b08798c74cbecd3fe5fbd6d5686a5254b49a835e8acb13907cef/isparkcache-0.1.11.tar.gz"
      }
    ],
    "0.1.8": [
      {
        "comment_text": "",
        "digests": {
          "md5": "04b7b4c7ac743d1d77021f771e7186ca",
          "sha256": "df8de9e28bfdbc76606a7fb2f185fe61141563dee49f65b12f83788f4d15324d"
        },
        "downloads": 0,
        "filename": "isparkcache-0.1.8.tar.gz",
        "has_sig": false,
        "md5_digest": "04b7b4c7ac743d1d77021f771e7186ca",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 5590,
        "upload_time": "2017-07-20T10:16:39",
        "url": "https://files.pythonhosted.org/packages/41/7d/e22beca59928b414902d5420818731df6cddf57cf5325de08cd81e4ebd85/isparkcache-0.1.8.tar.gz"
      }
    ],
    "0.1.9": [
      {
        "comment_text": "",
        "digests": {
          "md5": "979be75da74ed7ca6936c683481e3506",
          "sha256": "c84ce59e01b6021c2ab66830211a6f901c19843cd60903525345ac20f42a12c7"
        },
        "downloads": 0,
        "filename": "isparkcache-0.1.9.tar.gz",
        "has_sig": false,
        "md5_digest": "979be75da74ed7ca6936c683481e3506",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 18197,
        "upload_time": "2017-07-20T10:20:34",
        "url": "https://files.pythonhosted.org/packages/6e/cc/245f0153bb577eb7e3f5e1445831e238af9d2486a069f7b9c99bc9ae1f1b/isparkcache-0.1.9.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "abd9cef6b0636c534a3273f5b39e0d12",
        "sha256": "667a59a7d9557f248103b3bc0a75c5f392ddb5bf7bb13bc73fd8c3065f6b4fe4"
      },
      "downloads": 0,
      "filename": "isparkcache-0.1.11.tar.gz",
      "has_sig": false,
      "md5_digest": "abd9cef6b0636c534a3273f5b39e0d12",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 18195,
      "upload_time": "2017-07-20T10:29:11",
      "url": "https://files.pythonhosted.org/packages/43/ae/3879d103b08798c74cbecd3fe5fbd6d5686a5254b49a835e8acb13907cef/isparkcache-0.1.11.tar.gz"
    }
  ]
}