{
  "info": {
    "author": "Preston Parry",
    "author_email": "ClimbsBytes@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "Intended Audience :: Information Technology",
      "Intended Audience :: Science/Research",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "# auto_ml\n> Automated machine learning for production and analytics\n\n[![Build Status](https://travis-ci.org/ClimbsRocks/auto_ml.svg?branch=master)](https://travis-ci.org/ClimbsRocks/auto_ml)\n[![Documentation Status](http://readthedocs.org/projects/auto-ml/badge/?version=latest)](http://auto-ml.readthedocs.io/en/latest/?badge=latest)\n[![PyPI version](https://badge.fury.io/py/auto_ml.svg)](https://badge.fury.io/py/auto_ml)\n[![Coverage Status](https://coveralls.io/repos/github/ClimbsRocks/auto_ml/badge.svg?branch=master&cacheBuster=1)](https://coveralls.io/github/ClimbsRocks/auto_ml?branch=master)\n[![license](https://img.shields.io/github/license/mashape/apistatus.svg)]()\n<!-- Stars badge?! -->\n\n## Installation\n\n- `pip install auto_ml`\n\n## Getting started\n\n```python\nfrom auto_ml import Predictor\nfrom auto_ml.utils import get_boston_dataset\n\ndf_train, df_test = get_boston_dataset()\n\ncolumn_descriptions = {\n    'MEDV': 'output'\n    , 'CHAS': 'categorical'\n}\n\nml_predictor = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n\nml_predictor.train(df_train)\n\nml_predictor.score(df_test, df_test.MEDV)\n```\n\n## Show off some more features!\n\nauto_ml is designed for production. Here's an example that includes serializing and loading the trained model, then getting predictions on single dictionaries, roughly the process you'd likely follow to deploy the trained model.\n\n```python\nfrom auto_ml import Predictor\nfrom auto_ml.utils import get_boston_dataset\nfrom auto_ml.utils_models import load_ml_model\n\n# Load data\ndf_train, df_test = get_boston_dataset()\n\n# Tell auto_ml which column is 'output'\n# Also note columns that aren't purely numerical\n# Examples include ['nlp', 'date', 'categorical', 'ignore']\ncolumn_descriptions = {\n  'MEDV': 'output'\n  , 'CHAS': 'categorical'\n}\n\nml_predictor = Predictor(type_of_estimator='regressor', column_descriptions=column_descriptions)\n\nml_predictor.train(df_train)\n\n# Score the model on test data\ntest_score = ml_predictor.score(df_test, df_test.MEDV)\n\n# auto_ml is specifically tuned for running in production\n# It can get predictions on an individual row (passed in as a dictionary)\n# A single prediction like this takes ~1 millisecond\n# Here we will demonstrate saving the trained model, and loading it again\nfile_name = ml_predictor.save()\n\ntrained_model = load_ml_model(file_name)\n\n# .predict and .predict_proba take in either:\n# A pandas DataFrame\n# A list of dictionaries\n# A single dictionary (optimized for speed in production evironments)\npredictions = trained_model.predict(df_test)\nprint(predictions)\n```\n\n## XGBoost, Deep Learning with TensorFlow & Keras, and LightGBM\n\nauto_ml has all three of these awesome libraries integrated!\nGenerally, just pass one of them in for model_names.\n`ml_predictor.train(data, model_names=['DeepLearningClassifier'])`\n\nAvailable options are\n- `DeepLearningClassifier` and `DeepLearningRegressor`\n- `XGBClassifier` and `XGBRegressor`\n- `LGBMClassifer` and `LGBMRegressor`\n\nAll of these projects are ready for production. These projects all have prediction time in the 1 millisecond range for a single prediction, and are able to be serialized to disk and loaded into a new environment after training.\n\nDepending on your machine, they can occasionally be difficult to install, so they are not included in auto_ml's default installation. You are responsible for installing them yourself. auto_ml will run fine without them installed (we check what's isntalled before choosing which algorithm to use). If you want to try the easy install, just `pip install -r advanced_requirements.txt`, which will install TensorFlow, Keras, and XGBoost. LightGBM is not available as a pip install currently.\n\n\n## Classification\n\nBinary and multiclass classification are both supported. Note that for now, labels must be integers (0 and 1 for binary classification). auto_ml will automatically detect if it is a binary or multiclass classification problem- you just have to pass in `ml_predictor = Predictor(type_of_estimator='classifier', column_descriptions=column_descriptions)`\n\n\n## Feature Learning\n\nAlso known as \"finally found a way to make this deep learning stuff useful for my business\". Deep Learning is great at learning important features from your data. But the way it turns these learned features into a final prediction is relatively basic. Gradient boosting is great at turning features into accurate predictions, but it doesn't do any feature learning.\n\nIn auto_ml, you can now automatically use both types of models for what they're great at. If you pass `feature_learning=True, fl_data=some_dataframe` to `.train()`, we will do exactly that: train a deep learning model on your `fl_data`. We won't ask it for predictions (standard stacking approach), instead, we'll use it's penultimate layer to get it's 10 most useful features. Then we'll train a gradient boosted model (or any other model of your choice) on those features plus all the original features.\n\nAcross some problems, we've witnessed this lead to a 5% gain in accuracy, while still making predictions in 1-4 milliseconds, depending on model complexity.\n\n`ml_predictor.train(df_train, feature_learning=True, fl_data=df_fl_data)`\n\nThis feature only supports regression and binary classification currently. The rest of auto_ml supports multiclass classification.\n\n## Categorical Ensembling\n\nEver wanted to train one market for every store/customer, but didn't want to maintain hundreds of thousands of independent models? With `ml_predictor.train_categorical_ensemble()`, we will handle that for you. You'll still have just one consistent API, `ml_predictor.predict(data)`, but behind this single API will be one model for each category you included in your training data.\n\nJust tell us which column holds the category you want to split on, and we'll handle the rest. As always, saving the model, loading it in a different environment, and getting speedy predictions live in production is baked right in.\n\n`ml_predictor.train_categorical_ensemble(df_train, categorical_column='store_name')`\n\n\n### More details available in the docs\n\nhttp://auto-ml.readthedocs.io/en/latest/\n\n\n### Advice\n\nBefore you go any further, try running the code. Load up some data (either a DataFrame, or a list of dictionaries, where each dictionary is a row of data). Make a `column_descriptions` dictionary that tells us which attribute name in each row represents the value we're trying to predict. Pass all that into `auto_ml`, and see what happens!\n\nEverything else in these docs assumes you have done at least the above. Start there and everything else will build on top. But this part gets you the output you're probably interested in, without unnecessary complexity.\n\n\n## Docs\n\nThe full docs are available at https://auto_ml.readthedocs.io\nAgain though, I'd strongly recommend running this on an actual dataset before referencing the docs any futher.\n\n\n## What this project does\n\nAutomates the whole machine learning process, making it super easy to use for both analytics, and getting real-time predictions in production.\n\nA quick overview of buzzwords, this project automates:\n\n- Analytics (pass in data, and auto_ml will tell you the relationship of each variable to what it is you're trying to predict).\n- Feature Engineering (particularly around dates, and NLP).\n- Robust Scaling (turning all values into their scaled versions between the range of 0 and 1, in a way that is robust to outliers, and works with sparse data).\n- Feature Selection (picking only the features that actually prove useful).\n- Data formatting (turning a DataFrame or a list of dictionaries into a sparse matrix, one-hot encoding categorical variables, taking the natural log of y for regression problems, etc).\n- Model Selection (which model works best for your problem- we try roughly a dozen apiece for classification and regression problems, including favorites like XGBoost if it's installed on your machine).\n- Hyperparameter Optimization (what hyperparameters work best for that model).\n<!-- - Ensembling (Train up a bunch of different estimators, then train a final estimator to intelligently aggregate them together. Also useful if you're just trying to compare many different models and see what works best.) -->\n- Big Data (feed it lots of data- it's fairly efficient with resources).\n- Unicorns (you could conceivably train it to predict what is a unicorn and what is not).\n- Ice Cream (mmm, tasty...).\n- Hugs (this makes it much easier to do your job, hopefully leaving you more time to hug those those you care about).\n\n\n### Running the tests\n\nIf you've cloned the source code and are making any changes (highly encouraged!), or just want to make sure everything works in your environment, run\n`nosetests -v tests`.\n\nCI is also set up, so if you're developing on this, you can just open a PR, and the tests will run automatically on Travis-CI.\n\nThe tests are relatively comprehensive, though as with everything with auto_ml, I happily welcome your contributions here!\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/ClimbsRocks/auto_ml",
    "keywords": "machine learning,data science,automated machine learning,regressor,regressors,regression,classification,classifiers,classifier,estimators,predictors,XGBoost,Random Forest,sklearn,scikit-learn,analytics,analysts,coefficients,feature importancesanalytics,artificial intelligence,subpredictors,ensembling,stacking,blending,feature engineering,feature extraction,feature selection,production,pandas,dataframes,machinejs,deep learning,tensorflow,deeplearning,lightgbm,gradient boosting,gbm,keras,production ready,test coverage",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "automl",
    "platform": "",
    "project_url": "https://pypi.org/project/automl/",
    "release_url": "https://pypi.org/project/automl/2.1.5/",
    "requires_python": "",
    "summary": "Automated machine learning for production and analytics",
    "version": "2.1.5"
  },
  "releases": {
    "2.1.5": [
      {
        "comment_text": "",
        "digests": {
          "md5": "85d499b2330d2c930e7191c855d142c7",
          "sha256": "e8a9b7fd2d1d8e8236a13cbe35775929bae718ab4bc1a1c4743a9e5febce5c6b"
        },
        "downloads": 0,
        "filename": "automl-2.1.5-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "85d499b2330d2c930e7191c855d142c7",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 52868,
        "upload_time": "2017-05-19T15:48:02",
        "url": "https://files.pythonhosted.org/packages/fe/8d/32c1e4178fa42d3b84c19cd9d32c5a5c85809dedc125d99f5ccd23c6dce3/automl-2.1.5-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "4ce9ba8fbcef18eba0e3b012ac6675cd",
          "sha256": "2e2fc2d548bc4556cc857c854c66eafd62695f3bbd3902958a475cf098279fc1"
        },
        "downloads": 0,
        "filename": "automl-2.1.5.tar.gz",
        "has_sig": false,
        "md5_digest": "4ce9ba8fbcef18eba0e3b012ac6675cd",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 49116,
        "upload_time": "2017-05-19T15:48:05",
        "url": "https://files.pythonhosted.org/packages/91/45/75ba0559f14da0226948b599b5067eff7ebd555068f127558c9fc753e627/automl-2.1.5.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "85d499b2330d2c930e7191c855d142c7",
        "sha256": "e8a9b7fd2d1d8e8236a13cbe35775929bae718ab4bc1a1c4743a9e5febce5c6b"
      },
      "downloads": 0,
      "filename": "automl-2.1.5-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "85d499b2330d2c930e7191c855d142c7",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 52868,
      "upload_time": "2017-05-19T15:48:02",
      "url": "https://files.pythonhosted.org/packages/fe/8d/32c1e4178fa42d3b84c19cd9d32c5a5c85809dedc125d99f5ccd23c6dce3/automl-2.1.5-py2.py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "4ce9ba8fbcef18eba0e3b012ac6675cd",
        "sha256": "2e2fc2d548bc4556cc857c854c66eafd62695f3bbd3902958a475cf098279fc1"
      },
      "downloads": 0,
      "filename": "automl-2.1.5.tar.gz",
      "has_sig": false,
      "md5_digest": "4ce9ba8fbcef18eba0e3b012ac6675cd",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 49116,
      "upload_time": "2017-05-19T15:48:05",
      "url": "https://files.pythonhosted.org/packages/91/45/75ba0559f14da0226948b599b5067eff7ebd555068f127558c9fc753e627/automl-2.1.5.tar.gz"
    }
  ]
}