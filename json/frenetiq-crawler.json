{
  "info": {
    "author": "Daniel Kiss",
    "author_email": "littlesnorrboy@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "<h1>Frenetiq Crawler</h1>\n<h2>About</h2>\n<ul>\n<li>Version: 0.0.1</li>\n<li>Travis CI: <a href=\"https://travis-ci.org/snorrwe/frenetiq-crawler\"><img alt=\"Build Status\" src=\"https://travis-ci.org/snorrwe/frenetiq-crawler.svg?branch=master\" /></a></li>\n<li>Supported Python versions: <ul>\n<li>Python 2.7</li>\n<li>Python 3.6</li>\n<li>Pypy</li>\n<li>Pypy 3</li>\n</ul>\n</li>\n</ul>\n<h2>Installation</h2>\n<p><code>pip install frenetiq-crawler</code></p>\n<h2>Usage</h2>\n<h3>Example code</h3>\n<p>```python</p>\n<h1>!/usr/bin/python</h1>\n<p>from frenetiq_crawler import run\nfrom frenetiq_crawler.services import SERVICES\nfrom frenetiq_crawler.crawler.link_crawler import LinkCrawler</p>\n<p>class MyCrawler(LinkCrawler):\n    # This is a custom crawler to handle a single webpage\n    # If you wish to preserve existing functionality when overriding methods,\n    # do not forget to call the super method aswell\n    def feed(self, data):\n        # Override the feed method to customize handling the whole page data\n        self.log_service.info(\"Yeah boi, a page!\")\n        return LinkCrawler.feed(self, data)</p>\n<pre><code>def handle_starttag(self, tag, attrs):\n    # Override HTMLParser methods for custom behaviour\n    # Call the super method to return links on the page\n    # The default DomainCrawler class will continue crawling if crawl() returns a \n    # CrawlResult with links\n    super(MyCrawler, self).handle_starttag(tag, attrs)\n    if(tag == 'img'):\n        self.log_service.info(\"Yeeeeaaaah boiiiiiii, I found an %s\" % (tag))\n    if(tag == 'a'):\n        self.log_service.debug(\"Boi, I found a link!\")\n</code></pre>\n<p>def main():\n    # Override crawler_factory with my own implementation\n    SERVICES['crawler_factory'] = MyCrawler \n    run()</p>\n<p>if <strong>name</strong> == '<strong>main</strong>':\n    main()\n```</p>\n<p>```bash\n$ python crawler_example.py -u snorrwe.github.io/crawler_test</p>\n<p>[Info]Thread=[MainThread]        ----------Crawl starting----------\n[Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[1]\n[Info]Thread=[WSc--3]    Yeah boi, a page!\n[Debug]Thread=[WSc--3]   Boi, I found a link!\n[Debug]Thread=[WSc--3]   Boi, I found a link!\n[Info]Thread=[WSc--3]    Yeeeeaaaah boiiiiiii, I found an img\n[Info]Thread=[WSc--3]    Link=[http://snorrwe.github.io/crawler_test] StatusCode=[200] Size=[310]\n[Debug]Thread=[WSc--3]   URLs visited=[1], remaining=[2]\n[Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[2]\n[Info]Thread=[WSc--8]    Yeah boi, a page!\n[Debug]Thread=[WSc--8]   Boi, I found a link!\n[Info]Thread=[WSc--8]    Link=[http://snorrwe.github.io/crawler_test/kanga.html] StatusCode=[200] Size=[220]\n[Debug]Thread=[WSc--8]   URLs visited=[2], remaining=[0]\n[Info]Thread=[WSc--7]    Link=[http://snorrwe.github.io/crawler_test/kanga2.html] StatusCode=[404] Size=[9340]\n[Debug]Thread=[WSc--7]   URLs visited=[3], remaining=[0]\n[Info]Thread=[MainThread]        Total urls crawled=[3] Urls left to crawl=[0]\n[Info]Thread=[MainThread]        ----------Crawl finished----------\n```</p>\n<h3>Command line arguments</h3>\n<table>\n    <thead>\n        <tr>\n            <th>Name</th>\n            <th>Short</th>\n            <th>Description</th>\n        </tr>\n    </thead>\n    <tbody>\n        <div>\n            <tr>\n                <td>--help</td>\n                <td>-h</td>\n                <td rowspan=\"2\">Show the help and exit</td>\n            </tr>\n            <tr>\n            </tr>\n        </div>\n        <div>\n            <tr>\n                <td>--url</td>\n                <td>-u</td>\n                <td rowspan=\"2\">Base url you wish to crawl.<br>\n                <i>\n                    Note that if you pass the url argument to run() or crawl() this option will be ignored.\n                </i>\n                </td>\n            </tr>\n            <tr>\n            </tr>\n        </div>\n        <div>\n            <tr>\n                <td>--threads</td>\n                <td>-t</td>\n                <td rowspan=\"2\">Maximum number of concurrent threads</td>\n            </tr>\n            <tr>\n            </tr>\n        </div>\n        <div>\n            <tr>\n                <td>--loglevel</td>\n                <td>-l</td>\n                <td rowspan=\"2\">Level of logging, possible values = [all, info, debug, warn, error, none]</td>\n            </tr>\n            <tr>\n            </tr>\n        </div>\n    </tbody>\n</table>\n\n<h2>Testing</h2>\n<h3>Running the unit tests</h3>\n<p>Running the unit tests with the <strong>pytest</strong> package.<br>\nTo install pytest via pip run <code>pip install pytest</code>.</p>\n<p>To run the tests run <code>pytest</code> in the root folder.</p>\n<h3>Test code</h3>\n<h4>Unit testing</h4>\n<p>Test files are located next to the files they meant to test.<br>\nTest files have the same base name, and end with <em>_test</em><br>\nFor example: tests for file <em>some_source.py</em> are in the file <em>some_source_test.py</em></p>\n<h4>End-to-end testing</h4>\n<p>Test files are located in the <em>e2e</em> directory.<br></p>\n<h2>License</h2>\n<p><a href=\"https://github.com/snorrwe/Crawler/blob/master/LICENSE\">MIT</a></p>",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/snorrwe/frenetiq-crawler",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "frenetiq-crawler",
    "platform": "",
    "project_url": "https://pypi.org/project/frenetiq-crawler/",
    "release_url": "https://pypi.org/project/frenetiq-crawler/0.0.2/",
    "requires_dist": [],
    "requires_python": ">=2.7, >=3.4",
    "summary": "A simple web crawling module",
    "version": "0.0.2"
  },
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b91f83695d29aee59742e5198403dae7",
          "sha256": "3dfdaad6a27074be34bef2d013e4c7b33f5402bf1d75a2bd3589c084b77be8e0"
        },
        "downloads": 0,
        "filename": "frenetiq_crawler-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b91f83695d29aee59742e5198403dae7",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12081,
        "upload_time": "2017-08-24T23:08:24",
        "url": "https://files.pythonhosted.org/packages/f1/ca/da35841b3ea8b02a8bd6535e2ee133213d1385365a87adb63135eb8f78f7/frenetiq_crawler-0.0.2.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "b91f83695d29aee59742e5198403dae7",
        "sha256": "3dfdaad6a27074be34bef2d013e4c7b33f5402bf1d75a2bd3589c084b77be8e0"
      },
      "downloads": 0,
      "filename": "frenetiq_crawler-0.0.2.tar.gz",
      "has_sig": false,
      "md5_digest": "b91f83695d29aee59742e5198403dae7",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 12081,
      "upload_time": "2017-08-24T23:08:24",
      "url": "https://files.pythonhosted.org/packages/f1/ca/da35841b3ea8b02a8bd6535e2ee133213d1385365a87adb63135eb8f78f7/frenetiq_crawler-0.0.2.tar.gz"
    }
  ]
}