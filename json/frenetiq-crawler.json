{
  "info": {
    "author": "Daniel Kiss",
    "author_email": "littlesnorrboy@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "Frenetiq Crawler\n================\n\nAbout\n-----\n\n-  Version: 0.0.1\n-  Travis CI: |Build Status|\n-  Supported Python versions:\n\n   -  Python 2.7\n   -  Python 3.6\n   -  Pypy\n   -  Pypy 3\n\nInstallation\n------------\n\n``pip install frenetiq-crawler``\n\nUsage\n-----\n\nExample code\n~~~~~~~~~~~~\n\n.. code:: python\n\n    #!/usr/bin/python\n\n    from frenetiq_crawler import run\n    from frenetiq_crawler.services import SERVICES\n    from frenetiq_crawler.crawler.link_crawler import LinkCrawler\n\n    class MyCrawler(LinkCrawler):\n        # This is a custom crawler to handle a single webpage\n        # If you wish to preserve existing functionality when overriding methods,\n        # do not forget to call the super method aswell\n        def feed(self, data):\n            # Override the feed method to customize handling the whole page data\n            self.log_service.info(\"Yeah boi, a page!\")\n            return LinkCrawler.feed(self, data)\n\n        def handle_starttag(self, tag, attrs):\n            # Override HTMLParser methods for custom behaviour\n            # Call the super method to return links on the page\n            # The default DomainCrawler class will continue crawling if crawl() returns a \n            # CrawlResult with links\n            super(MyCrawler, self).handle_starttag(tag, attrs)\n            if(tag == 'img'):\n                self.log_service.info(\"Yeeeeaaaah boiiiiiii, I found an %s\" % (tag))\n            if(tag == 'a'):\n                self.log_service.debug(\"Boi, I found a link!\")\n\n    def main():\n        # Override crawler_factory with my own implementation\n        SERVICES['crawler_factory'] = MyCrawler \n        run()\n\n    if __name__ == '__main__':\n        main()\n\n.. code:: bash\n\n    python crawler_example.py -u snorrwe.github.io/crawler_test\n\n    [Info]Thread=[MainThread]        ----------Crawl starting----------\n    [Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[1]\n    [Info]Thread=[WSc--0]    Yeah boi, a page!\n    [Debug]Thread=[WSc--0]   Boi, I found a link!\n    [Debug]Thread=[WSc--0]   Boi, I found a link!\n    [Info]Thread=[WSc--0]    Yeeeeaaaah boiiiiiii, I found an img\n    [Info]Thread=[WSc--0]    Link=[http://snorrwe.github.io/crawler_test] StatusCode=[200] Size=[310]\n    [Debug]Thread=[WSc--0]\n        Urls visited=[1]\n        Urls in progess=[0]\n        Urls left=[2]\n    [Debug]Thread=[MainThread]       No urls to crawl, going to sleep. Work in progress=[2]\n    [Info]Thread=[WSc--4]    Link=[http://snorrwe.github.io/crawler_test/kanga2.html] StatusCode=[404] Size=[9340]\n    [Debug]Thread=[WSc--4]\n        Urls visited=[2]\n        Urls in progess=[1]\n        Urls left=[0]\n    [Info]Thread=[WSc--2]    Yeah boi, a page!\n    [Debug]Thread=[WSc--2]   Boi, I found a link!\n    [Info]Thread=[WSc--2]    Link=[http://snorrwe.github.io/crawler_test/kanga.html] StatusCode=[200] Size=[220]\n    [Debug]Thread=[WSc--2]\n        Urls visited=[3]\n        Urls in progess=[0]\n        Urls left=[0]\n    [Info]Thread=[MainThread]\n        Urls visited=[3]\n        Urls in progess=[0]\n        Urls left=[0]\n    [Info]Thread=[MainThread]        ----------Crawl finished----------\n\nCommand line arguments\n~~~~~~~~~~~~~~~~~~~~~~\n\n.. raw:: html\n\n   <table>\n       <thead>\n           <tr>\n               <th>\n\nName\n\n.. raw:: html\n\n   </th>\n               <th>\n\nShort\n\n.. raw:: html\n\n   </th>\n               <th>\n\nDescription\n\n.. raw:: html\n\n   </th>\n           </tr>\n       </thead>\n       <tbody>\n           <div>\n               <tr>\n                   <td>\n\n--help\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-h\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nShow the help and exit\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--url\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-u\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nBase url you wish to crawl. Note that if you pass the url argument to\nrun() or crawl() this option will be ignored.\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--threads\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-t\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nMaximum number of concurrent threads\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n           <div>\n               <tr>\n                   <td>\n\n--loglevel\n\n.. raw:: html\n\n   </td>\n                   <td>\n\n-l\n\n.. raw:: html\n\n   </td>\n                   <td rowspan=\"2\">\n\nLevel of logging, possible values = [all, info, debug, warn, error,\nnone]\n\n.. raw:: html\n\n   </td>\n               </tr>\n               <tr>\n               </tr>\n           </div>\n       </tbody>\n   </table>\n\nTesting\n-------\n\nRunning the unit tests\n~~~~~~~~~~~~~~~~~~~~~~\n\nRunning the unit tests with the **pytest** package. To install pytest\nvia pip run ``pip install pytest``.\n\nTo run the tests run ``pytest`` in the root folder.\n\nTest code\n~~~~~~~~~\n\nUnit testing\n^^^^^^^^^^^^\n\nTest files are located next to the files they meant to test. Test files\nhave the same base name, and end with **test\\ * For example: tests for\nfile *\\ some*\\ source.py* are in the file *some\\_source\\_test.py*\n\nEnd-to-end testing\n^^^^^^^^^^^^^^^^^^\n\nTest files are located in the *e2e* directory.\n\nLicense\n-------\n\n`MIT <https://github.com/snorrwe/Crawler/blob/master/LICENSE>`__\n\n.. |Build Status| image:: https://travis-ci.org/snorrwe/frenetiq-crawler.svg?branch=master\n   :target: https://travis-ci.org/snorrwe/frenetiq-crawler",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/snorrwe/frenetiq-crawler",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "frenetiq-crawler",
    "platform": "",
    "project_url": "https://pypi.org/project/frenetiq-crawler/",
    "release_url": "https://pypi.org/project/frenetiq-crawler/0.0.3/",
    "requires_dist": [],
    "requires_python": ">=2.7, >=3.4",
    "summary": "A simple web crawling module",
    "version": "0.0.3"
  },
  "releases": {
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b91f83695d29aee59742e5198403dae7",
          "sha256": "3dfdaad6a27074be34bef2d013e4c7b33f5402bf1d75a2bd3589c084b77be8e0"
        },
        "downloads": 0,
        "filename": "frenetiq_crawler-0.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "b91f83695d29aee59742e5198403dae7",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12081,
        "upload_time": "2017-08-24T23:08:24",
        "url": "https://files.pythonhosted.org/packages/f1/ca/da35841b3ea8b02a8bd6535e2ee133213d1385365a87adb63135eb8f78f7/frenetiq_crawler-0.0.2.tar.gz"
      }
    ],
    "0.0.3": [
      {
        "comment_text": "",
        "digests": {
          "md5": "05baa3a7a6d37503a96248784a130ae8",
          "sha256": "444f83b29006228a16be4e8dda86cfc40425586a9d5303170e5c35b038532ddc"
        },
        "downloads": 0,
        "filename": "frenetiq_crawler-0.0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "05baa3a7a6d37503a96248784a130ae8",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12404,
        "upload_time": "2017-08-26T09:51:02",
        "url": "https://files.pythonhosted.org/packages/4e/e5/d7b101f1f5e81a977e22604913bafe5f130da92aba9017b568620d3ce025/frenetiq_crawler-0.0.3.tar.gz"
      }
    ],
    "0.0.dev1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b23523a4c68fd015b1ccd1604db74c3a",
          "sha256": "e2b79725be399b0f694158159e3a6d78eaf9ecdb0cbcb64b7b66b73f4177bec9"
        },
        "downloads": 0,
        "filename": "frenetiq_crawler-0.0.dev1.tar.gz",
        "has_sig": false,
        "md5_digest": "b23523a4c68fd015b1ccd1604db74c3a",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12416,
        "upload_time": "2017-08-25T21:38:33",
        "url": "https://files.pythonhosted.org/packages/21/fa/886b98d90a353a01cb09b3b543105b13158dd1a32f5bc31db84aedd5b445/frenetiq_crawler-0.0.dev1.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "05baa3a7a6d37503a96248784a130ae8",
        "sha256": "444f83b29006228a16be4e8dda86cfc40425586a9d5303170e5c35b038532ddc"
      },
      "downloads": 0,
      "filename": "frenetiq_crawler-0.0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "05baa3a7a6d37503a96248784a130ae8",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 12404,
      "upload_time": "2017-08-26T09:51:02",
      "url": "https://files.pythonhosted.org/packages/4e/e5/d7b101f1f5e81a977e22604913bafe5f130da92aba9017b568620d3ce025/frenetiq_crawler-0.0.3.tar.gz"
    }
  ]
}