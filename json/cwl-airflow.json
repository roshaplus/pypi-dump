{
  "info": {
    "author": "Michael Kotliar",
    "author_email": "misha.kotliar@gmail.com",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "[![Build Status](https://travis-ci.org/Barski-lab/cwl-airflow.svg?branch=master)](https://travis-ci.org/Barski-lab/cwl-airflow)\n# cwl-airflow\n\n### About\nPython package to extend **[Apache-Airflow 1.8.2](https://github.com/apache/incubator-airflow)**\nfunctionality with **[CWL v1.0](http://www.commonwl.org/v1.0/)** support.\n\n### Installation\n1. Make sure your system satisfies the following criteria:\n      - Ubuntu 16.04.3\n        - python 2.7.12\n        - pip\n          ```\n          sudo apt install python-pip\n          pip install --upgrade pip\n          ```\n        - setuptools\n          ```\n          pip install setuptools\n          ```\n        - [docker](https://docs.docker.com/engine/installation/linux/docker-ce/ubuntu/)\n          ```\n          sudo apt-get update\n          sudo apt-get install apt-transport-https ca-certificates curl software-properties-common\n          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\n          sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\"\n          sudo apt-get update\n          sudo apt-get install docker-ce\n          sudo groupadd docker\n          sudo usermod -aG docker $USER\n          ```\n          Log out and log back in so that your group membership is re-evaluated.\n        - libmysqlclient-dev\n          ```bash\n          sudo apt-get install libmysqlclient-dev\n          ```\n        - nodejs\n          ```\n          sudo apt-get install nodejs\n          ```\n2. Get the latest version of `cwl-airflow`.\n   If you don't want to download workflow example and its input data,\n   omit `--recursive` flag). If **[Apache-Airflow](https://github.com/apache/incubator-airflow)**\n   or **[cwltool](http://www.commonwl.org/ \"cwltool main page\")** aren't installed,\n   it will be done automatically with recommended versions:\n   **Apache-Airflow v1.8.2**, **cwltool 1.0.20180116213856**. If you have already installed\n   **Apache-Airflow v1.8.2**, set `AIRFLOW_HOME` environment variable to point to Airflow\n   home directory, before running the following commands.\n      ```sh\n      $ git clone --recursive https://github.com/Barski-lab/cwl-airflow.git\n      $ cd cwl-airflow\n      $ pip install --user .\n      $ ./post_install.sh\n      ```\n\n3. If required, add **[extra packages](https://airflow.incubator.apache.org/installation.html#extra-packages)**\n   for extending Airflow functionality with MySQL, PostgreSQL backend support etc.\n\n### Running\n\n#### Automatic mode\n1. Put your cwl descriptor file with all of the related tools and subworkflows\n   into the folder set as **cwl_workflows** parameter in the **[cwl]** section  of Airflow\n   configuration file **airflow.cfg**\n\n2. Put your input parameters file into subfolder **new** of the directory set as **cwl_jobs** parameter\n   in the **[cwl]** section  of Airflow configuration file **airflow.cfg**\n\n    - to allow automatically fetch CWL descriptor file by job's file name, follow naming rule\n      ```\n      [identical].cwl                 - workflow descriptor filename\n      [identical][arbitrary].json     - input parameters filename\n      ```\n      where `[identical]` part of the name defines the correspondence between workflow and job files.\n      \n    - job file may include additional fields which in case of **output_folder** and **tmp_folder**\n      redefines parameters of the same name from **[cwl]** section  of Airflow configuration file\n      **airflow.cfg**\n      ```     \n      {\n          \"uid\": \"arbitrary unique id, which will be used for current workflow run\",\n          \"output_folder\": \"path to the folder to save results\",\n          \"tmp_folder\": \"path to the folder to save temporary calculation results\",\n          \"author\": \"Author of a the experiment. Default: CWL-Airflow\"\n      }\n      ```\n      \n3. Run Airflow scheduler:\n   ```sh\n   $ airflow scheduler\n   ```\n\n#### Manual mode\nUse `cwl-airflow-runner` with explicitly specified cwl descriptor `WORKFLOW`\nand input parameters `JOB` files.\n\n```bash\n   cwl-airflow-runner WORKFLOW JOB\n```\n\nIf necessary, set additional arguments following the `cwl-airflow-runner --help`\n\n\n### Collecting output\n  All output files will be saved into subfolder of the directory set as **output_folder** parameter\n  in the **[cwl]** section of Airflow configuration file **airflow.cfg** with the name corresponding\n  to the job file name.\n  \n### Running example workflow\nIf you cloned from **[cwl-airflow](https://github.com/Barski-lab/cwl-airflow.git)**\nusing `--recursive` flag, you may run `cwl-airflow` with example\n**[biowardrobe_chipseq_se.cwl](https://github.com/Barski-lab/ga4gh_challenge/blob/master/biowardrobe_chipseq_se.cwl)** workflow.\nWe assume that you cloned **[cwl-airflow](https://github.com/Barski-lab/cwl-airflow.git)** into `/tmp`,\nand **[cwl]** section of your Airflow configuration file **airflow.cfg** has the following values for **cwl_jobs**\nand **cwl_workflows** parameters\n   - `cwl_jobs = /home/user/airflow/cwl/jobs`\n   - `cwl_workflows = /home/user/airflow/cwl/workflows`\n   \nTo run the **[biowardrobe_chipseq_se.cwl](https://github.com/Barski-lab/ga4gh_challenge/blob/master/biowardrobe_chipseq_se.cwl)** workflow\ndo the following steps:\n1. Decompress input FASTQ file, running the script\n      \n  ```sh\n  $ cd /tmp/cwl-airflow/workflow_example/data\n  $ ./prepare_inputs.sh\n  ```\n2. Move `workflow_example` folder into the directory set as **cwl_workflows** parameter in the **[cwl]** section  of Airflow\n   configuration file **airflow.cfg**\n   \n   ```python\n   mv /tmp/cwl-airflow/workflow_example /home/user/airflow/cwl/workflows\n   ```\n   \n3. Update input parameters file `biowardrobe_chipseq_se.json`\n   with the correct locations of your input files\n   ```python\n    cat /home/user/airflow/cwl/workflows/workflow_example/biowardrobe_chipseq_se.json\n    {\n      \"fastq_file\": {\"class\": \"File\", \"location\": \"/home/user/airflow/cwl/workflows/workflow_example/data/inputs/SRR1198790.fastq\", \"format\": \"http://edamontology.org/format_1930\"},\n      \"indices_folder\": {\"class\": \"Directory\", \"location\": \"/home/user/airflow/cwl/workflows/workflow_example/data/references/dm3/bowtie_indices\"},\n      \"annotation_file\": {\"class\": \"File\", \"location\": \"/home/user/airflow/cwl/workflows/workflow_example/data/references/dm3/refgene.tsv\", \"format\": \"http://edamontology.org/format_3475\"},\n      \"chrom_length\": {\"class\": \"File\", \"location\": \"/home/user/airflow/cwl/workflows/workflow_example/data/references/dm3/chrNameLength.txt\", \"format\": \"http://edamontology.org/format_2330\"},\n      \"clip_3p_end\": 0,\n      \"clip_5p_end\": 0,\n      \"remove_duplicates\": false,\n      \"exp_fragment_size\": 150,\n      \"force_fragment_size\": false,\n      \"broad_peak\": false,\n      \"threads\": 8,\n      \"genome_size\": \"1.2e8\"\n    }\n    ```\n4. Move input parameters file `biowardrobe_chipseq_se.json`\n   into the subfolder **new** of the directory set as **cwl_jobs** parameter in the **[cwl]** section  of Airflow\n   configuration file **airflow.cfg**\n   ```python\n    mv /home/user/airflow/cwl/workflows/workflow_example/biowardrobe_chipseq_se.json /home/user/airflow/cwl/jobs/new \n   ```\n5. Start airflow scheduler\n   ```python\n    airflow scheduler\n   ```",
    "docs_url": null,
    "download_url": "https://github.com/Barski-lab/cwl-airflow",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/Barski-lab/cwl-airflow",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "cwl-airflow",
    "platform": "",
    "project_url": "https://pypi.org/project/cwl-airflow/",
    "release_url": "https://pypi.org/project/cwl-airflow/1.0.0/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Python package to extend Airflow functionality with CWL v1.0 support",
    "version": "1.0.0"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "57dafd2432ee8f41420470584b7806fb",
          "sha256": "11d0cfd878c82320291d4312c1f3225c5ab67067af9050c5bff42f31c99dd6f6"
        },
        "downloads": -1,
        "filename": "cwl-airflow-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "57dafd2432ee8f41420470584b7806fb",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 16453,
        "upload_time": "2018-01-26T21:48:13",
        "url": "https://files.pythonhosted.org/packages/0d/79/918fa36f22883df734a91021d734473a4e2f37b27562a48a1cdabbc239aa/cwl-airflow-1.0.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "57dafd2432ee8f41420470584b7806fb",
        "sha256": "11d0cfd878c82320291d4312c1f3225c5ab67067af9050c5bff42f31c99dd6f6"
      },
      "downloads": -1,
      "filename": "cwl-airflow-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "57dafd2432ee8f41420470584b7806fb",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 16453,
      "upload_time": "2018-01-26T21:48:13",
      "url": "https://files.pythonhosted.org/packages/0d/79/918fa36f22883df734a91021d734473a4e2f37b27562a48a1cdabbc239aa/cwl-airflow-1.0.0.tar.gz"
    }
  ]
}