{
  "info": {
    "author": "Lablup Inc.",
    "author_email": "joongi@lablup.com",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: No Input/Output (Daemon)",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development"
    ],
    "description": "Backend.AI Kernel Runner\n========================\n\nA common base runner for various programming languages.\n\nIt manages an internal task queue so that multiple command/code execution requests\nare processed in the FIFO order, without garbling the console output.\n\n\nHow to write a new computation kernel\n-------------------------------------\n\nInherit ``ai.backend.kernel.BaseRunner`` and implement the following methods:\n\n* ``async def init_with_loop(self)``\n\n  - Called after the asyncio event loop becomes available.\n\n  - Mostly just ``pass``.\n\n  - If your kernel supports interactive user input, then put set\n    ``self.user_input_queue`` as an ``asyncio.Queue`` object.  It's your job\n    to utilize the queue object for waiting for the user input.  (See\n    ``handle_input()`` method in ``ai/backend/kernel/python/inproc.py`` for\n    reference)  If it's not set, then any attempts for getting interactive user\n    input will simply return ``\"<user-input is unsupported>\"``.\n\n* ``async def build_heuristic(self)``\n\n  - *(Batch mode)* Write a heuristic code to find some build script or run a\n    good-enough build command for your language/runtime.\n\n  - *(Blocking)* You don't have to worry about overlapped execution since the\n    base runner will take care of it.\n\n* ``async def execute_heuristic(self)``\n\n  - *(Batch mode)* Write a heuristic code to find the main program.\n\n  - *(Blocking)* You don't have to worry about overlapped execution since the\n    base runner will take care of it.\n\n* ``async def query(self, code_text)``\n\n  - *(Query mode)* Directly run the given code snippet. Depending on the language/runtime,\n    you may need to create a temporary file and execute an external program.\n\n  - *(Blocking)* You don't have to worry about overlapped execution since the\n    base runner will take care of it.\n\n* ``async def complete(self, data)``\n\n  - *(Query mode)* Take a dict data that includes the current line of code where\n    the user is typing and return a list of strings that can auto-complete it.\n\n  - *(Non-blocking)* You should implement this method to run asynchronously with\n    ongoing code execution.\n\n* ``async def interrupt(self)``\n\n  - *(Query mode)* Send an interruption signal to the running program. The implementation\n    is up to you. The Python runner currently spawns a thread for in-process\n    query-mode execution and use a ctypes hack to throw KeyboardInterrupt\n    exception into it.\n\n  - *(Non-blocking)* You should implement this method to run asynchronously with\n    ongoing code execution.\n\n\nNOTE: Existing codes are good referecnes!\n\n\nHow to use in your Backend.AI computation kernels\n-------------------------------------------------\n\nInstall this package using pip via a ``RUN`` instruction in Dockerfile.\nThen, set the ``CMD`` instruction like below:\n\n.. code-block:: dockerfile\n\n   CMD [\"/home/sorna/jail\", \"-policy\", \"/home/sorna/policy.yml\", \\\n        \"/usr/local/bin/python\", \"-m\", \"ai.backend.kernel\", \"<language>\"]\n\nwhere ``<language>`` should be one of the supported language names defined in\n``lang_map`` variable in ``ai/backend/kernel/__main__.py`` file.\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/lablup/backend.ai-kernel-runner",
    "keywords": "",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "backend.ai-kernel-runner",
    "platform": "",
    "project_url": "https://pypi.org/project/backend.ai-kernel-runner/",
    "release_url": "https://pypi.org/project/backend.ai-kernel-runner/1.0.1/",
    "requires_dist": [
      "codecov; extra == 'test'",
      "flake8; extra == 'test'",
      "asynctest; extra == 'test'",
      "pytest-mock; extra == 'test'",
      "pytest-cov; extra == 'test'",
      "pytest-asyncio; extra == 'test'",
      "pytest (>=3.1); extra == 'test'",
      "matplotlib; extra == 'python'",
      "numpy; extra == 'python'",
      "pandas; extra == 'python'",
      "IPython; extra == 'python'",
      "six; extra == 'python'",
      "pytest-sugar; extra == 'dev'",
      "codecov; extra == 'dev'",
      "flake8; extra == 'dev'",
      "asynctest; extra == 'dev'",
      "pytest-mock; extra == 'dev'",
      "pytest-cov; extra == 'dev'",
      "pytest-asyncio; extra == 'dev'",
      "pytest (>=3.1); extra == 'dev'",
      "twine; extra == 'dev'",
      "wheel; extra == 'dev'",
      "twine; extra == 'build'",
      "wheel; extra == 'build'",
      "msgpack-python",
      "janus",
      "namedlist",
      "simplejson",
      "uvloop (>=0.8)",
      "aiozmq (>=0.7)",
      "async-timeout (>=1.1)"
    ],
    "requires_python": ">=3.6",
    "summary": "User code executors for Backend.AI kernels",
    "version": "1.0.1"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "50487641bbc49a287c33077766f98f43",
          "sha256": "90face49482df6a2ab52e58c7105748d57beb4c8a4edbc938fdb3f433aa88cfb"
        },
        "downloads": -1,
        "filename": "backend.ai_kernel_runner-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "50487641bbc49a287c33077766f98f43",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 26933,
        "upload_time": "2017-11-01T16:31:35",
        "url": "https://files.pythonhosted.org/packages/9a/39/e2f864d5f13789fbccf3bec1c62981f567da5710d55a2a813bbc934da701/backend.ai_kernel_runner-1.0.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "8ff714a57f119a606e40b17aa063daba",
          "sha256": "d4c8707d51546a32f4630386d56e4ff8cab72567798e98572e66d946e315a582"
        },
        "downloads": -1,
        "filename": "backend.ai-kernel-runner-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "8ff714a57f119a606e40b17aa063daba",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12983,
        "upload_time": "2017-11-01T16:31:38",
        "url": "https://files.pythonhosted.org/packages/c0/99/3b1b79dfa0df9e031fe28056c8242bd732c0dfbc57b78f01e70c87d6e266/backend.ai-kernel-runner-1.0.0.tar.gz"
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0dbf3410ce8643039394f95654e33c3e",
          "sha256": "a4acc445ef96fb696ccb7682e07ec8d8598021e71d9adc4b92cda64c8ddf4f1a"
        },
        "downloads": -1,
        "filename": "backend.ai_kernel_runner-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0dbf3410ce8643039394f95654e33c3e",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 32606,
        "upload_time": "2017-11-01T17:36:32",
        "url": "https://files.pythonhosted.org/packages/0b/70/07423810c9cbd1cc72c7a70a5fc30793a61176ec68ac17f924c13f6b4484/backend.ai_kernel_runner-1.0.1-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "0a0063a98587fb8f437013a6ee2254e4",
          "sha256": "b260bea576d57ae7cd8fe2186f17bea11608f7cb03779a200270f01e0037cc19"
        },
        "downloads": -1,
        "filename": "backend.ai-kernel-runner-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "0a0063a98587fb8f437013a6ee2254e4",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 16762,
        "upload_time": "2017-11-01T17:36:34",
        "url": "https://files.pythonhosted.org/packages/6e/b1/a3e173d9ef951833c5aed49ff456882464b42556020c5f90eda07102431f/backend.ai-kernel-runner-1.0.1.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "0dbf3410ce8643039394f95654e33c3e",
        "sha256": "a4acc445ef96fb696ccb7682e07ec8d8598021e71d9adc4b92cda64c8ddf4f1a"
      },
      "downloads": -1,
      "filename": "backend.ai_kernel_runner-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "0dbf3410ce8643039394f95654e33c3e",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "size": 32606,
      "upload_time": "2017-11-01T17:36:32",
      "url": "https://files.pythonhosted.org/packages/0b/70/07423810c9cbd1cc72c7a70a5fc30793a61176ec68ac17f924c13f6b4484/backend.ai_kernel_runner-1.0.1-py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "0a0063a98587fb8f437013a6ee2254e4",
        "sha256": "b260bea576d57ae7cd8fe2186f17bea11608f7cb03779a200270f01e0037cc19"
      },
      "downloads": -1,
      "filename": "backend.ai-kernel-runner-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "0a0063a98587fb8f437013a6ee2254e4",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 16762,
      "upload_time": "2017-11-01T17:36:34",
      "url": "https://files.pythonhosted.org/packages/6e/b1/a3e173d9ef951833c5aed49ff456882464b42556020c5f90eda07102431f/backend.ai-kernel-runner-1.0.1.tar.gz"
    }
  ]
}