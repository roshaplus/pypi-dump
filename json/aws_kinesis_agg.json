{
  "info": {
    "author": "Brent Nash",
    "author_email": "brenash@amazon.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: Other/Proprietary License",
      "Natural Language :: English",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2.7",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Utilities"
    ],
    "description": "Python Kinesis Aggregation & Deaggregation Modules\r\n==================================================\r\n\r\nThe Kinesis Aggregation/Deaggregation Modules for Python provide the\r\nability to do in-memory aggregation and deaggregation of standard\r\nKinesis user records using the `Kinesis Aggregated Record\r\nFormat <https://github.com/awslabs/amazon-kinesis-producer/blob/master/aggregation-format.md>`__\r\nto allow for more efficient transmission of records.\r\n\r\nInstallation\r\n------------\r\n\r\nThe Python Record Aggregation/Deaggregation modules are available on the\r\nPython Package Index (PyPI) as\r\n`aws\\_kinesis\\_agg <https://pypi.python.org/pypi/aws_kinesis_agg>`__.\r\nYou can install it via the ``pip`` command line tool:\r\n\r\n::\r\n\r\n    pip install aws_kinesis_agg\r\n\r\nAlternately, you can simply copy the aws\\_kinesis\\_agg module from this\r\nrepository and use it directly with the caveat that the `Google protobuf\r\nmodule <https://pypi.python.org/pypi/protobuf>`__ must also be available\r\n(if you install via ``pip``, this dependency will be handled for you).\r\n\r\nRecord Aggregation Module (aggregator.py)\r\n-----------------------------------------\r\n\r\nThe `aggregator.py <aggregator.py>`__ module contains Python classes\r\nthat allow you to aggregate records using the `Kinesis Aggregated Record\r\nFormat <https://github.com/awslabs/amazon-kinesis-producer/blob/master/aggregation-format.md>`__.\r\nUsing record aggregation improves throughput and reduces costs when\r\nwriting producer applications that publish data to Amazon Kinesis.\r\n\r\nUsage\r\n~~~~~\r\n\r\nThe record aggregation module provides a simple interface for creating\r\nprotocol buffers encoded data in a producer application. The\r\n``aws_kinesis_agg`` module provides methods for efficiently packing\r\nindividual records into larger aggregated records.\r\n\r\nWhen using aggregation, you create a RecordAggregator object and then\r\nprovide a partition key, raw data and (optionally) an explicit hash key\r\nfor each record. You can choose to either provide a callback function\r\nthat will be invoked when a fully-packed aggregated record is available\r\nor you can add records and check byte sizes or number of records until\r\nthe aggregated record is suitably full. You're guaranteed that any\r\naggregated record returned from the RecordAggregator object will fit\r\nwithin a single PutRecord request to Kinesis.\r\n\r\nTo get started, import the ``aws_kinesis_agg`` module:\r\n\r\n::\r\n\r\n    import aws_kinesis_agg\r\n\r\nAs you produce records in your producer application, you will aggregate\r\nthem using the aggregation methods available in the ``aws_kinesis_agg``\r\nmodule. The ``aws_kinesis_agg`` module provides methods to do both\r\niterative aggregation and callback-based aggregation.\r\n\r\nIterative Aggregation\r\n^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe iterative aggregation method involves adding records one at a time\r\nto the RecordAggregator and checking the response to determine when a\r\nfull aggregated record is available. The ``add_user_record`` method\r\nreturns ``None`` when there is room for more records in the existing\r\naggregated record and returns an ``AggRecord`` object when a full\r\naggregated record is available for transmission.\r\n\r\n::\r\n\r\n    for rec in records:\r\n        result = kinesis_aggregator.add_user_record(rec.PartitionKey, rec.Data, rec.ExplicitHashKey)\r\n        if result:\r\n            #Send the result to Kinesis    \r\n\r\nCallback-based Aggregation\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nTo use callback-based aggregation, you must register a callback via the\r\n``on_record_complete`` method. As you add individual records to the\r\n``RecordAggregator`` object, you will receive a callback (on a separate\r\nthread) whenever a new fully-packed aggregated record is available.\r\n\r\n::\r\n\r\n    def my_callback(agg_record):\r\n        #Send the record to Kinesis\r\n       \r\n    ...\r\n\r\n    kinesis_aggregator.on_record_complete(my_callback)\r\n    for rec in records:\r\n        kinesis_aggregator.add_user_record(rec.PartitionKey, rec.Data, rec.ExplicitHashKey)\r\n\r\nExamples\r\n~~~~~~~~\r\n\r\nThis repository includes an example script that uses the record\r\naggregation module `aggregator.py <aggregator.py>`__ to aggregate\r\nrecords and transmit them to Amazon Kinesis using callback-based\r\naggregation. You can find this example functionality in the file\r\n`kinesis\\_publisher.py <src/kinesis_publisher.py>`__, which you can use\r\nas a template for your own applications to to easily build and transmit\r\nencoded data.\r\n\r\nCallback-based Aggregation and Transmission Example\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe example below assumes you are running Python version 2.7.x and also\r\nrequires you to install and configure the ``boto3`` module. You can\r\ninstall ``boto3`` via ``pip install boto3`` or any other normal Python\r\ninstall mechanism. To configure the example to be able to publish to\r\nyour Kinesis stream, make sure you follow the instructions in the `Boto3\r\nConfiguration\r\nGuide <https://boto3.readthedocs.org/en/latest/guide/configuration.html>`__.\r\nThe example below has been stripped down for brevity, but you can still\r\nfind the full working version at\r\n`kinesis\\_publisher.py <src/kinesis_publisher.py>`__. The abridged\r\nexample is:\r\n\r\n::\r\n\r\n    import boto3\r\n    import aws_kinesis_agg.aggregator\r\n        \r\n    kinesis_client = None\r\n        \r\n    def send_record(agg_record):\r\n        global kinesis_client\r\n        pk, ehk, data = agg_record.get_contents()\r\n        kinesis_client.put_record(StreamName='MyKinesisStreamName',\r\n                                      Data=data,\r\n                                      PartitionKey=pk,\r\n                                      ExplicitHashKey=ehk)\r\n        \r\n    if __name__ == '__main__':\r\n        kinesis_client = boto3.client('kinesis', region_name='us-west-2')\r\n         \r\n        kinesis_agg = aws_kinesis_agg.aggregator.RecordAggregator()\r\n        kinesis_agg.on_record_complete(send_record)\r\n        \r\n        for i in range(0,1024):\r\n            pk, ehk, data = get_record(...)\r\n            kinesis_agg.add_user_record(pk, data, ehk)\r\n        \r\n        #Clear out any remaining records that didn't trigger a callback yet\r\n        send_record(kinesis_agg.clear_and_get()) \r\n\r\nRecord Deaggregation Module (deaggregator.py)\r\n---------------------------------------------\r\n\r\nThe `deaggregator.py <deaggregator.py>`__ module contains Python classes\r\nthat allow you to deaggregate records that were transmitted using the\r\n`Kinesis Aggregated Record\r\nFormat <https://github.com/awslabs/amazon-kinesis-producer/blob/master/aggregation-format.md>`__,\r\nincluding those transmitted by the Kinesis Producer Library. This\r\nlibrary will allow you to deaggregate aggregated records in any Python\r\nenvironment, including AWS Lambda.\r\n\r\nUsage\r\n~~~~~\r\n\r\nThe record deaggregation module provides a simple interface for working\r\nwith Kinesis aggregated message data in a consumer application. The\r\n``aws_kinesis_agg`` module provides methods for both bulk and\r\ngenerator-based processing.\r\n\r\nWhen using deaggregation, you provide an aggregated Kinesis Record and\r\nget back multiple Kinesis User Records. If a Kinesis Record that is\r\nprovided is not an aggregated Kinesis record, that's perfectly fine -\r\nyou'll just get a single record output from the single record input. A\r\nKinesis user record which is returned from deaggregation looks like:\r\n\r\n::\r\n\r\n    {\r\n        'eventVersion' : String - The version number of the Kinesis event used\r\n        'eventID' : String - The unique ID of this Kinesis event\r\n        'kinesis' :\r\n        {\r\n            'partitionKey' : String - The Partition Key provided when the record was submitted\r\n            'explicitHashKey' : String - The hash value used to explicitly determine the shard the data record is assigned to by overriding the partition key hash (or None if absent) \r\n            'data' : String - The original data transmitted by the producer (base64 encoded)\r\n            'kinesisSchemaVersion' : String - The version number of the Kinesis message schema used,\r\n            'sequenceNumber' : BigInt - The sequence number assigned to the record on submission to Kinesis\r\n            'subSequenceNumber' : Int - The sub-sequence number for the User Record in the aggregated record, if aggregation was in use by the producer\r\n            'aggregated' : Boolean - Always True for a user record extracted from a Kinesis aggregated record\r\n        },\r\n        'invokeIdentityArn' : String - The ARN of the IAM user used to invoke this Lambda function\r\n        'eventName' : String - Always \"aws:kinesis:record\" for a Kinesis record\r\n        'eventSourceARN' : String - The ARN of the source Kinesis stream\r\n        'eventSource' : String - Always \"aws:kinesis\" for a Kinesis record\r\n        'awsRegion' : String - The name of the source region for the event (e.g. \"us-east-1\")\r\n    }\r\n\r\nTo get started, import the ``aws_kinesis_agg`` module:\r\n\r\n``import aws_kinesis_agg``\r\n\r\nNext, when you receive a Kinesis Record in your consumer application,\r\nyou will extract the user records using the deaggregation methods\r\navailable in the ``aws_kinesis_agg`` module.\r\n\r\n**IMPORTANT**: The deaggregation methods available in the\r\n``aws_kinesis_agg`` module expect input records in the same\r\ndictionary-based format that they are normally received in from AWS\r\nLambda. See the `Programming Model for Authoring Lambda Functions in\r\nPython <https://docs.aws.amazon.com/lambda/latest/dg/python-programming-model.html>`__\r\nsection of the AWS documentation for more details.\r\n\r\nBulk Conversion\r\n^^^^^^^^^^^^^^^\r\n\r\nThe bulk conversion method of deaggregation takes in a list of Kinesis\r\nRecords, extracts all the aggregated user records and accumulates them\r\ninto a list. Any records that are passed in to this method that are not\r\nKinesis aggregated records will be returned unchanged. The method\r\nreturns a list of Kinesis user records in the same format as they are\r\nnormally delivered by Lambda's Kinesis event handler.\r\n\r\n::\r\n\r\n    user_records = deaggregate_records(raw_kinesis_records)\r\n\r\nGenerator-based Conversion\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nThe generator-based conversion method of deaggregation uses a Python\r\n`generator function <https://wiki.python.org/moin/Generators>`__ to\r\nextract user records from a raw Kinesis Record one at a time in an\r\niterative fashion. Any records that are passed in to this method that\r\nare not Kinesis aggregated records will be returned unchanged. For\r\nexample, you could use this code to iterate through each deaggregated\r\nrecord:\r\n\r\n::\r\n\r\n    for record in iter_deaggregate_records(raw_kinesis_records):        \r\n            \r\n        #Process each record\r\n        pass \r\n\r\nExamples\r\n~~~~~~~~\r\n\r\nThis module includes two example AWS Lambda function in the file\r\n`lambda\\_function.py <src/lambda_function.py>`__ that give you the\r\nability to easily build new functions to process Kinesis aggregated data\r\nvia AWS Lambda.\r\n\r\nBulk Conversion Example\r\n^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n::\r\n\r\n    from __future__ import print_function\r\n\r\n    from aws_kinesis_agg.deaggregator import deaggregate_records\r\n    import base64\r\n\r\n    def lambda_bulk_handler(event, context):\r\n        \r\n        raw_kinesis_records = event['Records']\r\n        \r\n        #Deaggregate all records in one call\r\n        user_records = deaggregate_records(raw_kinesis_records)\r\n        \r\n        #Iterate through deaggregated records\r\n        for record in user_records:        \r\n            \r\n            # Kinesis data in Python Lambdas is base64 encoded\r\n            payload = base64.b64decode(record['kinesis']['data'])\r\n            \r\n            #TODO: Process each record\r\n        \r\n        return 'Successfully processed {} records.'.format(len(user_records))\r\n\r\nGenerator-based Conversion Example\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\n::\r\n\r\n    from __future__ import print_function\r\n\r\n    from aws_kinesis_agg.deaggregator import iter_deaggregate_records\r\n    import base64\r\n\r\n    def lambda_generator_handler(event, context):\r\n        \r\n        raw_kinesis_records = event['Records']\r\n        record_count = 0\r\n        \r\n        #Deaggregate all records using a generator function\r\n        for record in iter_deaggregate_records(raw_kinesis_records):   \r\n                 \r\n            # Kinesis data in Python Lambdas is base64 encoded\r\n            payload = base64.b64decode(record['kinesis']['data'])\r\n           \r\n            #TODO: Process each record\r\n           \r\n            record_count += 1\r\n            \r\n        return 'Successfully processed {} records.'.format(record_count)\r\n\r\nBuild & Deploy a Lambda Function to process Kinesis Records\r\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n\r\nOne easy way to get started processing Kinesis data is to use AWS\r\nLambda. By building on top of the existing\r\n`lambda\\_function.py <lambda_function.py>`__ module in this repository,\r\nyou can take advantage of Kinesis message deaggregation features without\r\nhaving to write boilerplate code.\r\n\r\nWhen you're ready to make a build and upload to AWS Lambda, you have two\r\nchoices:\r\n\r\n-  Follow the existing instructions at `Creating a Deployment Package\r\n   (Python) <https://docs.aws.amazon.com/lambda/latest/dg/lambda-python-how-to-create-deployment-package.html>`__\r\n\r\nOR\r\n\r\n-  At the root of this Python project, you can find a sample build file\r\n   called `make\\_lambda\\_build.py <make_lambda_build.py>`__. This file\r\n   is a platform-agnostic build script that will take the existing\r\n   Python project in this demo and package it in a single build file\r\n   called ``python_lambda_build.zip`` that you can upload directly to\r\n   AWS Lambda.\r\n\r\nIn order to use the build script, make sure that the python ``pip`` tool\r\nis available on your command line. If you have other ``pip``\r\ndependencies, make sure to add them to the ``PIP_DEPENDENCIES`` list at\r\nthe top of the `make\\_lambda\\_build.py <make_lambda_build.py>`__. Then\r\nrun this command:\r\n\r\n::\r\n\r\n    python make_lambda_build.py\r\n\r\nThe build script will create a new folder called ``build``, copy all the\r\nPython source files, download any necessary dependencies via ``pip`` and\r\ncreate the file ``python_lambda_build.zip`` that you can deploy to AWS\r\nLambda.\r\n\r\nImportant Build Note for AWS Lambda Users\r\n^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n\r\nIf you choose to make your own Python zip file to deploy to AWS Lambda,\r\nbe aware that the Google\r\n`protobuf <https://pypi.python.org/pypi/protobuf>`__ module normally\r\nrelies on using a Python ``pth`` setting to make the root ``google``\r\nmodule importable. If you see an error in your AWS Lambda logs such as:\r\n\r\n::\r\n\r\n    \"Unable to import module 'lambda_function': No module named google.protobuf\"\r\n\r\nYou can go into the ``google`` module folder (the same folder containing\r\nthe ``protobuf`` folder) and make an empty file called ``__init__.py``.\r\nOnce you rezip everything and redeploy, this should fix the error above.\r\n\r\n**NOTE**: If you used the provided\r\n`make\\_lambda\\_build.py <make_lambda_build.py>`__ script, this issue is\r\nalready handled for you.\r\n\r\n--------------\r\n\r\nCopyright 2014-2015 Amazon.com, Inc. or its affiliates. All Rights\r\nReserved.\r\n\r\nLicensed under the Amazon Software License (the \"License\"). You may not\r\nuse this file except in compliance with the License. A copy of the\r\nLicense is located at\r\n\r\n::\r\n\r\n    http://aws.amazon.com/asl/\r\n\r\nor in the \"license\" file accompanying this file. This file is\r\ndistributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\r\nKIND, express or implied. See the License for the specific language\r\ngoverning permissions and limitations under the License.",
    "docs_url": null,
    "download_url": "UNKNOWN",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "http://github.com/awslabs/kinesis-aggregation",
    "keywords": "aws,kinesis,aggregation,deaggregation,kpl",
    "license": "SEE LICENSE IN LICENSE.TXT",
    "maintainer": null,
    "maintainer_email": null,
    "name": "aws_kinesis_agg",
    "platform": "UNKNOWN",
    "project_url": "https://pypi.org/project/aws_kinesis_agg/",
    "release_url": "https://pypi.org/project/aws_kinesis_agg/1.0.1/",
    "requires_python": null,
    "summary": "Python module to assist in taking advantage of the Kinesis message aggregation format for both aggregation and deaggregation.",
    "version": "1.0.1"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "4e0fe5ca4a6b388ace299b084c4e7651",
          "sha256": "1bbd4e77607da5001ae27df5080e9a3cc26f0b4f5c268342655563ff328360bb"
        },
        "downloads": 2481,
        "filename": "aws_kinesis_agg-1.0.0.zip",
        "has_sig": false,
        "md5_digest": "4e0fe5ca4a6b388ace299b084c4e7651",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 30577,
        "upload_time": "2016-03-29T14:15:56",
        "url": "https://files.pythonhosted.org/packages/d6/88/1653afe42064444074ff44a5049ed6065b2b5e7a9c5c0723205cd29431e0/aws_kinesis_agg-1.0.0.zip"
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "f66745680125568a670e99690caa0df2",
          "sha256": "707618375ef1cd8b6f3434559fd52537c889708600faf857d68fac60fe2e6bd8"
        },
        "downloads": 418,
        "filename": "aws_kinesis_agg-1.0.1.zip",
        "has_sig": false,
        "md5_digest": "f66745680125568a670e99690caa0df2",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 30649,
        "upload_time": "2016-04-19T04:12:40",
        "url": "https://files.pythonhosted.org/packages/31/5e/d5ef137d6122a58cca610c0f18a5c5a3578221bae5fe67bd7bf29454f4d4/aws_kinesis_agg-1.0.1.zip"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "f66745680125568a670e99690caa0df2",
        "sha256": "707618375ef1cd8b6f3434559fd52537c889708600faf857d68fac60fe2e6bd8"
      },
      "downloads": 418,
      "filename": "aws_kinesis_agg-1.0.1.zip",
      "has_sig": false,
      "md5_digest": "f66745680125568a670e99690caa0df2",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 30649,
      "upload_time": "2016-04-19T04:12:40",
      "url": "https://files.pythonhosted.org/packages/31/5e/d5ef137d6122a58cca610c0f18a5c5a3578221bae5fe67bd7bf29454f4d4/aws_kinesis_agg-1.0.1.zip"
    }
  ]
}