{
  "info": {
    "author": "DaVinciDW",
    "author_email": "darkwings_love@163.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 2 - Pre-Alpha",
      "Environment :: Web Environment",
      "Intended Audience :: Developers",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2.6",
      "Programming Language :: Python :: 2.7",
      "Topic :: Internet",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Text Processing :: Indexing",
      "Topic :: Utilities"
    ],
    "description": "Sasila\r\n======\r\n.. image:: https://img.shields.io/badge/version-0.0.1-green.svg\r\n   :target: https://pypi.python.org/pypi/Sasila\r\n   :alt: Sasila Version\r\n\r\n.. image:: https://img.shields.io/badge/pypi-v1.4.0-green.svg\r\n   :target: https://pypi.python.org/pypi/Sasila\r\n   :alt: Wheel Status\r\n\r\nOverview\r\n========\r\nsasila is a simple spider system\r\n\r\nInstall\r\n=======\r\n\r\nThe quick way::\r\n\r\n    pip install sasila\r\n\r\nTutorial\r\n=======\r\ncar_processor.py::\r\n\r\n    #!/usr/bin/env python\r\n    # -*- coding: utf-8 -*-\r\n    from sasila.slow_system.core.request_spider import RequestSpider\r\n    from sasila.slow_system.pipeline.console_pipeline import ConsolePipeline\r\n    from sasila.slow_system.pipeline.text_pipeline import TextPipelineCar\r\n    from sasila.slow_system.processor.base_processor import BaseProcessor\r\n    from sasila.slow_system.downloader.http.spider_request import Request\r\n    from sasila.slow_system.utils.decorator import checkResponse\r\n\r\n    from bs4 import BeautifulSoup as bs\r\n    import json\r\n    import time\r\n    import sys\r\n\r\n    reload(sys)\r\n    sys.setdefaultencoding(\"utf-8\")\r\n\r\n\r\n    class Car_Processor(BaseProcessor):\r\n        spider_id = \"car_spider\"\r\n        spider_name = \"car_spider\"\r\n        allowed_domains = [\"che168.com\"]\r\n        start_requests = [Request(url=\"http://www.che168.com\", priority=0)]\r\n\r\n        @checkResponse\r\n        def process(self, response):\r\n            soup = bs(response.m_response.content, \"lxml\")\r\n            province_div_list = soup.select(\"div.city-list div.cap-city > div.fn-clear\")\r\n            for province_div in province_div_list:\r\n                province_name = province_div.select(\"span.capital a\")[0].text\r\n                city_list = province_div.select(\"div.city a\")\r\n                for city in city_list:\r\n                    city_name = city.text\r\n                    pinyin = city[\"href\"].strip(\"/\").split(\"/\")[0]\r\n                    request = Request(\r\n                            url=\"http://www.che168.com/handler/usedcarlistv5.ashx?action=brandlist&area=%s\" % pinyin,\r\n                            priority=1, callback=self.process_page_1)\r\n                    request.meta[\"province\"] = province_name\r\n                    request.meta[\"city\"] = city_name\r\n                    yield request\r\n\r\n        @checkResponse\r\n        def process_page_1(self, response):\r\n            brand_list = list(json.loads(response.m_response.content.decode(\"gb2312\")))\r\n            for brand in brand_list:\r\n                brand_dict = dict(brand)\r\n                brand_name = brand_dict[\"name\"]\r\n                url = response.nice_join(brand_dict[\"url\"]) + \"/\"\r\n                request = Request(url=url, priority=2, callback=self.process_page_2)\r\n                request.meta[\"province\"] = response.request.meta[\"province\"]\r\n                request.meta[\"city\"] = response.request.meta[\"city\"]\r\n                request.meta[\"brand\"] = brand_name\r\n                yield request\r\n\r\n        @checkResponse\r\n        def process_page_2(self, response):\r\n            soup = bs(response.m_response.content, \"lxml\")\r\n            cars_line_list = soup.select(\"div#series div.content-area dl.model-list dd a\")\r\n            for cars_line in cars_line_list:\r\n                cars_line_name = cars_line.text\r\n                url = \"http://www.che168.com\" + cars_line[\"href\"]\r\n                request = Request(url=url, priority=3, callback=self.process_page_3)\r\n                request.meta[\"province\"] = response.request.meta[\"province\"]\r\n                request.meta[\"city\"] = response.request.meta[\"city\"]\r\n                request.meta[\"brand\"] = response.request.meta[\"brand\"]\r\n                request.meta[\"cars_line\"] = cars_line_name\r\n                yield request\r\n\r\n        @checkResponse\r\n        def process_page_3(self, response):\r\n            soup = bs(response.m_response.content, \"lxml\")\r\n            car_info_list = soup.select(\"div#a2 ul#viewlist_ul li a.carinfo\")\r\n            for car_info in car_info_list:\r\n                url = \"http://www.che168.com\" + car_info[\"href\"]\r\n                request = Request(url=url, priority=4, callback=self.process_page_4)\r\n                request.meta[\"province\"] = response.request.meta[\"province\"]\r\n                request.meta[\"city\"] = response.request.meta[\"city\"]\r\n                request.meta[\"brand\"] = response.request.meta[\"brand\"]\r\n                request.meta[\"cars_line\"] = response.request.meta[\"cars_line\"]\r\n                yield request\r\n            next_page = soup.find(lambda tag: tag.name == \"a\" and \"\u4e0b\u4e00\u9875\" in tag.text)\r\n            if next_page:\r\n                url = \"http://www.che168.com\" + next_page[\"href\"]\r\n                request = Request(url=url, priority=3, callback=self.process_page_3)\r\n                request.meta[\"province\"] = response.request.meta[\"province\"]\r\n                request.meta[\"city\"] = response.request.meta[\"city\"]\r\n                request.meta[\"brand\"] = response.request.meta[\"brand\"]\r\n                request.meta[\"cars_line\"] = response.request.meta[\"cars_line\"]\r\n                yield request\r\n\r\n        @checkResponse\r\n        def process_page_4(self, response):\r\n            soup = bs(response.m_response.content, \"lxml\")\r\n            # <html><head><title>Object moved</title></head><body>\r\n            # <h2>Object moved to <a href=\"/CarDetail/wrong.aspx?errorcode=5&amp;backurl=/&amp;infoid=21415515\">here</a>.</h2>\r\n            # </body></html>\r\n            if len(soup.select(\"div.car-title h2\")) != 0:\r\n                car = soup.select(\"div.car-title h2\")[0].text\r\n                detail_list = soup.select(\"div.details li\")\r\n                if len(detail_list) == 0:\r\n                    soup = bs(response.m_response.content, \"html5lib\")\r\n                    detail_list = soup.select(\"div.details li\")\r\n                mileage = detail_list[0].select(\"span\")[0].text.replace(\"\u4e07\u516c\u91cc\", \"\")\r\n                first_borad_date = detail_list[1].select(\"span\")[0].text\r\n                gear = detail_list[2].select(\"span\")[0].text.split(\"\uff0f\")[0]\r\n                displacement = detail_list[2].select(\"span\")[0].text.split(\"\uff0f\")[1]\r\n                price = soup.select(\"div.car-price ins\")[0].text.replace(\"\uffe5\", \"\")\r\n                crawl_date = time.strftime(\"%Y-%m-%d\", time.localtime(time.time()))\r\n\r\n                item = dict()\r\n                item[\"car\"] = car\r\n                item[\"mileage\"] = mileage\r\n                item[\"first_borad_date\"] = first_borad_date\r\n                item[\"gear\"] = gear\r\n                item[\"displacement\"] = displacement\r\n                item[\"price\"] = price\r\n                item[\"crawl_date\"] = crawl_date\r\n\r\n                item[\"province\"] = response.request.meta[\"province\"]\r\n                item[\"city\"] = response.request.meta[\"city\"]\r\n                item[\"brand\"] = response.request.meta[\"brand\"]\r\n                item[\"cars_line\"] = response.request.meta[\"cars_line\"]\r\n                yield item\r\n\r\nmain.py::\r\n\r\n    #!/usr/bin/env python\r\n    # -*- coding: utf-8 -*-\r\n    from car_processor import Car_Processor\r\n    from sasila.slow_system.pipeline.console_pipeline import ConsolePipeline\r\n    from sasila.slow_system.core.request_spider import RequestSpider\r\n    from sasila.slow_system.manager import manager\r\n    import sasila\r\n\r\n    spider_car = RequestSpider(Car_Processor()).set_pipeline(ConsolePipeline())\r\n    manager.set_spider(spider_car)\r\n    sasila.start()\r\n\r\nthen start your redis and run script::\r\n\r\n    python main.py\r\n\r\nthen start your spider in your browser::\r\n\r\n    http://127.0.0.1:5000/slow_spider/start?spider_id=car_spider\r\n\r\nyou can stop spider::\r\n\r\n    http://127.0.0.1:5000/slow_spider/start?spider_id=car_spider\r\n\r\n\r\n\r\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/DarkSand/Sasila",
    "keywords": "",
    "license": "MIT License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "sasila",
    "platform": "all",
    "project_url": "https://pypi.org/project/sasila/",
    "release_url": "https://pypi.org/project/sasila/0.0.2/",
    "requires_dist": [
      "six (>=1.10.0)",
      "selenium (>=2.53.6)",
      "requests (>=2.13.0)",
      "redis (>=2.10.5)",
      "lxml (>=3.7.2)",
      "grequests (>=0.3.0)",
      "beautifulsoup4 (>=4.6.0)",
      "SQLAlchemy (>=1.1.4)",
      "Flask (>=0.11.1)"
    ],
    "requires_python": "",
    "summary": "a simple spider system",
    "version": "0.0.2"
  },
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "8755165255dc38455bbcdea7ca6a8b7b",
          "sha256": "7a5c674e74fa90cad2fbce3c7b977e89e92613f6d7daa165831255ab23be213f"
        },
        "downloads": 0,
        "filename": "sasila-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8755165255dc38455bbcdea7ca6a8b7b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 51401,
        "upload_time": "2017-07-04T08:30:04",
        "url": "https://files.pythonhosted.org/packages/c0/bc/a93c4f0ed172448d31fb8fcfc086c8f1f9b87c7cca67a281ced7dcd9a5a3/sasila-0.0.1-py2.py3-none-any.whl"
      }
    ],
    "0.0.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "c168f15d498555cc10c1be1e8354aa92",
          "sha256": "e573b672d281f00861c98948b0860b7bd4ea6448838b12a7f490bb225c289a1f"
        },
        "downloads": 0,
        "filename": "sasila-0.0.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c168f15d498555cc10c1be1e8354aa92",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 54928,
        "upload_time": "2017-07-06T01:51:42",
        "url": "https://files.pythonhosted.org/packages/8d/87/c1279f39ff1bccb7ac2cc1ad10fa982ff83c3db136d085d9635049157467/sasila-0.0.2-py2.py3-none-any.whl"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "c168f15d498555cc10c1be1e8354aa92",
        "sha256": "e573b672d281f00861c98948b0860b7bd4ea6448838b12a7f490bb225c289a1f"
      },
      "downloads": 0,
      "filename": "sasila-0.0.2-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c168f15d498555cc10c1be1e8354aa92",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 54928,
      "upload_time": "2017-07-06T01:51:42",
      "url": "https://files.pythonhosted.org/packages/8d/87/c1279f39ff1bccb7ac2cc1ad10fa982ff83c3db136d085d9635049157467/sasila-0.0.2-py2.py3-none-any.whl"
    }
  ]
}