{
  "info": {
    "author": "Lukasz Janyst",
    "author_email": "xyz@jany.st",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: Console",
      "Environment :: No Input/Output (Daemon)",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.6",
      "Topic :: Internet :: WWW/HTTP"
    ],
    "description": "\n=========\nScrapy Do\n=========\n\n.. image:: https://api.travis-ci.org/ljanyst/scrapy-do.svg?branch=master\n   :target: https://travis-ci.org/ljanyst/scrapy-do\n\n.. image:: https://coveralls.io/repos/github/ljanyst/scrapy-do/badge.svg?branch=master\n   :target: https://coveralls.io/github/ljanyst/scrapy-do?branch=master\n\n.. image:: https://img.shields.io/pypi/v/scrapy-do.svg\n   :target: https://pypi.python.org/pypi/scrapy-do\n   :alt: PyPI Version\n\n\nScrapy Do is a daemon that provides a convenient way to run `Scrapy\n<https://scrapy.org/>`_ spiders. It can either do it once - immediately; or it\ncan run them periodically, at specified time intervals. It's been inspired by\n`scrapyd <https://github.com/scrapy/scrapyd>`_ but written from scratch. For\nthe time being, it only comes with a REST API. Version 0.2.0 will come with a\ncommand line client, and version 0.3.0 will have an interactive web interface.\n\n * Homepage: `https://jany.st/scrapy-do.html <https://jany.st/scrapy-do.html>`_\n * Documentation: `https://scrapy-do.readthedocs.io/en/latest/ <https://scrapy-do.readthedocs.io/en/latest/>`_\n\n-----------\nQuick Start\n-----------\n\n* Install ``scrapy-do`` using ``pip``:\n\n  .. code-block:: console\n\n       $ pip install scrapy-do\n\n* Start the daemon in the foreground:\n\n  .. code-block:: console\n\n       $ scrapy-do -n scrapy-do\n\n* Open another terminal window, download the Scrapy's Quotesbot example and\n  create a deployable archive:\n\n  .. code-block:: console\n\n       $ git clone https://github.com/scrapy/quotesbot.git\n       $ cd quotesbot\n       $ git archive master -o quotesbot.zip --prefix=quotesbot/\n\n* Push the code to the server:\n\n  .. code-block:: console\n\n       $ curl -s http://localhost:7654/push-project.json \\\n              -F name=quotesbot \\\n              -F archive=@quotesbot.zip | jq -r\n       {\n         \"status\": \"ok\",\n         \"spiders\": [\n           \"toscrape-css\",\n           \"toscrape-xpath\"\n         ]\n       }\n\n* Schedule some jobs:\n\n  .. code-block:: console\n\n       $ curl -s http://localhost:7654/schedule-job.json \\\n              -F project=quotesbot \\\n              -F spider=toscrape-css \\\n              -F \"when=every 2 to 3 hours\" | jq -r\n       {\n         \"status\": \"ok\",\n         \"identifier\": \"04a38a03-1ce4-4077-aee1-e8275d1c20b6\"\n       }\n\n       $ curl -s http://localhost:7654/schedule-job.json \\\n              -F project=quotesbot \\\n              -F spider=toscrape-css \\\n              -F when=now | jq -r\n       {\n         \"status\": \"ok\",\n         \"identifier\": \"83d447b0-ba6e-42c5-a80f-6982b2e860cf\"\n       }\n\n* See what's going on:\n\n  .. code-block:: console\n\n       $ curl -s \"http://localhost:7654/list-jobs.json?status=ACTIVE\" | jq -r\n       {\n         \"status\": \"ok\",\n         \"jobs\": [\n           {\n             \"identifier\": \"83d447b0-ba6e-42c5-a80f-6982b2e860cf\",\n             \"status\": \"RUNNING\",\n             \"actor\": \"USER\",\n             \"schedule\": \"now\",\n             \"project\": \"quotesbot\",\n             \"spider\": \"toscrape-css\",\n             \"timestamp\": \"2017-12-10 22:33:14.853565\",\n             \"duration\": null\n           },\n           {\n             \"identifier\": \"04a38a03-1ce4-4077-aee1-e8275d1c20b6\",\n             \"status\": \"SCHEDULED\",\n             \"actor\": \"USER\",\n             \"schedule\": \"every 2 to 3 hours\",\n             \"project\": \"quotesbot\",\n             \"spider\": \"toscrape-css\",\n             \"timestamp\": \"2017-12-10 22:31:12.320832\",\n             \"duration\": null\n           }\n         ]\n       }\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://jany.st/scrapy-do.html",
    "keywords": "",
    "license": "BSD License",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-do",
    "platform": "",
    "project_url": "https://pypi.org/project/scrapy-do/",
    "release_url": "https://pypi.org/project/scrapy-do/0.1.0/",
    "requires_dist": [
      "schedule",
      "python-dateutil",
      "psutil",
      "pyOpenSSL",
      "twisted",
      "scrapy"
    ],
    "requires_python": "",
    "summary": "Spider Runner for Scrapy",
    "version": "0.1.0"
  },
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b34748d95f5503b9a1f731e8c3b2295b",
          "sha256": "d90388c240648c391b1dc4d911d158d735a487f7c3c2c82d6b3d08db353afecd"
        },
        "downloads": -1,
        "filename": "scrapy_do-0.1.0-py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "b34748d95f5503b9a1f731e8c3b2295b",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 20685,
        "upload_time": "2017-12-11T17:40:11",
        "url": "https://files.pythonhosted.org/packages/f3/3f/0a9fdcbbde07dacaccaa13f23c311e1d58808b2637b9b89d870093f79681/scrapy_do-0.1.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "0e6b6e12f968af9161b414c5dd710649",
          "sha256": "b63188f4450a304f9e78fd1899ce2053f0ca9bb631226c42f18105c27039f791"
        },
        "downloads": -1,
        "filename": "scrapy-do-0.1.0.tar.gz",
        "has_sig": true,
        "md5_digest": "0e6b6e12f968af9161b414c5dd710649",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 15531,
        "upload_time": "2017-12-11T17:40:14",
        "url": "https://files.pythonhosted.org/packages/4c/40/3337dc90bc3a35fdc54c4d590375f7589dc7b88e2c495615bc7b0f342bb3/scrapy-do-0.1.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "b34748d95f5503b9a1f731e8c3b2295b",
        "sha256": "d90388c240648c391b1dc4d911d158d735a487f7c3c2c82d6b3d08db353afecd"
      },
      "downloads": -1,
      "filename": "scrapy_do-0.1.0-py3-none-any.whl",
      "has_sig": true,
      "md5_digest": "b34748d95f5503b9a1f731e8c3b2295b",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "size": 20685,
      "upload_time": "2017-12-11T17:40:11",
      "url": "https://files.pythonhosted.org/packages/f3/3f/0a9fdcbbde07dacaccaa13f23c311e1d58808b2637b9b89d870093f79681/scrapy_do-0.1.0-py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "0e6b6e12f968af9161b414c5dd710649",
        "sha256": "b63188f4450a304f9e78fd1899ce2053f0ca9bb631226c42f18105c27039f791"
      },
      "downloads": -1,
      "filename": "scrapy-do-0.1.0.tar.gz",
      "has_sig": true,
      "md5_digest": "0e6b6e12f968af9161b414c5dd710649",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 15531,
      "upload_time": "2017-12-11T17:40:14",
      "url": "https://files.pythonhosted.org/packages/4c/40/3337dc90bc3a35fdc54c4d590375f7589dc7b88e2c495615bc7b0f342bb3/scrapy-do-0.1.0.tar.gz"
    }
  ]
}