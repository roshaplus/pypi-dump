{
  "info": {
    "author": "Kilian Batzner",
    "author_email": "info@kilians.net",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3 :: Only",
      "Topic :: Scientific/Engineering :: Artificial Intelligence"
    ],
    "description": "tensorlm\n========\n\nGenerate Shakespeare poems with 4 lines of code.\n\n<a href=\"http://www.mlowl.com/post/character-language-model-lstm-tensorflow/\" target=\"_blank\">[![showcase\nof the package]]</a>\n\nInstallation\n------------\n\n`tensorlm` is written in / for Python 3.\n\n    pip3 install tensorflow>=1.1\n    pip3 install tensorlm\n\nBasic Usage\n-----------\n\nUse the `CharLM` or `WordLM` class:\n\n``` {.python}\nimport tensorflow as tf\nfrom tensorlm import CharLM\n\nwith tf.Session() as session:\n\n    # Create a new model. You can also use WordLM\n    model = CharLM(session, \"datasets/sherlock/train.txt\", max_vocab_size=96,\n                   neurons_per_layer=100, num_layers=3, num_timesteps=15)\n\n    # Train it\n    model.train(session, max_epochs=5, max_steps=500, print_logs=True)\n\n    # Let it generate a text\n    generated = model.sample(session, \"The \", num_steps=100)\n    print(\"The \" + generated)\n```\n\nThis should output something like:\n\n    The     eee       ee      ee      ee     e e     ee      ee     e  e    e  e    e  e    e  e    e  e\n\nCommand Line Usage\n------------------\n\n**Train:**\\\n`python3 -m tensorlm.cli --train=True --level=char --train_text_path=datasets/sherlock/train.txt --max_vocab_size=96 --neurons_per_layer=100 --num_layers=3 --batch_size=10 --num_timesteps=160 --save_dir=out/model --max_epochs=300 --save_interval_hours=0.5`\n\n**Sample:**\\\n`python3 -m tensorlm.cli --sample=True --level=char --neurons_per_layer=400 --num_layers=3 --num_timesteps=160 --save_dir=out/model`\n\n**Evaluate:**\\\n`python3 -m tensorlm.cli --evaluate=True --level=char --evaluate_text_path=datasets/sherlock/valid.txt --neurons_per_layer=400 --num_layers=3 --batch_size=10 --num_timesteps=160 --save_dir=out/model`\n\nSee `python3 -m tensorlm.cli --help` for all options.\n\nAdvanced Usage\n--------------\n\n### Custom Input Data\n\nThe inputs and targets don\u2019t have to be text. `GeneratingLSTM` only\nexpects token ids, so you can use any data type for the sequences, as\nlong as you can encode the data to integer ids.\n\n``` {.python}\n# We use integer ids from 0 to 19, so the vocab size is 20. The range of ids must always start\n# at zero.\nbatch_inputs = np.array([[1, 2, 3, 4], [15, 16, 17, 18]])  # 2 batches, 4 time steps each\nbatch_targets = np.array([[2, 3, 4, 5], [16, 17, 18, 19]])\n\n# Create the model in a TensorFlow graph\nmodel = GeneratingLSTM(vocab_size=20, neurons_per_layer=10, num_layers=2, max_batch_size=2)\n\n# Initialize all defined TF Variables\nsession.run(tf.global_variables_initializer())\n\nfor _ in range(5000):\n    model.train_step(session, batch_inputs, batch_targets)\n\nsampled = model.sample_ids(session, [15], num_steps=3)\nprint(\"Sampled: \" + str(sampled))\n```\n\nThis should output something like:\n\n    Sampled: [16, 18, 19]\n\n### Custom Training, Dropout etc.\n\nUse the `GeneratingLSTM` class directly. This class is agnostic to the\ndataset type. It expects integer ids and returns integer ids.\n\n\\`\\`\\`python\\\nimport tensorflow\n\n  [showcase of the package]: http://i.cubeupload.com/8Cm5RQ.gif\n  [![showcase of the package]]: http://www.mlowl.com/post/character-language-model-lstm-tensorflow/",
    "docs_url": null,
    "download_url": "https://github.com/batzner/tensorlm/archive/v0.3.tar.gz",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/batzner/tensorlm",
    "keywords": "tensorflow,text,generation,language,model,rnn,lstm,deep,neural,char,word",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tensorlm",
    "platform": "",
    "project_url": "https://pypi.org/project/tensorlm/",
    "release_url": "https://pypi.org/project/tensorlm/0.3/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "TensorFlow wrapper for deep neural text generation on character or word level with RNNs / LSTMs",
    "version": "0.3"
  },
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "b9110589493680534c72ad0214312c5d",
          "sha256": "92efa334883fb4e7f25db52af6a144b4c331a485d9666ba6b9bda94827b5656a"
        },
        "downloads": 0,
        "filename": "tensorlm-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "b9110589493680534c72ad0214312c5d",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 22711,
        "upload_time": "2017-08-30T11:55:09",
        "url": "https://files.pythonhosted.org/packages/6e/31/9bbffe12bd459eea77d2f1886d84e31083dc48ce24429084d07dcad8ef65/tensorlm-0.1.tar.gz"
      }
    ],
    "0.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "287fd30c9547f362a0e12ad21f7b23e2",
          "sha256": "5c9bff74ccc69330d2dca34ef1df92e549436ac191f5aba1328f7d10d85b90e2"
        },
        "downloads": 0,
        "filename": "tensorlm-0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "287fd30c9547f362a0e12ad21f7b23e2",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 21703,
        "upload_time": "2017-08-30T12:06:48",
        "url": "https://files.pythonhosted.org/packages/1d/5a/7b97bf9a5e825db537ffd7a87a37ac12523c580dce604dc32fe1e526643f/tensorlm-0.2.tar.gz"
      }
    ],
    "0.3": [
      {
        "comment_text": "",
        "digests": {
          "md5": "bf4e68f29e761fcec95c85cfa4c00d1e",
          "sha256": "fe5ba4d28f3021a7223a3d5c22ebf4687ef84e7c820895ac5373212ff9366d17"
        },
        "downloads": 0,
        "filename": "tensorlm-0.3.tar.gz",
        "has_sig": false,
        "md5_digest": "bf4e68f29e761fcec95c85cfa4c00d1e",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 21808,
        "upload_time": "2017-08-30T12:10:55",
        "url": "https://files.pythonhosted.org/packages/40/10/29ad0fa9f0fde4a287aaf01f6defc6755ccfffa319ab20c33a04bd9c6ab8/tensorlm-0.3.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "bf4e68f29e761fcec95c85cfa4c00d1e",
        "sha256": "fe5ba4d28f3021a7223a3d5c22ebf4687ef84e7c820895ac5373212ff9366d17"
      },
      "downloads": 0,
      "filename": "tensorlm-0.3.tar.gz",
      "has_sig": false,
      "md5_digest": "bf4e68f29e761fcec95c85cfa4c00d1e",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 21808,
      "upload_time": "2017-08-30T12:10:55",
      "url": "https://files.pythonhosted.org/packages/40/10/29ad0fa9f0fde4a287aaf01f6defc6755ccfffa319ab20c33a04bd9c6ab8/tensorlm-0.3.tar.gz"
    }
  ]
}