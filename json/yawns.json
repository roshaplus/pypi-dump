{
  "info": {
    "author": "Alec Clowes",
    "author_email": "aclowes@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Topic :: Software Development :: Libraries :: Application Frameworks"
    ],
    "description": "YAWN: Yet Another Workflow Engine\n=================================\n\nYAWN provides a framework for executing a set of shell commands with dependencies\nin a distributed manner and on a repeating schedule. Other tools do similar things and\nare inspirations for this one; particularly Celery_ and Airflow_.\n\n.. _Celery: http://www.celeryproject.org/\n.. _Airflow: https://airflow.incubator.apache.org/\n\n.. image:: https://circleci.com/gh/aclowes/yawn/tree/master.svg?style=svg\n  :target: https://circleci.com/gh/aclowes/yawn/tree/master\n.. image:: https://codecov.io/gh/aclowes/yawn/branch/master/graph/badge.svg\n  :target: https://codecov.io/gh/aclowes/yawn\n\nPrinciples\n----------\n\nWhat is different from existing tools and why?\n\nCode separation\n  YAWN runs your commands as sub-processes, so there is no co-mingling of your python code\n  with the YAWN code. You are responsible for how your code is released and what version of your\n  code gets run.\n\nState separation\n  Environment variables are the only state that can be passed to your commands. Your application\n  should key off just a date or record ID and get more complex state from its data sources.\n\nVersioning\n  The workflow configuration and every run is versioned, so you have a complete history.\n\nBroker\n  YAWN uses Postgres to store internal state and as a message queue. Using only Postgres allows\n  for simple setup and configuration. YAWN uses the new ``SELECT ... FOR UPDATE SKIP LOCKED``\n  statement to efficiently select from the queue table.\n\nComponents\n----------\n\nWeb Servers\n  The website provides a user interface to view the workflows and tasks running within them.\n  It allows you to run an existing workflow or re-run a failed task. The web server also provides\n  a REST API to programatically create and run workflows.\n\nWorkers\n  The worker schedules and executes tasks. The worker uses ``subprocess.Popen`` to run tasks and\n  capture stdout and stderr.\n\nConcepts\n--------\n\nWorkflow\n  A set of Tasks that can depend on each other, forming what is popularly known as a directed\n  acyclic graph (DAG). Workflows can be scheduled to run on a regular basis and they are versioned\n  so they can change over time.\n\nRun\n  An instance of a workflow, manually triggered or scheduled.\n\nTask\n  A shell command that specifies the upstream tasks it depends on, the number times to retry, and a\n  timeout. The task is given environment variables configured in the workflow and run.\n\nExecution\n  A single execution of a Task's command, capturing the exit code and standard output and error.\n\nQueue\n  A first-in, first-out list of Tasks to execute.\n\nWorker\n  A process that reads from a set of Queues and executes the associated Tasks, recording the\n  results in an Execution.\n\nExamples\n--------\n\nRun ``yawn examples`` to populate two workflows into the database.\n\nHere is a screenshot of the page for a single workflow:\n\n.. image:: https://cloud.githubusercontent.com/assets/910316/21969288/fe40baf0-db51-11e6-97f2-7e6875c1e575.png\n\nREST API\n--------\n\nBrowse the API by going to http://127.0.0.1:8000/api/ in a browser.\n\nWhen creating a workflow, the format is (shown as YAML for readability)::\n\n    name: Example\n    parameters:\n      ENVIRONMENT: production\n      CALCULATION_DATE: 2017-01-01\n    schedule: 0 0 *\n    schedule_active: True\n\n    tasks:\n    - name: task_1\n      queue: default\n      max_retries: 1\n      timeout: 30\n      command: python my_awesome_program.py $ENVIRONMENT\n    - name: task_2\n      queue: default\n      command: echo $CALCULATION_DATE | grep 2017\n      upstream:\n      - task_1\n\n``/api/workflows/``\n  GET a list of versions or a single workflow version. POST to create or update a workflow\n  using the schema show above. PATCH to change the ``schedule``, ``schedule_active``, or\n  ``parameters`` fields only.\n\n  * POST - use the schema shown above\n  * PATCH ``{\"schedule_active\": false}``\n\n``/api/runs/``\n  GET a list of runs, optionally filtering to a particular workflow using ``?workflow=<id>``.\n  POST to create a new run. PATCH to change the parameters.\n\n  * POST ``{\"workflow_id\": 1, \"parameters\": null}``\n  * PATCH ``{\"parameters\": {\"ENVIRONMENT\": \"test\"}}``\n\n``/api/tasks/<id>/``\n  GET a single task from a workflow run, and its executions with their status and logging\n  information. PATCH to enqueue a task or kill a running execution.\n\n  * PATCH ``{\"enqueue\": true}``\n  * PATCH ``{\"terminate\": <execution_id>}``\n\nPython API\n----------\n\nImport and use the Django models to create your workflow::\n\n    from yawn.workflow.models import WorkflowName\n    from yawn.task.models import Template\n\n    name, _ = WorkflowName.objects.get_or_create(name='Simple Workflow Example')\n    workflow = name.new_version(parameters={'MY_OBJECT_ID': '1', 'SOME_SETTING': 'false'})\n    task1 = Template.objects.create(workflow=workflow, name='start', command='echo Starting...')\n    task2 = Template.objects.create(workflow=workflow, name='task2', command='echo Working on $MY_OBJECT_ID')\n    task2.upstream.add(task1)\n    task3 = Template.objects.create(workflow=workflow, name='task3',\n                                    command='echo Another busy thing && sleep 20')\n    task3.upstream.add(task1)\n    task4 = Template.objects.create(workflow=workflow, name='done', command='echo Finished!')\n    task4.upstream.add(task2, task3)\n\n    workflow.submit_run(parameters={'child': 'true'})\n\nAlternatively, use the serializer to give tasks as a dictionary in the format used\nby the API. This method checks if a version of the Workflow exists with the same structure,\nand will return the existing version if so::\n\n    from yawn.workflow.serializers import WorkflowSerializer\n\n    serializer = WorkflowSerializer(data=test_views.data())\n    serializer.is_valid(raise_exception=True)\n    workflow = serializer.save()\n    workflow.submit_run()\n\nContributing\n------------\n\nTo develop on YAWN, fork the repository and checkout a local copy::\n\n  git clone https://github.com/<you>/yawn\n\nInstall the backend Django_ dependencies and run its server. Your database should be at\n``postgres://localhost:5432/yawn`` by default. The ``yawn`` command is a wrapper on Django's\n``manage.py``::\n\n  pip install -e .[test]\n  createdb yawn\n  yawn migrate\n  yawn runserver\n\nInstall the frontend create-react-app_ dependencies and run its server::\n\n  cd frontend\n  yarn install\n  yarn start\n\nRun the tests::\n\n  pytest\n  yarn test\n\nLoad some examples and run the worker to process them::\n\n  yawn examples\n  yawn worker\n\nRelease the built version, test installing it::\n\n  (cd frontend/ && yarn build)\n  ./setup.py sdist upload -r https://test.pypi.org/legacy/\n  pip install -i https://testpypi.python.org/pypi yawns\n\n.. _create-react-app: https://github.com/facebookincubator/create-react-app\n.. _Django: https://airflow.incubator.apache.org/\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/aclowes/yawn",
    "keywords": "task execution subprocess dag workflow",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "yawns",
    "platform": "",
    "project_url": "https://pypi.org/project/yawns/",
    "release_url": "https://pypi.org/project/yawns/0.1.2/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Yet Another Workflow Engine, a subprocess-based DAG execution system",
    "version": "0.1.2"
  },
  "releases": {
    "0.1.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "d569c5fde74f6005a2f2255d1e81936c",
          "sha256": "a299027f36e721508c1929afd13872f0847b240f2aa1cfffce85b1bd634db30a"
        },
        "downloads": 14,
        "filename": "yawns-0.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d569c5fde74f6005a2f2255d1e81936c",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 5808,
        "upload_time": "2017-02-09T20:31:45",
        "url": "https://files.pythonhosted.org/packages/c7/a5/45ee0a1c44e78176df1d72587ba942e3bff3d3423759635776dd6d57641d/yawns-0.1.0.tar.gz"
      }
    ],
    "0.1.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0857dd2a778f6403e8546e8d3e91d85f",
          "sha256": "80d81f280f965b9da133f97b4d962dc761ad8f16a92e195f92616c736f0a43c4"
        },
        "downloads": 0,
        "filename": "yawns-0.1.2.tar.gz",
        "has_sig": false,
        "md5_digest": "0857dd2a778f6403e8546e8d3e91d85f",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 2515932,
        "upload_time": "2017-06-30T02:07:09",
        "url": "https://files.pythonhosted.org/packages/ad/1f/bf126b97db51486edd0945bc5df5d244380dac50d740255af133511c7080/yawns-0.1.2.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "0857dd2a778f6403e8546e8d3e91d85f",
        "sha256": "80d81f280f965b9da133f97b4d962dc761ad8f16a92e195f92616c736f0a43c4"
      },
      "downloads": 0,
      "filename": "yawns-0.1.2.tar.gz",
      "has_sig": false,
      "md5_digest": "0857dd2a778f6403e8546e8d3e91d85f",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 2515932,
      "upload_time": "2017-06-30T02:07:09",
      "url": "https://files.pythonhosted.org/packages/ad/1f/bf126b97db51486edd0945bc5df5d244380dac50d740255af133511c7080/yawns-0.1.2.tar.gz"
    }
  ]
}