{
  "info": {
    "author": "Wirote Aroonmanakun",
    "author_email": "awirote@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU General Public License v3 (GPLv3)",
      "Programming Language :: Python :: 3.4",
      "Topic :: Software Development :: Libraries :: Python Modules",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "Thai Language Toolkit Project\n=======================\n\nTLTK is a Python package for Thai language processing.  TLTK requires Python 3.4 or higher.\nThe project is a part of open source software provided by Chulalongkorn University.\n\n----\n\ntltk.nlp  :  project provides basic tools for Thai language processing.\n\nInput Thai texts must be in utf-8 encoding.\n\nBasic tools available are:\ntltk.nlp.word_sement(Text) : word segmentation using maximum collocation approach, e.g. word_segment('\u0e42\u0e1b\u0e23\u0e41\u0e01\u0e23\u0e21\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22') => '\u0e42\u0e1b\u0e23\u0e41\u0e01\u0e23\u0e21|\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a|\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25|\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22<s/>'\ntltk.nlp.syl_segment(Text) : syllable segmentation using 3gram statistics e.g. syl_segment('\u0e42\u0e1b\u0e23\u0e41\u0e01\u0e23\u0e21\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e30\u0e21\u0e27\u0e25\u0e1c\u0e25\u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22') => '\u0e42\u0e1b\u0e23~\u0e41\u0e01\u0e23\u0e21~\u0e2a\u0e33~\u0e2b\u0e23\u0e31\u0e1a~\u0e1b\u0e23\u0e30~\u0e21\u0e27\u0e25~\u0e1c\u0e25~\u0e20\u0e32~\u0e29\u0e32~\u0e44\u0e17\u0e22<s/>'\ntltk.nlp.word_segment_mm(Text) : another word segmentation using maximal matching approach (minimum word approach)\ntltk.nlp.spell_candidates(Word) : list of possible correct words using minimum edit distance, e.g.  spell_candidates('\u0e23\u0e31\u0e01\u0e29') => ['\u0e23\u0e31\u0e01', '\u0e17\u0e31\u0e01\u0e29', '\u0e2d\u0e31\u0e01\u0e29', '\u0e23\u0e38\u0e01\u0e29', '\u0e23\u0e31\u0e01\u0e02', '\u0e23\u0e31\u0e01\u0e29\u0e32', '\u0e23\u0e31\u0e01\u0e29\u0e4c']\n\nOther defined functions in the package:\ntltk.nlp.reset_thaidict() : clear dictionary content\ntltk.nlp.read_thaidict(DictFile) : add a new dictionary\ntltk.nlp.check_thaidict(Word) : check whether Word exists in the dictionary\n\n------\nWord segmentation is based on a maximum collocation approach described in this publication:\n\"Aroonmanakun, W. 2002. Collocation and Thai Word Segmentation. In Thanaruk Theeramunkong and Virach Sornlertlamvanich, eds. Proceedings of the Fifth Symposium on Natural Language Processing & The Fifth Oriental COCOSDA Workshop. Pathumthani: Sirindhorn International Institute of Technology. 68-75.\" (http://pioneer.chula.ac.th/~awirote/ling/SNLP2002-0051c.pdf)\n\nUse tltk.nlp.word_segment(Text) or tltk.nlp.syl_segment(Text) for segmenting Thai texts. Input text is a paragraph of Thai texts which can be mixed with English texts. Spaces in the paragraph will be marked as \"<s/>\". Word boundary is marked by \"|\". Syllable boundary is marked by \"~\". Syllables here are written syllable. One written syllable may be rponounced as two syllables, i.e. \"\u0e2a\u0e01\u0e31\u0e14\" is segemnted here as one written syllable, but it is pronounced as two syllables \"sa1-kat1\".\n\nDetermining words in a sentence is based on the dictionary and maximum collocation strength between syllables. Since many compounds and idioms, e.g. '\u0e40\u0e15\u0e32\u0e44\u0e21\u0e42\u0e04\u0e23\u0e40\u0e27\u0e1f', '\u0e44\u0e1f\u0e1f\u0e49\u0e32\u0e01\u0e23\u0e30\u0e41\u0e2a\u0e2a\u0e25\u0e31\u0e1a', '\u0e1b\u0e35\u0e07\u0e1a\u0e1b\u0e23\u0e30\u0e21\u0e32\u0e13', '\u0e2d\u0e38\u0e42\u0e21\u0e07\u0e04\u0e4c\u0e43\u0e15\u0e49\u0e14\u0e34\u0e19', '\u0e2d\u0e32\u0e2b\u0e32\u0e23\u0e08\u0e32\u0e19\u0e14\u0e48\u0e27\u0e19', '\u0e1b\u0e39\u0e19\u0e02\u0e32\u0e27\u0e1c\u0e2a\u0e21\u0e1e\u0e34\u0e40\u0e28\u0e29', '\u0e40\u0e15\u0e49\u0e19\u0e41\u0e23\u0e49\u0e07\u0e40\u0e15\u0e49\u0e19\u0e01\u0e32' etc., are included in the standard dictionary, these will likely be segmented as one word. For applications that prefer a result as smallest words (i.e. '\u0e23\u0e16','\u0e42\u0e14\u0e22\u0e2a\u0e32\u0e23' as segmented in BEST corpus), users should reset the default dictionary used in this package and reload a new dictionary containing only simple words and minimum compounds. Use \"reset_thaidict()\" to clear default dictionary content, and \"read_thaidict('DICT_FIILE')\" to load a new dictionary.\n\nThe standard dictionary used in this package has more then 85,000 entries including abbreviations and transliterations compiled from various sources. A dictionary of 8,700 proper names e.g. country names, organization names, location names, animal names, plant names, food names, ..., such as '\u0e2d\u0e38\u0e0b\u0e40\u0e1a\u0e01\u0e34\u0e2a\u0e16\u0e32\u0e19', '\u0e2a\u0e33\u0e19\u0e31\u0e01\u0e40\u0e25\u0e02\u0e32\u0e18\u0e34\u0e01\u0e32\u0e23\u0e19\u0e32\u0e22\u0e01\u0e23\u0e31\u0e10\u0e21\u0e19\u0e15\u0e23\u0e35', '\u0e27\u0e31\u0e14\u0e43\u0e2b\u0e0d\u0e48\u0e2a\u0e38\u0e27\u0e23\u0e23\u0e13\u0e32\u0e23\u0e32\u0e21', '\u0e2b\u0e19\u0e2d\u0e19\u0e40\u0e08\u0e32\u0e30\u0e25\u0e33\u0e15\u0e49\u0e19\u0e02\u0e49\u0e32\u0e27\u0e42\u0e1e\u0e14', '\u0e1b\u0e25\u0e32\u0e2b\u0e21\u0e36\u0e01\u0e01\u0e23\u0e30\u0e40\u0e17\u0e35\u0e22\u0e21\u0e1e\u0e23\u0e34\u0e01\u0e44\u0e17\u0e22', are also added as a list of words in the system.\n\nFor segmenting a specific domain text, a specialized dicionary can be used by adding more dictionary before segmenting texts. This can be done simply by calling read_thaidict(\"SPECIALIZED_DICT\")\n\nA dictionary is a text file with \"iso-8859-11\" encoding in the format of one word per one line.\n\n*** Module \"spell_candidates\" is modified from Peter Norvig's Python codes at http://norvig.com/spell-correct.html ***\n\n\n------\nMore basic tools will be added in the future, e.g. \n#### tltk.nlp.transcribe(ThaiText)  =>  IPA\n#### tltk.nlp.romanize(ThaiText)  => romanization\n#### tltk.nlp.pronounce(ThaiWord)  \u0e2a\u0e2b\u0e01\u0e34\u0e08 => \u0e2a\u0e30\u0e2b\u0e30\u0e01\u0e34\u0e14\n\ntltk.corpus  :   basic tools for corpus enquiry\n\n####  to be added in the future\n\ntltk.corpus.load(TNC)\nTNC.word_frequency(Word)\nTNC.word_collocate(Word,STAT)\nTNC.word_bigram(Word)  =>  [W2a, W2b, W2c, ....]\nTNC.word_trigram(Word1,Word2)  =>  [W3a, W3b, W3c, ....]\nTNC.bigram_prob(Word1,Word2)\nTNC.trigram_prob(Word1,Word2,Word3)\n\n\n\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "http://pypi.python.org/pypi/nltk/",
    "keywords": "Thai language toolkit,Thai language processing,segmentation",
    "license": "GPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "tltk",
    "platform": "",
    "project_url": "https://pypi.org/project/tltk/",
    "release_url": "https://pypi.org/project/tltk/0.1.3/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Thai Language Toolkit",
    "version": "0.1.3"
  },
  "releases": {
    "0.1.3": [
      {
        "comment_text": "",
        "digests": {
          "md5": "c54f2d83b088dae0b8dbb6bb3ab2902d",
          "sha256": "86ade5157fd207ab9f74d51afb57a5f7d6c476779a6e11e5d09a85e90d7a5000"
        },
        "downloads": 0,
        "filename": "tltk-0.1.3-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c54f2d83b088dae0b8dbb6bb3ab2902d",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 1462016,
        "upload_time": "2017-07-02T16:50:34",
        "url": "https://files.pythonhosted.org/packages/58/a5/98ec42572c38fbae0cbb4844df82a49071d4df568f09f21f9ba6194f4c80/tltk-0.1.3-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "24a42ea93f0f94d3ccb74fa16b112e93",
          "sha256": "f9446b2ee2cfdbd971e6dced05398e64c87f7dd06feeac8422e20c3ae4313177"
        },
        "downloads": 0,
        "filename": "tltk-0.1.3.tar.gz",
        "has_sig": false,
        "md5_digest": "24a42ea93f0f94d3ccb74fa16b112e93",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 1455540,
        "upload_time": "2017-07-02T16:51:06",
        "url": "https://files.pythonhosted.org/packages/f1/80/7e0f387acae8327a82273d5b1ca34fe6b00a82f7cab04a957dba0ce7b679/tltk-0.1.3.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "c54f2d83b088dae0b8dbb6bb3ab2902d",
        "sha256": "86ade5157fd207ab9f74d51afb57a5f7d6c476779a6e11e5d09a85e90d7a5000"
      },
      "downloads": 0,
      "filename": "tltk-0.1.3-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "c54f2d83b088dae0b8dbb6bb3ab2902d",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 1462016,
      "upload_time": "2017-07-02T16:50:34",
      "url": "https://files.pythonhosted.org/packages/58/a5/98ec42572c38fbae0cbb4844df82a49071d4df568f09f21f9ba6194f4c80/tltk-0.1.3-py2.py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "24a42ea93f0f94d3ccb74fa16b112e93",
        "sha256": "f9446b2ee2cfdbd971e6dced05398e64c87f7dd06feeac8422e20c3ae4313177"
      },
      "downloads": 0,
      "filename": "tltk-0.1.3.tar.gz",
      "has_sig": false,
      "md5_digest": "24a42ea93f0f94d3ccb74fa16b112e93",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 1455540,
      "upload_time": "2017-07-02T16:51:06",
      "url": "https://files.pythonhosted.org/packages/f1/80/7e0f387acae8327a82273d5b1ca34fe6b00a82f7cab04a957dba0ce7b679/tltk-0.1.3.tar.gz"
    }
  ]
}