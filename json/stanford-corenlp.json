{
  "info": {
    "author": "Stanford NLP Group",
    "author_email": "chaganty@cs.stanford.edu",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Topic :: Software Development :: Object Brokering"
    ],
    "description": "Stanford CoreNLP Python Interface\n=================================\n\nThis package contains a python interface for `Stanford CoreNLP\n<https://github.com/stanfordnlp/CoreNLP>` that contains a reference\nimplementation to interface with the `Stanford CoreNLP server\n<https://stanfordnlp.github.io/CoreNLP/corenlp-server.html>`. The\npackage also contains a base class to expose a python-based annotation\nprovider (e.g. your favorite neural NER system) to the CoreNLP\npipeline via a lightweight service.\n\n----\n\nAnnotation Server Usage\n\n::\n\n  from corenlp import CoreNLPClient\n\n  text = \"Chris wrote a simple sentence that he parsed with Stanford CoreNLP.\"\n\n  # We assume that you've defined a variable $JAVANLP_HOME\n  # that points to a Stanford CoreNLP checkout.\n  # The code below will launch StanfordCoreNLPServer in the background\n  # and communicate with the server to annotate the sentence.\n  with corenlp.CoreNLPClient(annotators=\"tokenize ssplit\".split()) as client:\n    ann = client.annotate(text)\n\n  # You can access annotations using ann.\n  sentence = ann.sentence[0]\n\n  # The corenlp.to_text function is a helper function that\n  # reconstructs a sentence from tokens.\n  assert corenlp.to_text(sentence) == text\n\n  # You can access any property within a sentence.\n  print(sentence.text)\n\n  # Likewise for tokens\n  token = sentence.token[0]\n  print(token.lemma)\n\nSee `test_client.py` and `test_protobuf.py` for more examples.\n\nAnnotation Service Usage\n\n::\n\n    import corenlp\n    from .happyfuntokenizer import Tokenizer\n\n    class HappyFunTokenizer(Tokenizer, corenlp.Annotator):\n        def __init__(self, preserve_case=False):\n            Tokenizer.__init__(self, preserve_case)\n            corenlp.Annotator.__init__(self)\n\n        @property\n        def name(self):\n            \"\"\"\n            Name of the annotator (used by CoreNLP)\n            \"\"\"\n            return \"happyfun\"\n\n        @property\n        def requires(self):\n            \"\"\"\n            Requires has to specify all the annotations required before we\n            are called.\n            \"\"\"\n            return []\n\n        @property\n        def provides(self):\n            \"\"\"\n            The set of annotations guaranteed to be provided when we are done.\n            NOTE: that these annotations are either fully qualified Java\n            class names or refer to nested classes of\n            edu.stanford.nlp.ling.CoreAnnotations (as is the case below).\n            \"\"\"\n            return [\"TextAnnotation\",\n                    \"TokensAnnotation\",\n                    \"TokenBeginAnnotation\",\n                    \"TokenEndAnnotation\",\n                    \"CharacterOffsetBeginAnnotation\",\n                    \"CharacterOffsetEndAnnotation\",\n                   ]\n\n        def annotate(self, ann):\n            \"\"\"\n            @ann: is a protobuf annotation object.\n            Actually populate @ann with tokens.\n            \"\"\"\n            buf, beg_idx, end_idx = ann.text.lower(), 0, 0\n            for i, word in enumerate(self.tokenize(ann.text)):\n                token = ann.sentencelessToken.add()\n                # These are the bare minimum required for the TokenAnnotation\n                token.word = word\n                token.tokenBeginIndex = i\n                token.tokenEndIndex = i+1\n\n                # Seek into the txt until you can find this word.\n                try:\n                    # Try to update beginning index\n                    beg_idx = buf.index(word, beg_idx)\n                except ValueError:\n                    # Give up -- this will be something random\n                    end_idx = beg_idx + len(word)\n\n                token.beginChar = beg_idx\n                token.endChar = end_idx\n\n                beg_idx, end_idx = end_idx, end_idx\n\n    annotator = HappyFunTokenizer()\n    # Calling .start() will launch the annotator as a service running on\n    # port 8432 by default.\n    annotator.start()\n\n    # annotator.properties contains all the right properties for\n    # Stanford CoreNLP to use this annotator. \n    with corenlp.CoreNLPClient(properties=annotator.properties, annotators=\"happyfun ssplit pos\".split()) as client:\n        ann = client.annotate(\"RT @ #happyfuncoding: this is a typical Twitter tweet :-)\")\n\n        tokens = [t.word for t in ann.sentence[0].token]\n        print(tokens)\n\n\nSee `test_annotator.py` for more examples.",
    "docs_url": null,
    "download_url": "UNKNOWN",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/stanfordnlp/python-corenlp",
    "keywords": "corenlp natural-language-processing nlp",
    "license": "MIT",
    "maintainer": null,
    "maintainer_email": null,
    "name": "stanford-corenlp",
    "platform": "UNKNOWN",
    "project_url": "https://pypi.org/project/stanford-corenlp/",
    "release_url": "https://pypi.org/project/stanford-corenlp/3.7.0/",
    "requires_python": null,
    "summary": "Official python interface for Stanford CoreNLP",
    "version": "3.7.0"
  },
  "releases": {
    "3.7.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "d0b4cbaad54ff343584924829a7406b2",
          "sha256": "ba633e186427fe725e40207c810eea2b40a36ba3329ecdaaebb4dc68045ba865"
        },
        "downloads": 0,
        "filename": "stanford-corenlp-3.7.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d0b4cbaad54ff343584924829a7406b2",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 12766,
        "upload_time": "2017-06-10T03:33:24",
        "url": "https://files.pythonhosted.org/packages/eb/c2/9dae16864dc322e130ce5133d47d49744dec03b538ae64ba6c583bcfb376/stanford-corenlp-3.7.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "d0b4cbaad54ff343584924829a7406b2",
        "sha256": "ba633e186427fe725e40207c810eea2b40a36ba3329ecdaaebb4dc68045ba865"
      },
      "downloads": 0,
      "filename": "stanford-corenlp-3.7.0.tar.gz",
      "has_sig": false,
      "md5_digest": "d0b4cbaad54ff343584924829a7406b2",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 12766,
      "upload_time": "2017-06-10T03:33:24",
      "url": "https://files.pythonhosted.org/packages/eb/c2/9dae16864dc322e130ce5133d47d49744dec03b538ae64ba6c583bcfb376/stanford-corenlp-3.7.0.tar.gz"
    }
  ]
}