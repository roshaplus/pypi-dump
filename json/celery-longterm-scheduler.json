{
  "info": {
    "author": "Zeit Online",
    "author_email": "zon-backend@zeit.de",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "=========================\ncelery_longterm_scheduler\n=========================\n\nSchedules celery tasks to run in the potentially far future, using a separate\nstorage backend (currently only redis is supported) in combination with a\ncronjob.\n\n\nUsage\n=====\n\n* Configure the storage by adding a setting like ``longterm_scheduler_backend =\n  'redis://localhost:6739/1'`` to your celery configuration.\n  (The storage also respects the built-in celery configuration settings\n  ``redis_socket_timeout``, ``redis_socket_connect_timeout`` and\n  ``redis_max_connections``.)\n* Configure your celery app to use a customized task class\n  ``MYCELERY = celery.Celery(task_cls=celery_longterm_scheduler.Task)``\n* Set up a cronjob to run ``celery longterm_scheduler`` (e.g. every 5 minutes)\n* Now you can schedule your tasks by calling\n  ``mytask.apply_async(args, kwargs, eta=datetime)`` as normal. This returns\n  a normal ``AsyncResult`` object, but only reading the ``.id`` is supported;\n  any other methods or properties may fail explictly or implicitly.\n* You can completely delete a scheduled job by calling\n  ``celery_longterm_scheduler.get_scheduler(MYCELERY).revoke('mytaskid')``\n  (we cannot hook into the celery built-in ``AsyncResult.revoke()``,\n  unfortunately). ``revoke()`` returns True on success and False if the given\n  task cannot be found in the storage backend (e.g. because it has already come\n  due and been executed).\n\nInstead of sending a normal job to the celery broker (with added timing\ninformation), this creates a job entry in the scheduler storage backend. The\ncronjob then periodically checks the storage for any jobs that are due, and\nonly then sends a normal celery job to the broker.\n\n\nRationale\n=========\n\nWhy not use the celery built-in ``apply_async(eta=)``? Because you cannot ever\nreally delete a pending job. ``AsyncResult('mytaskid').revoke()`` can only add\nthe task ID to the statedb, where it has to stay _forever_ so the job is\nrecognized as revoked. For jobs that are scheduled to run in 6 months time or\nlater, this would create an unmanageable, ever-growing statedb.\n\nWhy not use celerybeat? Because it is built for periodic jobs, and we need\nsingle-shot jobs. And then there's not much to gain from the celerybeat\nimplementation, especially since we want to use redis as storage (since we're\nalready using that as broker and result backend).\n\n\nImplementation\n==============\n\nRedis schema\n------------\n\ncelery_longterm_scheduler assumes that it talks to a dedicated redis database.\nIt creates an entry per scheduled job using ``SET jobid job-configuration``\n(job-configuration is serialized with JSON) and uses a single sorted set named\n``scheduled_task_id_by_time`` that contains the jobids scored by the unix\ntimestamp (UTC) when they are due.\n\n\nRun tests\n=========\n\nUsing `tox`_ and `py.test`_. Maybe install ``tox`` (e.g. via ``pip install tox``)\nand then simply run ``tox``.\n\nFor the integration tests you need to have the redis binary installed (tests\nstart `their own server`_).\n\n.. _`tox`: http://tox.readthedocs.io/\n.. _`py.test`: http://pytest.org/\n.. _`their own server`: https://pypi.python.org/pypi/testing.redis\n\n\ncelery_longterm_scheduler changes\n=================================\n\n1.0.0 (2017-09-29)\n------------------\n\n- Initial release",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "http://www.zeit.de/",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "celery-longterm-scheduler",
    "platform": "",
    "project_url": "https://pypi.org/project/celery-longterm-scheduler/",
    "release_url": "https://pypi.org/project/celery-longterm-scheduler/1.0.0/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Schedules celery tasks to run in the potentially far future",
    "version": "1.0.0"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "007eda2f87d637a2675a4d56928c2ba5",
          "sha256": "8f0e59729b59315dcc869c1c5457f1640ed22de016dc56c3f0a485a0fd96b50f"
        },
        "downloads": 0,
        "filename": "celery_longterm_scheduler-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "007eda2f87d637a2675a4d56928c2ba5",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 11307,
        "upload_time": "2017-09-29T08:16:14",
        "url": "https://files.pythonhosted.org/packages/8a/aa/5aa9dec889a25b4f9b7539af33d26a720fafb1279ddfe7275af1e9ef2abf/celery_longterm_scheduler-1.0.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "007eda2f87d637a2675a4d56928c2ba5",
        "sha256": "8f0e59729b59315dcc869c1c5457f1640ed22de016dc56c3f0a485a0fd96b50f"
      },
      "downloads": 0,
      "filename": "celery_longterm_scheduler-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "007eda2f87d637a2675a4d56928c2ba5",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 11307,
      "upload_time": "2017-09-29T08:16:14",
      "url": "https://files.pythonhosted.org/packages/8a/aa/5aa9dec889a25b4f9b7539af33d26a720fafb1279ddfe7275af1e9ef2abf/celery_longterm_scheduler-1.0.0.tar.gz"
    }
  ]
}