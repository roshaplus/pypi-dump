{
  "info": {
    "author": "BBVA",
    "author_email": "cesar.gallego@bbva.com",
    "bugtrack_url": null,
    "classifiers": [
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering :: Artificial Intelligence",
      "Topic :: Scientific/Engineering :: Information Analysis",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "|Build Status| |Coverage| |Docs|\n\nETL library\n===========\n\nThe main goal of the library is perform a Transformation over a data\nevent. Supports a variety of functions typically used on machine\nlearning and AI.\n\nDevelopment is oriented into a functional style avoiding side effects on\ntransformations. This code is inspired by parser combinator libraries;\nthat use for each function only one input (in order to chain functions)\nand two output (output or error).\n\nInstallation\n------------\n\n-  In console ``pip install data-refinery`` or ``python setup.py install`` from sources.\n\nArchitecture\n------------\n\nOn ETL library we have two kind of operations: Tuple Operations and\nField Operations.\n\nThe Tuple Operations affect a field or a group of fields. Some example\noperations are keep a field, or use several fields to spawn new one. The\nsignature of the Tuple Operation its:\n\n.. code:: python\n\n    def operation(input_value: dict, output_value: dict, error_value: dict) -> (dict, dict, dict):\n        # your code ...\n        return input_value, output_value, error_value\n\nThe Fields Operations affect the value of a field. Some example\noperations are perform a min max normalization, or perform a lineal\ncategorization. The signature of the Field Operation its:\n\n.. code:: python\n\n    def operation(input_value: dict, error_value: dict) -> (dict, dict):\n        # your code ...\n        return output_value, error_value\n\nThe Field Operation can fail, so if you need to reject the value for\nsome reason you can return it at error value.\n\nThe Tr operation represents the tree of operations on a tuple. It's a\nTree, so you can save the intermediate values and perform new operations\nfrom it. The Tr has several functions that you can use.\n\nThen\n~~~~\n\nYou can push new tuple operation with the *then* function, and will take\nplace after current operation.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n\n    def _greet(i, o, e):\n        if \"who\" in i:\n            o.update({\"greet\": f\"Hello {i['who']}\"})\n        else:\n            e.update({\"greet\": \"unknown person\"})\n        return i, o, e\n\n    def _greet2(i, o, e):\n        if \"greet\" in o:\n            o.update({\"greet\": f\"{o['greet']}???\"})\n        return i, o, e\n\n    operation = Tr(_greet).then(_greet2).apply()\n\n    (inp, res, err) = operation({\"who\": \"Tom\"})\n    # will return ({'who': 'Tom'}, {'greet': 'Hello Tom???'}, {})\n\nInit\n~~~~\n\nTr also have a *init* function to push a operation to be perform the\nfirst of all, notice that this operation will push the operation as the\nroot of all the trees that you have.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n\n    def _to_hello(i, o={}, e={}):\n        return {\"hello\": i}, o, e\n\n    def _one_tr(i, o, e):\n        o.update({\"hello\": \"Tom\"})\n        return i, o, e\n\n    operation = Tr(_one_tr).init(_to_hello).apply()\n    (inp, res, err) = operation('world')\n    # will return ({\"hello\": \"world\"}, {\"hello\": \"Tom\"}, {})\n\nApply\n~~~~~\n\nGenerate the etl function to use, until this point no operations take\nplace.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import keep\n\n    transformation = Tr(keep(fields=[\"greet\"]))\n    # must return: <datarefinery.Tr.Tr at 0x7faa601e80f0>\n    operation = transformation.apply()\n    # must return: <function datarefinery.Tr.Tr.apply.<locals>._app>\n\nPeek\n~~~~\n\nThe last function of Tr it's *peek*, allow us to execute a Tuple\nOperation without change the value, so you can access the value and keep\nusing on more operations.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n\n    def _evil(i, o, e):\n        i.update({\"bad\": \"very bad\"})\n        return i, o, e\n\n    def _one_tr(i, o, e):\n        o.update({\"hello\": \"Tom\"})\n        return i, o, e\n    operation = Tr(_one_tr).peek(_evil).apply()\n    (inp, res, err) = operation({\"hello\": \"world\"})\n    # will return ({\"hello\": \"world\"}, {\"hello\": \"Tom\"}, {})\n\nInternally we use dict to represent the event. All functions included\nexpect dict as input.\n\nStructural operations\n---------------------\n\nThe main tool of the library is Transformation class. It's a cascade\ninterface that exposes several operations. All operations will return a\ntuple with the result or the error (both dicts)\n\nWrap\n~~~~\n\nThe wrap function allow to use any one input, one output, function as a\netl function.\n\nKeep\n~~~~\n\nKeep the specified field without transform them. Every field must be\nspecified or will not be on the output.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import keep\n\n    input_value = {\"greet\": \"hello\"}\n    operation = Tr(keep(fields=[\"greet\"])).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ('{\"greet\": \"hello\"}', {\"greet\":\"hello\"}, {})\n\nTODO: add keep\\_regexp function\n\nSubstitute\n~~~~~~~~~~\n\nChange the current value of the function using the provided function.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import substitution, wrap\n\n    input_value = {\"swag\": 0}\n    operation = Tr(substitution(fields=[\"swag\"], etl_func=wrap(lambda x: x+1))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': 0}, {'swag': 1}, {})\n\nAppend\n~~~~~~\n\nExpects a function that return new dict to append in order to add\nseveral fields to the output.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import append, wrap\n\n    input_value = {\"swag\": 0}\n    operation = Tr(append(fields=[\"swag\"], etl_func=wrap(lambda x: {\"greatless\": 0, \"swag\": 1}))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': 0}, {'greatless': 0, 'swag': 1}, {})\n\nFusion\n~~~~~~\n\nPass all the specified fields into the function and put the result in\nthe target field.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import fusion, wrap\n\n    input_value = {\"swag\": \"1\", \"person\": \"Tom\"}\n    operation = Tr(fusion(fields=[\"swag\", \"person\"], target_field=\"out\", etl_func=wrap(lambda x: \" \".join(x)))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'person': 'Tom', 'swag': '1'}, {'out': '1 Tom'}, {})\n\nYou can pass new functions to the transformation. But you must choose\none of the function interfaces that we offer. If your function don't\nneed to deal with errors you can use a regular function (one input\nparameter and one output).\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import filter_tuple, wrap, keep\n\n    input_value={\"hire\": \"1\"}\n    operation = Tr(filter_tuple(fields=[\"hire\"], etl_func=wrap(lambda x: x == \"1\"))).then(keep(fields=[\"hire\"])).apply()\n    (inp, res, err) = operation(input_value)\n    # must return ({'hire': '1'}, {'hire': '1'}, {})\n\nIf your function can fail you can use a etl function and return the\nvalue or the error (but not both).\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import substitution, wrap\n\n\n    input_value = {\"greet\": \"hi\"}\n    operation = Tr(substitution(fields=[\"greet\"], etl_func=wrap(lambda x: f\"{x}!!\"))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return ({'greet': 'hi'}, {'greet': 'hi!!'}, {})\n\nAlternative\n~~~~~~~~~~~\n\nThe alternative allows you to use another Tuple Operation if the current\nTuple Operation fails.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import alternative, substitution, wrap\n\n\n    def _fail_etl_func(i, e=None):\n        return None, \"nop\"\n\n    operation = Tr(alternative(\n        substitution([\"a\"], etl_func=_fail_etl_func),\n        substitution([\"b\"], etl_func=wrap(lambda x: x + 1))\n    )).apply()\n    (inp, res, err) = operation({\"a\": \"jajaja\", \"b\": 1})\n    # must return ({'a': 'jajaja', 'b': 1}, {'b': 2}, {})\n\nFusion Append\n~~~~~~~~~~~~~\n\nThe fusion append creates several fields from several fields calling\nonly one time the function.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.TupleOperations import fusion_append, wrap\n\n    operation = Tr(fusion_append(\n        fields=[\"greet\", \"who\"], error_field=\"tfus\",\n        etl_func=wrap(lambda x: {\"greet_person\": \" \".join(x), \"greet_world\": f\"{x[0]} world\"}))\n    )\\\n        .apply()\n    (inp, res, err) = operation({\"greet\": \"hello\", \"who\": \"Tom\"})\n    # must return ({'greet': 'hello', 'who': 'Tom'}, {'greet_person': 'hello Tom', 'greet_world': 'hello world'}, {})\n\nEtl Field operations\n--------------------\n\ntype\\_enforcer\n~~~~~~~~~~~~~~\n\nExpected function in order to cast the value to a type that can rise a\ncast exception.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import type_enforcer\n    from datarefinery.tuple.TupleOperations import substitution\n\n    _int_enforcer = type_enforcer(lambda x: int(x))\n\n    input_value = {\"swag\": \"1\"}\n    operation = Tr(substitution(fields=[\"swag\"], etl_func=_int_enforcer)).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': '1'}, {'swag': 1}, {})\n\nmin\\_max\\_normalization\n~~~~~~~~~~~~~~~~~~~~~~~\n\nThis function will perform the min max normalization of the value.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import min_max_normalization\n    from datarefinery.tuple.TupleOperations import substitution\n\n    input_value = {\"swag\": 25}\n    operation = Tr(substitution(fields=[\"swag\"], etl_func=min_max_normalization(0, 100))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': 25}, {'swag': 0.25}, {})\n\nstd\\_score\\_normalization\n~~~~~~~~~~~~~~~~~~~~~~~~~\n\nThis function will perform the standard score normalization of the\nvalue.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import std_score_normalization\n    from datarefinery.tuple.TupleOperations import substitution\n\n    input_value = {\"swag\": 85}\n    operation = Tr(substitution(fields=[\"swag\"], etl_func=std_score_normalization(79, 8))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': 85}, {'swag': 0.75}, {})\n\nbuckets\\_grouping\n~~~~~~~~~~~~~~~~~\n\nThis function returns a function that gives the index of the value using\na group interval by provided input.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import buckets_grouping\n    from datarefinery.tuple.TupleOperations import substitution\n\n    input_value = {\"swag\": 0.3}\n    operation = Tr(substitution(fields=[\"swag\"], etl_func=buckets_grouping(0.25, 0.5))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'swag': 0.3}, {'swag': 2}, {})\n\nlinear\\_category\n~~~~~~~~~~~~~~~~\n\nThis function returns a function that gives a categorization value,\nwhich consists in a substitution of the given value by a numeric\nrepresentation in the category supplied.\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import linear_category\n    from datarefinery.tuple.TupleOperations import substitution\n\n    input_value = {\"who\": \"anciano\"}\n    operation = Tr(substitution(fields=[\"who\"],\n        etl_func=linear_category([\"beb\u00e9\", \"ni\u00f1o\", \"joven\", \"adulto\", \"anciano\"]))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, {'who': 5}, {})\n\ncolumn\\_category\n~~~~~~~~~~~~~~~~\n\nThis function returns a function that gives a categorization value\nvectorized (see: one hot vector).\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.FieldOperations import column_category\n    from datarefinery.tuple.TupleOperations import append\n\n    input_value = {\"who\": \"anciano\"}\n    operation = Tr(append(fields=[\"who\"],\n        etl_func=column_category([\"beb\u00e9\", \"ni\u00f1o\", \"joven\", \"adulto\", \"anciano\"]))).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, {'adulto': 0, 'anciano': 1, 'beb\u00e9': 0, 'joven': 0, 'ni\u00f1o': 0}, {})\n\nEtl formats\n-----------\n\nfrom\\_json\n~~~~~~~~~~\n\nConverts from dict to json\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.Formats import from_json\n    from datarefinery.tuple.TupleOperations import keep\n\n    input_value = '{\"who\": \"anciano\"}'\n    operation = Tr(keep(fields=[\"who\"])).reader(from_json).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, {'who': 'anciano'}, {})\n\nto\\_json\n~~~~~~~~\n\nConverts from json to dict\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.Formats import to_json\n    from datarefinery.tuple.TupleOperations import keep\n\n    input_value = {\"who\": \"anciano\"}\n    operation = Tr(keep(fields=[\"who\"])).then(to_json).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, '{\"who\": \"anciano\"}', {})\n\ncsv\\_to\\_map\n~~~~~~~~~~~~\n\nConverts from csv to dict\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.Formats import csv_to_map\n    from datarefinery.tuple.TupleOperations import keep\n\n    input_value = '\"anciano\"\\r\\n'\n    operation = Tr(keep(fields=[\"who\"])).reader(csv_to_map([\"who\"])).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, {'who': 'anciano'}, {})\n\nmap\\_to\\_csv\n~~~~~~~~~~~~\n\nConverts from dict to csv\n\n.. code:: python\n\n    from datarefinery.Tr import Tr\n    from datarefinery.tuple.Formats import map_to_csv\n    from datarefinery.tuple.TupleOperations import keep\n\n    input_value = {\"who\": \"anciano\"}\n    operation = Tr(keep(fields=[\"who\"])).then(map_to_csv([\"who\"])).apply()\n    (inp, res, err) = operation(input_value)\n    # must return: ({'who': 'anciano'}, '\"anciano\"\\r\\n', {})\n\nETL - TupleDSL\n--------------\n\nAll tuple functions in library are built over the low level API offered\nin TupleDSL module. Composing this functions you can express any\ntransformation over a tuple.\n\nBy example, keep on 'who' field:\n\n.. code:: python\n\n    from datarefinery.tuple.TupleDSL import compose, use_input, read_field, write_field\n\n    f = \"who\"\n    tuple_operation = compose(use_input(), read_field(f), write_field(f))\n\nuse\\_input\n~~~~~~~~~~\n\nConnects the three parameters API to the two parameters API of Field\nOperations. Discarding the output.\n\nuse\\_output\n~~~~~~~~~~~\n\nConnects the three parameters API to the two parameters API of Field\nOperations. Discarding the input.\n\nread\\_field\n~~~~~~~~~~~\n\nBuilt a function that reads the specific field: tuple[field]\n\nwrite\\_field\n~~~~~~~~~~~~\n\nBuilt a function that writes the specific field: {field: value}\n\nread\\_match\n~~~~~~~~~~~\n\nRead all fields that fit on the supplied regular expression.\n\nread\\_fields\n~~~~~~~~~~~~\n\nRead all fields that you pass as parameters and built a function that\nreturns a list keeping the given order.\n\nwrite\\_error\\_field\n~~~~~~~~~~~~~~~~~~~\n\nIf any error is supplied then write the field as write\\_field: {field:\nerror}\n\ndict\\_enforcer\n~~~~~~~~~~~~~~\n\nIf any value different than a dict is supplied then will turn it into an\nerror.\n\napply\\_over\\_output\n~~~~~~~~~~~~~~~~~~~\n\nUpdate the output with the given dict.\n\ncompose\n~~~~~~~\n\nBuilt a new function using sequentially the functions supplied. Keep in\nmind that inputs and outputs must match.\n\n.. |Build Status| image:: https://travis-ci.org/laetitiae/data-refinery.svg\n   :target: https://travis-ci.org/laetitiae/data-refinery\n.. |Coverage| image:: https://codecov.io/gh/laetitiae/data-refinery/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/laetitiae/data-refinery\n.. |Docs| image:: https://readthedocs.org/projects/data-refinery/badge/?version=latest\n   :target: http://data-refinery.readthedocs.io/?badge=latest\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/laetitiae/data-refinery",
    "keywords": "",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "data-refinery",
    "platform": "",
    "project_url": "https://pypi.org/project/data-refinery/",
    "release_url": "https://pypi.org/project/data-refinery/0.1.41/",
    "requires_dist": [],
    "requires_python": ">=3.5",
    "summary": "Data Refinery: transformating data",
    "version": "0.1.41"
  },
  "releases": {
    "0.1.39": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0e3a57b7ef77ac52ddfdf54b1696672e",
          "sha256": "4beb4932e38152ab5c9e943b3852ce72e7b08fe104e2ce24272f5491c0ebe250"
        },
        "downloads": -1,
        "filename": "data_refinery-0.1.39-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0e3a57b7ef77ac52ddfdf54b1696672e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 17901,
        "upload_time": "2017-11-16T14:31:46",
        "url": "https://files.pythonhosted.org/packages/ce/7b/26bbf0d955047682d4b0d68cf482428f2341e58d9953ac6146c7b9af7720/data_refinery-0.1.39-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "1d668cf326d59dbcd954509345d122b3",
          "sha256": "20ae5ba4bc557649ff9bf9e1241f64ae52308dc0acb7f93b33db45ebe21f141a"
        },
        "downloads": -1,
        "filename": "data-refinery-0.1.39.tar.gz",
        "has_sig": false,
        "md5_digest": "1d668cf326d59dbcd954509345d122b3",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 14742,
        "upload_time": "2017-11-16T14:31:48",
        "url": "https://files.pythonhosted.org/packages/2c/ac/56379abb113c22b8d0e922e773553c2d466203784df7d714a07286bfea38/data-refinery-0.1.39.tar.gz"
      }
    ],
    "0.1.40": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0e36d36accfed48d55891895313d50b6",
          "sha256": "fa5bcc1047419fdc83255321ec9b1e27db0c9facbe0d743243de2f1c2203a235"
        },
        "downloads": -1,
        "filename": "data_refinery-0.1.40-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0e36d36accfed48d55891895313d50b6",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 17898,
        "upload_time": "2017-11-16T14:37:34",
        "url": "https://files.pythonhosted.org/packages/9a/aa/e85245f22d97a3df409cfa06e7538bf5814b4695c066fe2fc65d46a8b033/data_refinery-0.1.40-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "c1642dd6267a695008b233fc3b11d379",
          "sha256": "b01d5e1da6216f53a6006c3faf25914e8f86b038238b66bf4f152e8eed13cdd7"
        },
        "downloads": -1,
        "filename": "data_refinery-0.1.40-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "c1642dd6267a695008b233fc3b11d379",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 17893,
        "upload_time": "2017-11-17T12:36:36",
        "url": "https://files.pythonhosted.org/packages/5e/6f/7edbfbc3824f3c6e67a80dea7ae6eb72866de0d6641ff0c2708b959ae800/data_refinery-0.1.40-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "cb456a1ef773fe84c4d7c9f373075c1e",
          "sha256": "d80a02a13f91b9f0948f1ebc8fb4a7d93452d9d0d28a5cbc25a2933f84dbd68f"
        },
        "downloads": -1,
        "filename": "data-refinery-0.1.40.tar.gz",
        "has_sig": false,
        "md5_digest": "cb456a1ef773fe84c4d7c9f373075c1e",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 14744,
        "upload_time": "2017-11-16T14:37:36",
        "url": "https://files.pythonhosted.org/packages/e1/da/e5943d94a24ad1595cc897b16ed7e3b60b388339f6df210edce6ebeea6cf/data-refinery-0.1.40.tar.gz"
      }
    ],
    "0.1.41": [
      {
        "comment_text": "",
        "digests": {
          "md5": "74e236b61bc499ca47b687d81bc2c825",
          "sha256": "3cd76202d4768dc00597bdba8c8e2091365a8ac128b13b94f4c03f97b559a64d"
        },
        "downloads": -1,
        "filename": "data_refinery-0.1.41-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "74e236b61bc499ca47b687d81bc2c825",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 17899,
        "upload_time": "2017-11-16T15:48:01",
        "url": "https://files.pythonhosted.org/packages/6c/97/39add7e21ac67cc9af81019dc5a884c413df9349a980bebd542e4fbb8b19/data_refinery-0.1.41-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "4c186065aceeffa687a72d9808294ae0",
          "sha256": "660fc8fa4fffa2067935c2dfdb297a8e46a04f3a5fa2f409858e70bb5795b5fd"
        },
        "downloads": -1,
        "filename": "data_refinery-0.1.41-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "4c186065aceeffa687a72d9808294ae0",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 17892,
        "upload_time": "2017-11-17T12:36:37",
        "url": "https://files.pythonhosted.org/packages/4f/6f/49920b72f54277f7d54ce73f17bacc26a99fa1d92a5586d102e9caf4482e/data_refinery-0.1.41-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "34d34b41ceb8a6b392110e1f53cb339c",
          "sha256": "8a63c620a7061ca1b1f0d8cd4bef9c207195f5e396bb5bbac4d0a224ac39d8b2"
        },
        "downloads": -1,
        "filename": "data-refinery-0.1.41.tar.gz",
        "has_sig": false,
        "md5_digest": "34d34b41ceb8a6b392110e1f53cb339c",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 14742,
        "upload_time": "2017-11-16T15:48:02",
        "url": "https://files.pythonhosted.org/packages/40/6e/62c14bf40b5d4abf621f84a96db664bb3a5adb5928fb600a2b3d15d56af1/data-refinery-0.1.41.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "74e236b61bc499ca47b687d81bc2c825",
        "sha256": "3cd76202d4768dc00597bdba8c8e2091365a8ac128b13b94f4c03f97b559a64d"
      },
      "downloads": -1,
      "filename": "data_refinery-0.1.41-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "74e236b61bc499ca47b687d81bc2c825",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 17899,
      "upload_time": "2017-11-16T15:48:01",
      "url": "https://files.pythonhosted.org/packages/6c/97/39add7e21ac67cc9af81019dc5a884c413df9349a980bebd542e4fbb8b19/data_refinery-0.1.41-py2.py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "4c186065aceeffa687a72d9808294ae0",
        "sha256": "660fc8fa4fffa2067935c2dfdb297a8e46a04f3a5fa2f409858e70bb5795b5fd"
      },
      "downloads": -1,
      "filename": "data_refinery-0.1.41-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "4c186065aceeffa687a72d9808294ae0",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "size": 17892,
      "upload_time": "2017-11-17T12:36:37",
      "url": "https://files.pythonhosted.org/packages/4f/6f/49920b72f54277f7d54ce73f17bacc26a99fa1d92a5586d102e9caf4482e/data_refinery-0.1.41-py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "34d34b41ceb8a6b392110e1f53cb339c",
        "sha256": "8a63c620a7061ca1b1f0d8cd4bef9c207195f5e396bb5bbac4d0a224ac39d8b2"
      },
      "downloads": -1,
      "filename": "data-refinery-0.1.41.tar.gz",
      "has_sig": false,
      "md5_digest": "34d34b41ceb8a6b392110e1f53cb339c",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 14742,
      "upload_time": "2017-11-16T15:48:02",
      "url": "https://files.pythonhosted.org/packages/40/6e/62c14bf40b5d4abf621f84a96db664bb3a5adb5928fb600a2b3d15d56af1/data-refinery-0.1.41.tar.gz"
    }
  ]
}