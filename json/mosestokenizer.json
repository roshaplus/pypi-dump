{
  "info": {
    "author": "Lu\u00eds Gomes",
    "author_email": "luismsgomes@gmail.com",
    "bugtrack_url": "",
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU Lesser General Public License v2 or later (LGPLv2+)",
      "Programming Language :: Python :: 3.5",
      "Topic :: Text Processing :: Linguistic"
    ],
    "description": "mosestokenizer\r\n==============\r\n\r\nThis package provides wrappers for some pre-processing Perl scripts from the\r\nMoses toolkit, namely, ``normalize-punctuation.perl``, ``tokenizer.perl``,\r\n``detokenizer.perl`` and ``split-sentences.perl``.\r\n\r\nSample Usage\r\n------------\r\n\r\nAll provided classes are importable from the package ``mosestokenizer``.\r\n\r\n    >>> from mosestokenizer import *\r\n\r\nAll classes have a constructor that takes a two-letter language code as\r\nargument (``'en'``, ``'fr'``, ``'de'``, etc) and the resulting objects\r\nare callable.\r\n\r\nWhen created, these wrapper objects launch the corresponding Perl script as a\r\nbackground process.  When the objects are no longer needed, you should call the\r\n``.close()`` method to close the background process and free system resources.\r\n\r\nThe objects also support the context manager interface.\r\nThus, if used within a ``with`` block, the ``.close()`` method is invoked\r\nautomatically when the block exits.\r\n\r\nThe following two usages of ``MosesTokenizer`` are equivalent:\r\n\r\n    >>> # here we will call .close() explicitly at the end:\r\n    >>> tokenize = MosesTokenizer('en')\r\n    >>> tokenize('Hello World!')\r\n    ['Hello', 'World', '!']\r\n    >>> tokenize.close()\r\n\r\n    >>> # here we take advantage of the context manager interface:\r\n    >>> with MosesTokenizer('en') as tokenize:\r\n    >>>     tokenize('Hello World!')\r\n    ...\r\n    ['Hello', 'World', '!']\r\n\r\nAs shown above, ``MosesTokenizer`` callable objects take a string and return a\r\nlist of tokens (strings).\r\n\r\nBy contrast, ``MosesDetokenizer`` takes a list of tokens and returns a string:\r\n\r\n    >>> with MosesDetokenizer('en') as detokenize:\r\n    >>>     detokenize(['Hello', 'World', '!'])\r\n    ...\r\n    'Hello World!'\r\n\r\n``MosesSentenceSplitter`` does more than the name says.  Besides splitting\r\nsentences, it will also unwrap text, i.e. it will try to guess if a sentence\r\ncontinues in the next line or not.  It takes a list of lines (strings) and\r\nreturns a list of sentences (strings):\r\n\r\n    >>> with MosesSentenceSplitter('en') as splitsents:\r\n    >>>     splitsents([\r\n    ...         'Mr. Smith is away.  Do you want to',\r\n    ...         'leave a message?'\r\n    ...     ])\r\n    ...\r\n    ['Mr. Smith is away.', 'Do you want to leave a message?']\r\n\r\n\r\n``MosesPunctuationNormalizer`` objects take a string as argument and return a\r\nstring:\r\n\r\n    >>> with MosesPunctuationNormalizer('en') as normalize:\r\n    >>>     normalize('\u00abHello World\u00bb \u2014 she said\u2026')\r\n    ...\r\n    '\"Hello World\" - she said...'\r\n\r\n\r\nLicense\r\n-------\r\n\r\nCopyright \u00ae 2016-2017, Lu\u00eds Gomes <luismsgomes@gmail.com>.\r\n\r\nThis library is free software; you can redistribute it and/or\r\nmodify it under the terms of the GNU Lesser General Public\r\nLicense as published by the Free Software Foundation; either\r\nversion 2.1 of the License, or (at your option) any later version.\r\n\r\nThis library is distributed in the hope that it will be useful,\r\nbut WITHOUT ANY WARRANTY; without even the implied warranty of\r\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\r\nLesser General Public License for more details.\r\n\r\nYou should have received a copy of the GNU Lesser General Public\r\nLicense along with this library; if not, write to the Free Software\r\nFoundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA\r\n02110-1301  USA",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://bitbucket.org/luismsgomes/mosestokenizer",
    "keywords": "text tokenization pre-processing",
    "license": "LGPLv2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "mosestokenizer",
    "platform": "",
    "project_url": "https://pypi.org/project/mosestokenizer/",
    "release_url": "https://pypi.org/project/mosestokenizer/1.0.0/",
    "requires_python": "",
    "summary": "Wrappers for several pre-processing scripts from the Moses toolkit.",
    "version": "1.0.0"
  },
  "releases": {
    "0.3.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "449bb9b59f795fa5422fade7b60cc044",
          "sha256": "923adc38d209dd5b482dd3e2eb3baccfa9988c4d018b7ae9d3357a11de8655dc"
        },
        "downloads": 327,
        "filename": "mosestokenizer-0.3.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "449bb9b59f795fa5422fade7b60cc044",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 43996,
        "upload_time": "2016-08-17T20:25:27",
        "url": "https://files.pythonhosted.org/packages/e6/ba/5665197497573bc4d91b2dd2049f52423b86bc1e62fe78df677fd0828b33/mosestokenizer-0.3.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "6bb80ceb25946503884f0ebeceb5c519",
          "sha256": "c8d9566f3646a938e5c1321b6aba87b02613003891f55e0db08cd10db16ea6ae"
        },
        "downloads": 133,
        "filename": "mosestokenizer-0.3.0.tar.gz",
        "has_sig": false,
        "md5_digest": "6bb80ceb25946503884f0ebeceb5c519",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 31365,
        "upload_time": "2016-08-17T20:25:17",
        "url": "https://files.pythonhosted.org/packages/d7/9c/ff162aa1452ea6789d04d5bcd5d74ac777735f96d030ae0d93b8b394aedf/mosestokenizer-0.3.0.tar.gz"
      }
    ],
    "0.5.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "f82674f9d9ab736a79f10a6a88a5fc29",
          "sha256": "e050a2c4a9114f1f11043532aeb2ce091f2b8da613a3007be117d1122a2c92db"
        },
        "downloads": 0,
        "filename": "mosestokenizer-0.5.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "f82674f9d9ab736a79f10a6a88a5fc29",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 49442,
        "upload_time": "2017-05-24T09:15:36",
        "url": "https://files.pythonhosted.org/packages/bf/6a/f483e313a4a75b81edce19c2be85af7f729fece96988b188d0ff7982e343/mosestokenizer-0.5.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "bea93689fcb2b735d588edbb3101a00c",
          "sha256": "d0f541fdae06a1257d7c708a9222121c951f78991a621a6a6809a4e69fdaf32c"
        },
        "downloads": 0,
        "filename": "mosestokenizer-0.5.0.tar.gz",
        "has_sig": false,
        "md5_digest": "bea93689fcb2b735d588edbb3101a00c",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 32645,
        "upload_time": "2017-05-24T09:15:29",
        "url": "https://files.pythonhosted.org/packages/0d/b6/99817d3f595b4c37253df7c0998aaf59df3afe15298ec73aed69f65d4049/mosestokenizer-0.5.0.tar.gz"
      }
    ],
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "dd56b4ad98df0fef082caceb0f3b2a9d",
          "sha256": "4de94102c00ad21ea26c1d8327bf72d38288c6c83c9b2920fb9a86c66eddf8b7"
        },
        "downloads": 0,
        "filename": "mosestokenizer-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "dd56b4ad98df0fef082caceb0f3b2a9d",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 51182,
        "upload_time": "2017-05-24T10:29:35",
        "url": "https://files.pythonhosted.org/packages/45/c6/913c968e5cbcaff6cdd2a54a1008330c01a573ecadcdf9f526058e3d33a0/mosestokenizer-1.0.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "ab8f1fea7c23bfbc132f36aee4eb1808",
          "sha256": "2d65a781add83e93612a5e491a2cfc9c3740048b8a028556a4e23fceb1a7d48a"
        },
        "downloads": 0,
        "filename": "mosestokenizer-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ab8f1fea7c23bfbc132f36aee4eb1808",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 33749,
        "upload_time": "2017-05-24T10:29:28",
        "url": "https://files.pythonhosted.org/packages/dc/12/cdc143b9e13c3f235ff10de86a16c8074982be6b5b22be9724603bb4872a/mosestokenizer-1.0.0.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "dd56b4ad98df0fef082caceb0f3b2a9d",
        "sha256": "4de94102c00ad21ea26c1d8327bf72d38288c6c83c9b2920fb9a86c66eddf8b7"
      },
      "downloads": 0,
      "filename": "mosestokenizer-1.0.0-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "dd56b4ad98df0fef082caceb0f3b2a9d",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "size": 51182,
      "upload_time": "2017-05-24T10:29:35",
      "url": "https://files.pythonhosted.org/packages/45/c6/913c968e5cbcaff6cdd2a54a1008330c01a573ecadcdf9f526058e3d33a0/mosestokenizer-1.0.0-py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "ab8f1fea7c23bfbc132f36aee4eb1808",
        "sha256": "2d65a781add83e93612a5e491a2cfc9c3740048b8a028556a4e23fceb1a7d48a"
      },
      "downloads": 0,
      "filename": "mosestokenizer-1.0.0.tar.gz",
      "has_sig": false,
      "md5_digest": "ab8f1fea7c23bfbc132f36aee4eb1808",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 33749,
      "upload_time": "2017-05-24T10:29:28",
      "url": "https://files.pythonhosted.org/packages/dc/12/cdc143b9e13c3f235ff10de86a16c8074982be6b5b22be9724603bb4872a/mosestokenizer-1.0.0.tar.gz"
    }
  ]
}