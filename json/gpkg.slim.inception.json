{
  "info": {
    "author": "Guild AI",
    "author_email": "packages@guild.ai",
    "bugtrack_url": null,
    "classifiers": [],
    "description": "\nModels\n######\n\nslim-inception-v1\n#################\n\n*Inception v1 classifier in TF-Slim*\n\nOperations\n==========\n\nfine-tune\n^^^^^^^^^\n\n*Fine-tune Inception v1*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**checkpoint**\n  *Model checkpoint to fine-tune (inception_v1)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\ntrain\n^^^^^\n\n*Train Inception v1*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\n\nslim-inception-v2\n#################\n\n*Inception v2 classifier in TF-Slim*\n\nOperations\n==========\n\nfine-tune\n^^^^^^^^^\n\n*Fine-tune Inception v2*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**checkpoint**\n  *Model checkpoint to fine-tune (inception_v1)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\ntrain\n^^^^^\n\n*Train Inception v2*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\n\nslim-inception-v3\n#################\n\n*Inception v3 classifier in TF-Slim*\n\nOperations\n==========\n\nfine-tune\n^^^^^^^^^\n\n*Fine-tune Inception v3*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**checkpoint**\n  *Model checkpoint to fine-tune (inception_v1)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\ntrain\n^^^^^\n\n*Train Inception v3*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\n\nslim-inception-v4\n#################\n\n*Inception v4 classifier in TF-Slim*\n\nOperations\n==========\n\nfine-tune\n^^^^^^^^^\n\n*Fine-tune Inception v4*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**checkpoint**\n  *Model checkpoint to fine-tune (inception_v1)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\ntrain\n^^^^^\n\n*Train Inception v4*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\n\nslim-inception-resnet-v2\n########################\n\n*Inception Resnet v2 classifier in TF-Slim*\n\nOperations\n==========\n\nfine-tune\n^^^^^^^^^\n\n*Fine-tune Inception Resnet v2*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**checkpoint**\n  *Model checkpoint to fine-tune (inception_v1)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\ntrain\n^^^^^\n\n*Train Inception Resnet v2*\n\nFlags\n-----\n\n**batch-size**\n  *Number of samples in each batch (default is 32)*\n\n**dataset**\n  *Dataset to train with (cifar10, mnist, flowers)*\n\n**log-every-n-steps**\n  *Steps between status updates (default is 10)*\n\n**max-steps**\n  *Maximum number of training steps*\n\n**optimizer**\n  *Training optimizer (adadelta, adagrad, adam, ftrl, momentum, sgd,\n  rmsprop) (default is 'rmsprop')*\n\n**save-summaries-secs**\n  *Seconds between summary saves (default is 60)*\n\n**weight-decay**\n  *Weight decay on the model weights (default is 4e-05)*\n\n\nReferences\n##########\n\nModelfile: https://github.com/guildai/index/tree/master/slim/inception/MODELS\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/guildai/index/tree/master/slim/inception",
    "keywords": "inception resnet images model",
    "license": "Apache 2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "gpkg.slim.inception",
    "platform": "",
    "project_url": "https://pypi.org/project/gpkg.slim.inception/",
    "release_url": "https://pypi.org/project/gpkg.slim.inception/0.1.0.dev1/",
    "requires_dist": [
      "gpkg.slim.datasets"
    ],
    "requires_python": "",
    "summary": "TF-Slim Inception models (v1, v2, v3, v4, and inception-resnet v2)",
    "version": "0.1.0.dev1"
  },
  "releases": {
    "0.1.0.dev1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "377c2accbc148a308b5bbbabb7a18d0b",
          "sha256": "235783132c6626db125e092627fa32000c7561783c1d766759da0cd90a64fd62"
        },
        "downloads": -1,
        "filename": "gpkg.slim.inception-0.1.0.dev1-py2.py3-none-any.whl",
        "has_sig": true,
        "md5_digest": "377c2accbc148a308b5bbbabb7a18d0b",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 7508,
        "upload_time": "2017-11-22T21:59:43",
        "url": "https://files.pythonhosted.org/packages/16/d4/c1780284218839c949277021328e773e42cd691c5605257059e1bfbea252/gpkg.slim.inception-0.1.0.dev1-py2.py3-none-any.whl"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "377c2accbc148a308b5bbbabb7a18d0b",
        "sha256": "235783132c6626db125e092627fa32000c7561783c1d766759da0cd90a64fd62"
      },
      "downloads": -1,
      "filename": "gpkg.slim.inception-0.1.0.dev1-py2.py3-none-any.whl",
      "has_sig": true,
      "md5_digest": "377c2accbc148a308b5bbbabb7a18d0b",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 7508,
      "upload_time": "2017-11-22T21:59:43",
      "url": "https://files.pythonhosted.org/packages/16/d4/c1780284218839c949277021328e773e42cd691c5605257059e1bfbea252/gpkg.slim.inception-0.1.0.dev1-py2.py3-none-any.whl"
    }
  ]
}