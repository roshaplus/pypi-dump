{
  "info": {
    "author": "Richard Mathie",
    "author_email": "richard.mathie@cantab.net",
    "bugtrack_url": null,
    "classifiers": [
      "Environment :: Web Environment",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.6",
      "Programming Language :: Python :: 2.7"
    ],
    "description": "Redis PubSub Dict\n=================\n\nA python class for using redis, or other key value stores, as a\ndictionary and caching the values locally for read heavy workloads.\nHeavily inspired by `pylru <https://pypi.python.org/pypi/pylru>`__.\n\nUsage\n-----\n\nThe idea is that Deleting or Updating keys in an instance of\n``PubSubRedisDict`` or ``PubSubCacheManager`` will update the matching\ncached keys in all instances of ``PubSubCacheManager``.\n``PubSubCacheManager`` will therefor maintain a cache of recently used\nkeys using an ``lru`` or just a straight up ``dict()``. This will reduce\nthe round trip latency and network overhead for any reads of the cached\nkeys.\n\n``RedisDict`` and ``RedisDict`` should work with instances of\n``redis.StrictRedis`` or ``rediscluster.StrictRedisCluster``. Use the\n``prefix`` for managing redis key namespaces.\n\nRedisDict\n~~~~~~~~~\n\nJust like a normal dictionary, but networked. Initialisation wont take a\ndictionary or iterable for now as it need connection and namespace\ninformation.\n\n\\`\\`\\` rc = StrictRedisCluster(startup\\_nodes=[{\"host\": \"redis\", \"port\":\n\"6379\"}]) reddict = RedisDict(rc, 'namespace')\n\n# you can set reddict[1] = 1 reddict[2] = [1,2,3] reddict['hello'] =\n'world' reddict[('complex',1)] = {'I': {'Am': {'Quite': ['a', 'complex',\n{'object': {} }]}}}\n\n# get somewhere else reddict[1] reddict['1'] # note its the same as\nreddict[1] reddict[('complex',1)] reddict[\"('complex', 1)\"] # the key is\nstr(('complex',1))\n\n# delete del reddict[1] # .. ect \\`\\`\\`\n\nPubSubRedisDict\n~~~~~~~~~~~~~~~\n\nLike ``RedisDict`` but will publish key update and delete events to a\n``<namespace>/[update|delete]`` channel.\n\n``redpubsub = PubSubRedisDict(rc, 'namespace')   # ect as before``\n\nPubSubCacheManager\n~~~~~~~~~~~~~~~~~~\n\nLike ``pylry.WriteThroughCacheManager`` but updates cache keys from\nstore when it receives a message from the\n``<namespace>/[update|delete]`` channel.\n``cache = pylru.lrucache(10) # maybe more than 10   redstore = PubSubRedisDict(rc, 'namespace')   redcache = PubSubCacheManager(redstore, cache)   # ect as before   # see the cache   print dict(redcache.cache)``\n\nFurther uses\n~~~~~~~~~~~~\n\nYou can hook up ``RedisDict`` or ``PubSubRedisDict`` to\n``pylru.WriteBackCacheManager`` to get a Redis backed dictionary which\nonly writes to Redis on 'flush' or when the item pops off the ``lru``\nfor write intensive workloads. However a lot more work would need to be\ndone to add the pubsub mechanism as there difficult cases to consider,\nsuch as what happens when the cache is dirty and we get notified that\nthe store key is updated?\n\nLimitations\n-----------\n\n-  all keys are strings.\n-  ``msgpack`` is used to marshal objects to redis, so ``msgpack``\n   object limitations apply. Though you can monkey patch the modules\n   ``loads`` and ``dumps`` method if you like.\n-  publish will publish to all consuming dictionary instances, there is\n   no partitioning, so writes and updates are expensive. You could come\n   up with a partitioning strategy to improve this.\n-  The published items eventually end up in the watched cash. There may\n   be a time lag between a client publishing a change and the key\n   updating in another clients cache.\n\nReferences\n----------\n\n-  `redis-py <http://redis-py.readthedocs.io/>`__\n-  `redis-py-cluster <http://redis-py-cluster.readthedocs.io/>`__\n-  `pylru <https://pypi.python.org/pypi/pylru>`__",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/Richard-Mathie/py-redis-pubsub-dict",
    "keywords": "",
    "license": "GNU GPLv2",
    "maintainer": "",
    "maintainer_email": "",
    "name": "redis-pubsub-dict",
    "platform": "any",
    "project_url": "https://pypi.org/project/redis-pubsub-dict/",
    "release_url": "https://pypi.org/project/redis-pubsub-dict/0.0.1/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "A python class for using redis, or other key value stores, and caching the values for read heavy workloads",
    "version": "0.0.1"
  },
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "1310200c213b339593e998258f0af63e",
          "sha256": "a2d21a6f514807e6bf4437a778217f6f17c2937a2734250839f68ce827cabc4a"
        },
        "downloads": -1,
        "filename": "redis_pubsub_dict-0.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "1310200c213b339593e998258f0af63e",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 4764,
        "upload_time": "2018-01-11T19:18:47",
        "url": "https://files.pythonhosted.org/packages/d4/f2/f8c032602de6c40bf1eff8cff1cdfba6eb15dfe3ab66660ed769ac9e4e1b/redis_pubsub_dict-0.0.1.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "1310200c213b339593e998258f0af63e",
        "sha256": "a2d21a6f514807e6bf4437a778217f6f17c2937a2734250839f68ce827cabc4a"
      },
      "downloads": -1,
      "filename": "redis_pubsub_dict-0.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "1310200c213b339593e998258f0af63e",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 4764,
      "upload_time": "2018-01-11T19:18:47",
      "url": "https://files.pythonhosted.org/packages/d4/f2/f8c032602de6c40bf1eff8cff1cdfba6eb15dfe3ab66660ed769ac9e4e1b/redis_pubsub_dict-0.0.1.tar.gz"
    }
  ]
}