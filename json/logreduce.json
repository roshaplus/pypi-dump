{
  "info": {
    "author": "Tristan Cacqueray",
    "author_email": "tdecacqu@redhat.com",
    "bugtrack_url": null,
    "classifiers": [
      "Intended Audience :: Developers",
      "Intended Audience :: System Administrators",
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3.5",
      "Topic :: Scientific/Engineering"
    ],
    "description": "logreduce - extract anomaly from log files\n==========================================\n\nBased on success logs, logreduce highlights useful text in failed logs.\nThe goal is to assist in debugging failure and reduce effort needed to read\nboring log files.\n\nOn average, learning run at 1000 lines per second, and\ntesting run at 0.800k lines per seconds.\n\n\nHow it works\n------------\n\nlogreduce uses a *model* to learn successful logs and detect outliers in\nfailed log that doesn't fit the model. The model is constructed as follow:\n\n* Random words are manually removed using regular expression\n* Striped lines are converted into a dictionary based numeric vector\n  (using **CountVectorizer**),\n* Vector are weighted based on term frequencies times inverse\n  document-frequency (using **TfidfTransformer**),\n* Then vector are used in a unsupervised nearest neighbor learning model.\n\nThere are currently two model:\n\n* simple, using **NearestNeighbors**\n* lsfh, using **LSHForest**\n\nIn short, logreduce relies heavily on line stripping with a bag-of-words\ntechnique and it uses the distance to known sentences to detect outliers.\n\nFor example this input:\n\n.. code-block:: console\n\n  2017-06-21 04:37:45,827 INFO [nodepool.builder.UploadWorker.0] Uploading DIB image build 0000000002 from /tmpxvLOTg/fake-image-0000000002.qcow2 to fake-provider\n\nResults in:\n\n.. code-block:: console\n\n  INFO nodepool builder UploadWorker Uploading image build from /fake image fake provider\n\n\nThe tokenization makes the model a bit dependent on the target data, for example,\nto support OpenStack logs, words begining by ns- or req- are taken into account.\nFurther improvement such as characters n-gram may remove such limitation.\n\n\nCaveats\n-------\n\nThis method doesn't work when debug content is only included in failed logs.\nTo successfully detect anomalies, failed and success logs needs to be similar,\notherwise all the extra information in failed logs will be considered anomalous.\n\nThis is currently the case for tripleo ovb ci where overcloud logs are\nonly included in the failed logs, resulting in a lot of false-positive.\n\nThis also happens with testr tests where success logs only contains 'SUCCESS'.\n\n\nInstall\n-------\n\n* Fedora:\n\n.. code-block:: console\n\n  sudo dnf install -y python3-scikit-learn\n  git clone https://softwarefactory-project.io/r/logreduce\n  pushd logreduce\n  sudo python3 setup.py develop\n  popd\n\n* Pip:\n\n.. code-block:: console\n\n  pip install --user logreduce\n\n* Fetch bootstrap for nicer html output\n\n.. code-block:: console\n\n  curl -O https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css\n  curl -O https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js\n\nUsage\n-----\n\nLog files can be a single file or a directory.\n\nLogreduce needs a **--baseline** for success log training, and a **target**\nfor the log to reduce.\n\nLogreduce will print anomalies on the console, the log files are not modified.\nWhen using the text **--output-format**, anomalies are printed using this format:\n\n.. code-block:: console\n\n  # \"%(distance)f | %(log_path)s:%(line_number)d: %(log_line)s\"\n\n  $ logreduce --baseline testr-nodepool-01/output.good testr-nodepool-01/output.fail\n  [...]\n  0.232 | testr-nodepool-01/output.fail:0677:\t  File \"voluptuous/schema_builder.py\", line 370, in validate_mapping\n  0.462 | testr-nodepool-01/output.fail:0678:\t    raise er.MultipleInvalid(errors)\n  0.650 | testr-nodepool-01/output.fail:0679:\tvoluptuous.error.MultipleInvalid: required key not provided @ data['providers'][2]['cloud']\n\nThe model can be trained and saved for re-use using **--save**.\nWhen using **--load** logreduce doesn't need a **--baseline**.\n\nFull usage:\n\n.. code-block:: console\n\n  $ logreduce --help\n  usage: logreduce [-h] [--debug] [--debug-token]\n                   [--ignore-file IGNORE_FILE [IGNORE_FILE ...]]\n                   [--model {simple,lshf,noop}] [--html HTML] [--json JSON]\n                   [--save FILE] [--load FILE] [--threshold THRESHOLD]\n                   [--merge-distance MERGE_DISTANCE]\n                   [--before-context BEFORE_CONTEXT]\n                   [--after-context AFTER_CONTEXT]\n                   [--context-length CONTEXT_LENGTH] [--baseline LOG]\n                   [target [target ...]]\n\n  positional arguments:\n    target                Failed logs\n\n  optional arguments:\n    -h, --help            show this help message and exit\n    --debug               Print debug\n    --debug-token         Print tokenization process\n    --ignore-file IGNORE_FILE [IGNORE_FILE ...]\n    --model {simple,lshf,noop}\n    --html FILE           Render html result\n    --json FILE           Render json result\n    --save FILE           Save the model\n    --load FILE           Load a previous model\n    --threshold THRESHOLD\n                          Outlier distance threshold, set to 0.0 to display all\n                          log, 1.0 to only display clear anomalies\n    --merge-distance MERGE_DISTANCE\n                          Distance between chunks to merge in a continuous one\n    --before-context BEFORE_CONTEXT\n                          Amount of lines to include before the anomaly\n    --after-context AFTER_CONTEXT\n                          Amount of lines to include after the anomaly\n    --context-length CONTEXT_LENGTH\n                          Set both after and before size\n    --baseline LOG        Success logs\n\n\nSee bellow for some examples\n\n\nExamples\n--------\n\n* Look for new events in log files:\n\n.. code-block:: console\n\n  $ logreduce --baseline /var/log/audit/audit.log.4 /var/log/audit/audit.log --context-length 0\n  0.276 | /var/log/audit/audit.log:0606: type=USER_AUTH msg=audit(1498373150.931:1661763): pid=20252 uid=0 auid=1000 ses=19490 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg='op=PAM:authentication grantors=pam_rootok acct=\"root\" exe=\"/usr/bin/su\" hostname=? addr=? terminal=pts/0 res=success'\n  0.287 | /var/log/audit/audit.log:0607: type=USER_ACCT msg=audit(1498373150.931:1661764): pid=20252 uid=0 auid=1000 ses=19490 subj=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 msg='op=PAM:accounting grantors=pam_succeed_if acct=\"root\" exe=\"/usr/bin/su\" hostname=? addr=? terminal=pts/0 res=success'\n\n* Re-using a model:\n\n.. code-block:: console\n\n  $ logreduce --baseline /var/log/audit/audit.log.4 --save ~/audit.model\n  $ logreduce --load ~/audit.model /var/log/audit/audit.log\n\n\nlogreduce-tests\n---------------\n\nThis package contains tests data for different type of log such as testr\nor syslog. Each tests includes a pre-computed list of the anomalies in log\nfailures.\n\nThis package also includes a command line utility to run logreduce against all\ntests data and print a summary of its performance.\n\n\nTest format\n...........\n\nEach tests case is composed of:\n\n* A *.good* file (or directory) that holds the baseline\n* A *.fail* file (or directory)\n* A *info.yaml* file that describe expected output:\n\n.. code-block:: yaml\n\n  threshold: float # set the distance threshold for the test\n  anomalies:\n    - optional: bool  # to define minor anomalies not considered false positive\n      lines: |        # the expected lines to be highlighted\n        Traceback...\n        RuntimeError...\n\n\nEvaluate\n........\n\nTo run the evaluation, first install logreduce-tests:\n\n.. code-block:: console\n\n  git clone https://softwarefactory-project.io/r/logreduce-tests\n  pushd logreduce-tests\n  sudo python3 setup.py develop\n\nlogreduce-tests expect tests directories as argument:\n\n.. code-block:: console\n\n  $ logreduce-tests tests/testr-zuul-[0-9]*\n  [testr-zuul-01]: 100.00% accuracy,  5.00% false-positive\n  [testr-zuul-02]:  80.00% accuracy,  0.00% false-positive\n  ...\n  Summary:  90.00% accuracy,  2.50% false-positive\n\nAdd --debug to display false positive and missing chunks.\n\n\nRoadmap/todo\n------------\n\n* Support automatic log analysis and reporting when a job failed,\n  e.g. through jenkins publisher or zuul post jobs.\n* Add tarball traversal in utils.files_iterator\n* Improve tokenization tests\n* Discard files that are 100% anomalous\n* Run logreduce-test in paralelle\n* Use model bin to group line per size, e.g. <8 tokens, 8~32 tokens, >32 tokens\n\nOther ideas:\n\n* Compare logreduce performance between two versions, perhaps using logreduce\n  itself... logception!\n* Find an alternative to lshf, the model currently spend 97% of the time in the\n  lsh.kneighbors method...\n* Investigate character n-gram instead of word vectorisation\n* Investigate more advance model such as recurrent neural net, perhaps using\n  tensorflow instead of scikit-learn\n* Investigate learning failed logs to reduce common/useless failure expression\n\n\nContribute\n----------\n\nContribution are most welcome, use **git-review** to propose a change.\nSetup your ssh keys after sign in https://softwarefactory-project.io/auth/login\n\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://logreduce.softwarefactory-project.io/",
    "keywords": "machine learning,ci,anomaly detection",
    "license": "",
    "maintainer": "",
    "maintainer_email": "",
    "name": "logreduce",
    "platform": "",
    "project_url": "https://pypi.org/project/logreduce/",
    "release_url": "https://pypi.org/project/logreduce/0.0.1/",
    "requires_dist": [
      "scipy",
      "scikit-learn",
      "numpy",
      "PyYAML"
    ],
    "requires_python": "",
    "summary": "extract anomaly from log files",
    "version": "0.0.1"
  },
  "releases": {
    "0.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "6ee4588e7c42ea50cc4944272f2e165a",
          "sha256": "6d734e27f4bb4359377d648e1113e5c89f1b517bb3d1310dbf38183402e1715c"
        },
        "downloads": -1,
        "filename": "logreduce-0.0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "6ee4588e7c42ea50cc4944272f2e165a",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 24714,
        "upload_time": "2017-12-27T05:40:27",
        "url": "https://files.pythonhosted.org/packages/17/a2/d9908bad5fa277cac726476f7b132f4490ace22996c58d8166a4ac656011/logreduce-0.0.1-py2.py3-none-any.whl"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "6ee4588e7c42ea50cc4944272f2e165a",
        "sha256": "6d734e27f4bb4359377d648e1113e5c89f1b517bb3d1310dbf38183402e1715c"
      },
      "downloads": -1,
      "filename": "logreduce-0.0.1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "6ee4588e7c42ea50cc4944272f2e165a",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 24714,
      "upload_time": "2017-12-27T05:40:27",
      "url": "https://files.pythonhosted.org/packages/17/a2/d9908bad5fa277cac726476f7b132f4490ace22996c58d8166a4ac656011/logreduce-0.0.1-py2.py3-none-any.whl"
    }
  ]
}