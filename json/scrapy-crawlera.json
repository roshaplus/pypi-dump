{
  "info": {
    "author": "Raul Gallegos",
    "author_email": "raul.ogh@gmail.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 5 - Production/Stable",
      "Framework :: Scrapy",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: BSD License",
      "Operating System :: OS Independent",
      "Programming Language :: Python",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Internet :: Proxy Servers",
      "Topic :: Internet :: WWW/HTTP",
      "Topic :: Software Development :: Libraries :: Application Frameworks",
      "Topic :: Software Development :: Libraries :: Python Modules"
    ],
    "description": "===============\nscrapy-crawlera\n===============\n\n.. image:: https://img.shields.io/pypi/v/scrapy-crawlera.svg\n   :target: https://pypi.python.org/pypi/scrapy-crawlera\n   :alt: PyPI Version\n\n.. image:: https://travis-ci.org/scrapy-plugins/scrapy-crawlera.svg?branch=master\n   :target: http://travis-ci.org/scrapy-plugins/scrapy-crawlera\n   :alt: Build Status\n\n.. image:: http://codecov.io/github/scrapy-plugins/scrapy-crawlera/coverage.svg?branch=master\n   :target: http://codecov.io/github/scrapy-plugins/scrapy-crawlera?branch=master\n   :alt: Code Coverage\n\nscrapy-crawlera provides easy use of `Crawlera <http://scrapinghub.com/crawlera>`_ with Scrapy.\n\nInstallation\n============\n\nYou can install scrapy-crawlera using pip::\n\n    pip install scrapy-crawlera\n\nConfiguration\n=============\n\n* Add the Crawlera middleware including it into the ``DOWNLOADER_MIDDLEWARES`` in your ``settings.py`` file::\n\n    DOWNLOADER_MIDDLEWARES = {\n        ...\n        'scrapy_crawlera.CrawleraMiddleware': 610\n    }\n\n* Then there are two ways to enable it.\n\n  * Through ``settings.py``::\n\n      CRAWLERA_ENABLED = True\n      CRAWLERA_APIKEY = 'apikey'\n\n  * Through spider attributes::\n\n      class MySpider:\n          crawlera_enabled = True\n          crawlera_apikey = 'apikey'\n\nHow to use it\n=============\n\nWith the middleware, the usage of crawlera is automatic, every request will go through crawlera without nothing to worry about.\n\nRemember that you are now making request to Crawlera, and the Crawlera service will be the one actually making the requests to the different sites.\n\nIf you need to specify special `Crawlera Headers <https://doc.scrapinghub.com/crawlera.html#request-headers>`_, just apply them as normal `Scrapy Headers <https://doc.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request.headers>`_.\n\nHere we have an example of specifying a Crawlera header into a Scrapy request::\n\n    scrapy.Request(\n        'http://example.com',\n        headers={\n            'X-Crawlera-Max-Retries': 1,\n            ...\n        },\n    )\n\nRemember that you could also set which headers to use by default by all\nrequests with `DEFAULT_REQUEST_HEADERS <http://doc.scrapy.org/en/1.0/topics/settings.html#default-request-headers>`_\n\n\nChanges\n=======\n\nv1.2.2 (2017-01-19)\n-------------------\n\n- Fix Crawlera error stats key in Python 3.\n- Add support for Python 3.6.\n\n\nv1.2.1 (2016-10-17)\n-------------------\n\nFix release date in README.\n\n\nv1.2.0 (2016-10-17)\n-------------------\n\n- Recommend middleware order to be ``610`` to run before ``RedirectMiddleware``.\n- Change default download timeout to 190s or 3 minutes 10 seconds\n  (instead of 1800s or 30 minutes).\n- Test and advertize Python 3 compatiblity.\n- New ``crawlera/request`` and ``crawlera/request/method/*`` stats counts.\n- Clear Scrapy DNS cache for proxy URL in case of connection errors.\n- Distribute plugin as universal wheel.\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/scrapy-plugins/scrapy-crawlera",
    "keywords": "",
    "license": "BSD",
    "maintainer": "",
    "maintainer_email": "",
    "name": "scrapy-crawlera",
    "platform": "Any",
    "project_url": "https://pypi.org/project/scrapy-crawlera/",
    "release_url": "https://pypi.org/project/scrapy-crawlera/1.2.2/",
    "requires_python": "",
    "summary": "Crawlera middleware for Scrapy",
    "version": "1.2.2"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "d1199907f12370bc4d75f12ebdffc46c",
          "sha256": "8912f6f9e552291d4c0c6282cbeea561a5d1042f9a3ffacce80ee180124c40e1"
        },
        "downloads": 2151,
        "filename": "scrapy-crawlera-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "d1199907f12370bc4d75f12ebdffc46c",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 3188,
        "upload_time": "2015-04-24T20:14:03",
        "url": "https://files.pythonhosted.org/packages/7d/f5/f73a91f184bc4967da304e0cbf50e05c712a0afcab7646c7f13801f484d4/scrapy-crawlera-1.0.0.tar.gz"
      }
    ],
    "1.0.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "03fe772e3b55b45afb1b8f88d089712a",
          "sha256": "1e10618aaf209c6db0a99252ec364a3b0179a19b7a9266e1f15b54f3c5b4c847"
        },
        "downloads": 1965,
        "filename": "scrapy-crawlera-1.0.2.tar.gz",
        "has_sig": false,
        "md5_digest": "03fe772e3b55b45afb1b8f88d089712a",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 3074,
        "upload_time": "2015-05-11T23:26:33",
        "url": "https://files.pythonhosted.org/packages/b8/b4/9babb45b88feaf9c0b3caf0d227b86094bbc7cd79df4e098a58a56b9921f/scrapy-crawlera-1.0.2.tar.gz"
      }
    ],
    "1.1.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "47d792e7ac7d459a1b84ca0c37a612af",
          "sha256": "23ca51b3fb4d8e7f912ed52591fb3134cb65e088778dd38e02226dcf0bd125ed"
        },
        "downloads": 173075,
        "filename": "scrapy_crawlera-1.1.0-py2-none-any.whl",
        "has_sig": false,
        "md5_digest": "47d792e7ac7d459a1b84ca0c37a612af",
        "packagetype": "bdist_wheel",
        "python_version": "py2",
        "size": 4151,
        "upload_time": "2015-10-19T17:10:11",
        "url": "https://files.pythonhosted.org/packages/5a/22/9e8e1e98c440496d8cb9e4bfee0e7fe3d00cf2a6d26a43915b7815482b6a/scrapy_crawlera-1.1.0-py2-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "ec255d32694297b75c7b70ccd42a79b2",
          "sha256": "037a27610c592e2cab614c1332d432ba2f22f7d7cfd28bb0188815ae4950a332"
        },
        "downloads": 1246,
        "filename": "scrapy-crawlera-1.1.0.tar.gz",
        "has_sig": false,
        "md5_digest": "ec255d32694297b75c7b70ccd42a79b2",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 3339,
        "upload_time": "2015-10-19T17:10:15",
        "url": "https://files.pythonhosted.org/packages/fc/62/296b8681e3b9250bf5b9c28d4af12a18c851e76740a393f00041c60aff27/scrapy-crawlera-1.1.0.tar.gz"
      }
    ],
    "1.2.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "286456ce673c30d4c69612fba3762a98",
          "sha256": "37dcddd8019a728e96a53986f3f088bf1df97e06cb5f3cac50a26a0cd91921a5"
        },
        "downloads": 81,
        "filename": "scrapy_crawlera-1.2.0-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "286456ce673c30d4c69612fba3762a98",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 4935,
        "upload_time": "2016-10-17T16:08:07",
        "url": "https://files.pythonhosted.org/packages/25/ca/cbf4b9abd9b601e0e1d8d56142ce5c0e6fdff503559924cc8a78e8acb387/scrapy_crawlera-1.2.0-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "3563961f99c2f2d49d54a3bbcbd626ae",
          "sha256": "f6ebd97bbf17dbad6860c18a816704a8c24f09241667333148a2cb5b7b1af847"
        },
        "downloads": 81,
        "filename": "scrapy-crawlera-1.2.0.tar.gz",
        "has_sig": false,
        "md5_digest": "3563961f99c2f2d49d54a3bbcbd626ae",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 4237,
        "upload_time": "2016-10-17T16:08:09",
        "url": "https://files.pythonhosted.org/packages/e2/a8/9fe4bb74d3cbdb6493aa678e3f1c7ac7dfb7573e0e488330f200cc4f46c4/scrapy-crawlera-1.2.0.tar.gz"
      }
    ],
    "1.2.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "0c50b23f1f411857ec6d25f5c03d4f6e",
          "sha256": "39f48cfd13f5c2463f916efea13920ba842a77e07efba40d3975e8c13a7c379b"
        },
        "downloads": 134036,
        "filename": "scrapy_crawlera-1.2.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "0c50b23f1f411857ec6d25f5c03d4f6e",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 4935,
        "upload_time": "2016-10-17T16:14:56",
        "url": "https://files.pythonhosted.org/packages/39/6d/c6f630122fe502ec16d6b48e670d11061ea0e37b05f37e0045c0cd98d839/scrapy_crawlera-1.2.1-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "cd223e99444571fdef16cb7583693933",
          "sha256": "d61b2bdbbf817d863ac8163fc6fa285192b7f79e735f64cdfafd7cbfb42daafd"
        },
        "downloads": 99,
        "filename": "scrapy-crawlera-1.2.1.tar.gz",
        "has_sig": false,
        "md5_digest": "cd223e99444571fdef16cb7583693933",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 4248,
        "upload_time": "2016-10-17T16:14:58",
        "url": "https://files.pythonhosted.org/packages/55/dd/895e938479219f209de47c534b13d27c44580d35fa0addb3dd9bbded094b/scrapy-crawlera-1.2.1.tar.gz"
      }
    ],
    "1.2.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "7f4ce63664e9dd0cec4b832b139525b5",
          "sha256": "906655abfb9b750e75f7f209be4784bcdbd1af0b3685980f64754f8c0e7bb224"
        },
        "downloads": 9609,
        "filename": "scrapy_crawlera-1.2.2-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "7f4ce63664e9dd0cec4b832b139525b5",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "size": 4959,
        "upload_time": "2017-01-19T14:03:19",
        "url": "https://files.pythonhosted.org/packages/4b/75/88cd6615a76089ba22167d1b3ca4e84cfd0598d3aab4d8c32c7aa0eaf9ee/scrapy_crawlera-1.2.2-py2.py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "f2132d0d08382c80b858dbdc2d1c1be1",
          "sha256": "f095cab88977551f63f2e4f22d88d416a93ea073a2cbbf29243b2968ec1a2656"
        },
        "downloads": 5,
        "filename": "scrapy-crawlera-1.2.2.tar.gz",
        "has_sig": false,
        "md5_digest": "f2132d0d08382c80b858dbdc2d1c1be1",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 4556,
        "upload_time": "2017-01-19T14:03:21",
        "url": "https://files.pythonhosted.org/packages/1e/fb/de34db768ff6c740b25712db57a075db957d7ac89d13e3575298747bf5aa/scrapy-crawlera-1.2.2.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "7f4ce63664e9dd0cec4b832b139525b5",
        "sha256": "906655abfb9b750e75f7f209be4784bcdbd1af0b3685980f64754f8c0e7bb224"
      },
      "downloads": 9609,
      "filename": "scrapy_crawlera-1.2.2-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "7f4ce63664e9dd0cec4b832b139525b5",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "size": 4959,
      "upload_time": "2017-01-19T14:03:19",
      "url": "https://files.pythonhosted.org/packages/4b/75/88cd6615a76089ba22167d1b3ca4e84cfd0598d3aab4d8c32c7aa0eaf9ee/scrapy_crawlera-1.2.2-py2.py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "f2132d0d08382c80b858dbdc2d1c1be1",
        "sha256": "f095cab88977551f63f2e4f22d88d416a93ea073a2cbbf29243b2968ec1a2656"
      },
      "downloads": 5,
      "filename": "scrapy-crawlera-1.2.2.tar.gz",
      "has_sig": false,
      "md5_digest": "f2132d0d08382c80b858dbdc2d1c1be1",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 4556,
      "upload_time": "2017-01-19T14:03:21",
      "url": "https://files.pythonhosted.org/packages/1e/fb/de34db768ff6c740b25712db57a075db957d7ac89d13e3575298747bf5aa/scrapy-crawlera-1.2.2.tar.gz"
    }
  ]
}