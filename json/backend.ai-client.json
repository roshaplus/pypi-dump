{
  "info": {
    "author": "Lablup Inc.",
    "author_email": "joongi@lablup.com",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 4 - Beta",
      "Environment :: No Input/Output (Daemon)",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: GNU Lesser General Public License v3 or later (LGPLv3+)",
      "Operating System :: MacOS :: MacOS X",
      "Operating System :: POSIX",
      "Programming Language :: Python",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Topic :: Scientific/Engineering",
      "Topic :: Software Development"
    ],
    "description": "Backend.AI Client\n=================\n\n.. image:: https://badge.fury.io/py/backend.ai-client.svg\n   :target: https://badge.fury.io/py/backend.ai-client\n   :alt: PyPI version\n\n.. image:: https://img.shields.io/pypi/pyversions/backend.ai-client.svg\n   :target: https://pypi.org/project/backend.ai-client/\n   :alt: Python Versions\n\n.. image:: https://travis-ci.org/lablup/backend.ai-client-py.svg?branch=master\n   :target: https://travis-ci.org/lablup/backend.ai-client-py\n   :alt: Build Status (Linux)\n\n.. image:: https://ci.appveyor.com/api/projects/status/5h6r1cmbx2965yn1/branch/master?svg=true\n   :target: https://ci.appveyor.com/project/lablup/backend.ai-client-py/branch/master\n   :alt: Build Status (Windows)\n\n.. image:: https://codecov.io/gh/lablup/backend.ai-client-py/branch/master/graph/badge.svg\n   :target: https://codecov.io/gh/lablup/backend.ai-client-py\n   :alt: Code Coverage\n\nThe official API client library for `Backend.AI <https://backend.ai>`_\n\nUsage\n-----\n\nYou should set the access key and secret key as environment variables to use the API.\nGrab your keypair from `cloud.backend.ai <https://cloud.backend.ai>`_ or your cluster admin.\n\n.. code-block:: sh\n\n   export BACKEND_ACCESS_KEY=...\n   export BACKEND_SECRET_KEY=...\n\n   # optional (for local clusters)\n   export BACKEND_ENDPOINT=\"https://my-precious-cluster/\"\n\n\nCommand-line Interface\n----------------------\n\nUse ``ai.backend.client.cli`` module with ``run`` command.\n\nTo run the code specified in the command line directly,\nuse ``-c`` option to pass the code string.\n\n.. code-block:: console\n\n   $ python -m ai.backend.client.cli run python3 -c \"print('hello world')\"\n   \u2219 Client session token: d3694dda6e5a9f1e5c718e07bba291a9\n   \u2714 Kernel (ID: zuF1OzMIhFknyjUl7Apbvg) is ready.\n   hello world\n   \u2714 Cleaned up the kernel.\n\nYou can even run a C code on-the-fly. (Note that we put a dollar sign before\nthe single-quoted code argument so that the shell to interpret ``'\\n'`` as\nactual newlines.)\n\n.. code-block:: console\n\n   $ python -m ai.backend.client.cli run c -c $'#include <stdio.h>\\nint main() {printf(\"hello world\\\\n\");}'\n   \u2219 Client session token: abc06ee5e03fce60c51148c6d2dd6126\n   \u2714 Kernel (ID: d1YXvee-uAJTx4AKYyeksA) is ready.\n   hello world\n   \u2714 Cleaned up the kernel.\n\nFor larger programs, you may upload multiple files and then build & execute\nthem.  The below is a simple example to run `a sample C program\n<https://gist.github.com/achimnol/df464c6a3fe05b21e9b06d5b80e986c5>`_.\n\n.. code-block:: console\n\n   $ git clone https://gist.github.com/achimnol/df464c6a3fe05b21e9b06d5b80e986c5 c-example\n   Cloning into 'c-example'...\n   Unpacking objects: 100% (5/5), done.\n   $ cd c-example\n   $ python -m ai.backend.client.cli run c main.c mylib.c mylib.h\n   \u2219 Client session token: 1c352a572bc751a81d1f812186093c47\n   \u2714 Kernel (ID: kJ6CgWR7Tz3_v2WsDHOwLQ) is ready.\n   \u2714 Uploading done.\n   \u2714 Build finished.\n   myvalue is 42\n   your name? LABLUP\n   hello, LABLUP!\n   \u2714 Cleaned up the kernel.\n\nPlease refer the ``--help`` manual provided by the ``run`` command.\n\nYou may use a shortcut command ``lcc`` and ``lpython`` instead of typing the full\nPython module path like:\n\n.. code-block:: console\n\n   $ lcc main.c mylib.c mylib.h\n\nTo use API development tools such as GraphiQL for the admin API, run an insecure local API proxy.\nThis will attach all the necessary authorization headers to your vanilla HTTP API requests.\n\n.. code-block:: console\n\n   $ python -m ai.backend.client.cli proxy\n   \u2219 Starting an insecure API proxy at http://localhost:8084\n\n\nSynchronous API\n---------------\n\n.. code-block:: python\n\n   from ai.backend.client import Kernel\n\n   kern = Kernel.get_or_create('lua5', client_token='abc')\n   result = kern.execute('print(\"hello world\")', mode='query')\n   print(result['console'])\n   kern.destroy()\n\nYou need to take care of ``client_token`` because it determines whether to\nreuse kernel sessions or not.\nSorna cloud has a timeout so that it terminates long-idle kernel sessions,\nbut within the timeout, any kernel creation requests with the same ``client_token``\nlet Sorna cloud to reuse the kernel.\n\nAsynchronous API\n----------------\n\n.. code-block:: python\n\n   import asyncio\n   from ai.backend.client.asyncio import AsyncKernel\n\n   async def main():\n       kern = await AsyncKernel.get_or_create('lua5', client_token='abc')\n       result = await kern.execute('print(\"hello world\")', mode='query')\n       print(result['console'])\n       await kern.destroy()\n\n   loop = asyncio.get_event_loop()\n   try:\n       loop.run_until_complete(main())\n   finally:\n       loop.close()\n\nAll the methods of ``AsyncKernel`` objects are exactly same to the synchronous version,\nexcept that they are coroutines.\n\nAdditionally, ``AsyncKernel`` offers async-only method ``stream_pty()``.\nIt returns a ``StreamPty`` object which allows you to access a pseudo-tty of the kernel.\n``StreamPty`` works like an async-generator and provides methods to send stdin inputs\nas well as resize the terminal.\n\n\n",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/lablup/backend.ai-client-py",
    "keywords": "",
    "license": "LGPLv3",
    "maintainer": "",
    "maintainer_email": "",
    "name": "backend.ai-client",
    "platform": "",
    "project_url": "https://pypi.org/project/backend.ai-client/",
    "release_url": "https://pypi.org/project/backend.ai-client/1.0.1/",
    "requires_dist": [
      "flake8; extra == 'test'",
      "codecov; extra == 'test'",
      "asynctest; extra == 'test'",
      "pytest-asyncio; extra == 'test'",
      "pytest-mock; extra == 'test'",
      "pytest-cov; extra == 'test'",
      "pytest (>=3.1); extra == 'test'",
      "flake8; extra == 'dev'",
      "codecov; extra == 'dev'",
      "asynctest; extra == 'dev'",
      "pytest-asyncio; extra == 'dev'",
      "pytest-mock; extra == 'dev'",
      "pytest-cov; extra == 'dev'",
      "pytest (>=3.1); extra == 'dev'",
      "twine; extra == 'dev'",
      "wheel; extra == 'dev'",
      "flake8; extra == 'ci'",
      "codecov; extra == 'ci'",
      "asynctest; extra == 'ci'",
      "pytest-asyncio; extra == 'ci'",
      "pytest-mock; extra == 'ci'",
      "pytest-cov; extra == 'ci'",
      "pytest (>=3.1); extra == 'ci'",
      "twine; extra == 'ci'",
      "wheel; extra == 'ci'",
      "tabulate (>=0.7.7)",
      "ConfigArgParse (>=0.12.0)",
      "simplejson",
      "requests (>=2.12)",
      "python-dateutil (>=2.5)",
      "namedlist (>=1.6)",
      "async-timeout",
      "aiohttp (>=2.2)",
      "multidict",
      "colorama"
    ],
    "requires_python": ">=3.5",
    "summary": "Backend.AI API Client Library",
    "version": "1.0.1"
  },
  "releases": {
    "1.0.0": [
      {
        "comment_text": "",
        "digests": {
          "md5": "960f44649a4307e5a3dec4fe1aebdaf2",
          "sha256": "deb4d58e4c56a7f1ce12a4c09d97ddb09748792f9c57792abecda488b40e5a53"
        },
        "downloads": 0,
        "filename": "backend.ai_client-1.0.0-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "960f44649a4307e5a3dec4fe1aebdaf2",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 34796,
        "upload_time": "2017-09-20T05:45:34",
        "url": "https://files.pythonhosted.org/packages/a9/38/ecd4470d58d6262f0446e68721125353c8fe049e3f01a792813d558110b8/backend.ai_client-1.0.0-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "338ce144a150c14c6c464b620d871b32",
          "sha256": "f3e520d8d38c663521bc0b66f5f1b7910c23c26a053bdb7261201bf0e9620e22"
        },
        "downloads": 0,
        "filename": "backend.ai-client-1.0.0.tar.gz",
        "has_sig": false,
        "md5_digest": "338ce144a150c14c6c464b620d871b32",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 14982,
        "upload_time": "2017-09-20T05:45:35",
        "url": "https://files.pythonhosted.org/packages/ab/e9/a9b4e4faa6c8cc8119011bb8183f54c9f0d603ce75e2baf31c4bf47f3260/backend.ai-client-1.0.0.tar.gz"
      }
    ],
    "1.0.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "5a0d1bfbddeab7429616a1bd26b71258",
          "sha256": "fcb8e4175e83339dc32488fdede5f0752ba2fdfe405dcc49d034ee5ed3059877"
        },
        "downloads": 0,
        "filename": "backend.ai_client-1.0.1-py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "5a0d1bfbddeab7429616a1bd26b71258",
        "packagetype": "bdist_wheel",
        "python_version": "py3",
        "size": 23111,
        "upload_time": "2017-10-05T16:35:14",
        "url": "https://files.pythonhosted.org/packages/25/c0/db36b98ba48b0dc26757514533730eefb816c866e685dcf08d7a02dad8e6/backend.ai_client-1.0.1-py3-none-any.whl"
      },
      {
        "comment_text": "",
        "digests": {
          "md5": "a07820f4527a4b92010163787f94b939",
          "sha256": "983c603a362cb1145bf4a4a0b30683549bb93febf48ecfde7337e6b21bcd6460"
        },
        "downloads": 0,
        "filename": "backend.ai-client-1.0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "a07820f4527a4b92010163787f94b939",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 14869,
        "upload_time": "2017-10-05T16:35:15",
        "url": "https://files.pythonhosted.org/packages/be/84/4fb82585461a21e9739e88ce2a1e6476e60b575e0ec8205aae97cf44ef67/backend.ai-client-1.0.1.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "5a0d1bfbddeab7429616a1bd26b71258",
        "sha256": "fcb8e4175e83339dc32488fdede5f0752ba2fdfe405dcc49d034ee5ed3059877"
      },
      "downloads": 0,
      "filename": "backend.ai_client-1.0.1-py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "5a0d1bfbddeab7429616a1bd26b71258",
      "packagetype": "bdist_wheel",
      "python_version": "py3",
      "size": 23111,
      "upload_time": "2017-10-05T16:35:14",
      "url": "https://files.pythonhosted.org/packages/25/c0/db36b98ba48b0dc26757514533730eefb816c866e685dcf08d7a02dad8e6/backend.ai_client-1.0.1-py3-none-any.whl"
    },
    {
      "comment_text": "",
      "digests": {
        "md5": "a07820f4527a4b92010163787f94b939",
        "sha256": "983c603a362cb1145bf4a4a0b30683549bb93febf48ecfde7337e6b21bcd6460"
      },
      "downloads": 0,
      "filename": "backend.ai-client-1.0.1.tar.gz",
      "has_sig": false,
      "md5_digest": "a07820f4527a4b92010163787f94b939",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 14869,
      "upload_time": "2017-10-05T16:35:15",
      "url": "https://files.pythonhosted.org/packages/be/84/4fb82585461a21e9739e88ce2a1e6476e60b575e0ec8205aae97cf44ef67/backend.ai-client-1.0.1.tar.gz"
    }
  ]
}