{
  "info": {
    "author": "Gareth Bult",
    "author_email": "oddjobz@linux.co.uk",
    "bugtrack_url": null,
    "classifiers": [
      "Development Status :: 3 - Alpha",
      "Intended Audience :: Developers",
      "License :: OSI Approved :: MIT License",
      "Programming Language :: Python :: 3.6",
      "Topic :: Database :: Database Engines/Servers"
    ],
    "description": "PyNNDB - Python Native NoSQL Database\n=====================================\n\n.. image:: https://travis-ci.org/oddjobz/pynndb.svg?branch=master\n    :target: https://travis-ci.org/oddjobz/pynndb\n\n.. image:: coverage.svg\n    :target: https://codecov.io/gh/oddjobz/pymamba\n\nPyNNDB is the second iteration of PyMamba, the name change reflects a conflict with another project\nof the same name, and a degree of incompatibility between the API in the old and new versions. At\nthis time the core components of the project should be considered relatively stable (beta) and are\nbeing used in production systems. The ORM module is experimental / alpha and has had very limited\ntesting, while the replication module is incomplete / experimental and still needs work.\n\nPyNNDB is a key / value based NoSQL database based on the LMDB storage engine. If you are looking to access your\ndatabase from a low-level language such as C/C++/Java, then you will probably find faster database options. However,\nif you only intend to access your database 'from' Python, then you will probably find PyNNDB a good bit quicker than\nthe more traditional alternatives.\n\nWhat stable features does it have?\n----------------------------------\n* Variable length records, each stored with a Mongo compatible UUID\n* Records are read / written as Python Dict objects\n* Secondary indexes based on a lambda function of the contents of the record\n* Duplicate keys on secondary indexes\n* ACID Transactions handling\n* Multi-thread and multi-process access to bypass GIL performance limitations\n\nWhat Features can I try?\n------------------------\n* A native Object Relational Mapper, typically seen with SQL databases, loosely based on SQLAlchemy\n\nWhat Features are in development?\n---------------------------------\n* High speed multi-node replication\n* Native command line shell\n* ReadTheDocs documentation\n\n-------------------\nSome basic Examples\n-------------------\n\nThis is an example of how to create a new database called my-database, then within that database to create a table called people, then to add some people. (this is all from the Python shell)\n\n.. code-block:: python\n\n    from pymamba import Database\n    db = Database('my-database')\n    people = db.table('people')\n    people.append({'name': 'Fred Bloggs', 'age': 21})\n    people.append({'name': 'Joe Smith', 'age': 22})\n    people.append({'name': 'John Doe', 'age': 19})\n\nNow there are lots of different ways of recovering information from the database, the simplest is just to use find() which can be used to scan through the entire table. As find returns a generator, you can either use it within a for-loop, or use list to recover the results as a single list object.\n\n.. code-block:: python\n\n    >>> for doc in people.find():\n    ...     print(doc)\n    ...\n    {'_id': b'58ed69161839fc5e5a57bc35', 'name': 'Fred Bloggs', 'age': 21}\n    {'_id': b'58ed69211839fc5e5a57bc36', 'name': 'Joe Smith', 'age': 22}\n    {'_id': b'58ed69301839fc5e5a57bc37', 'name': 'John Doe', 'age': 19}\n\nNote that the returned record includes an _id field, this is almost identical to the ObjectId field used by Mongo, except we're returning a simple byte-string rather than an ObjectId class. A nice feature of dealing with data in this form when matched with Python's new 'format' function is the ability to easily format this data like so;\n\n.. code-block:: python\n\n    >>> for doc in people.find():\n    ...     print('Name: {name:20} Age:{age:3}'.format(**doc))\n    ...\n    Name: Fred Bloggs          Age: 21\n    Name: Joe Smith            Age: 22\n    Name: John Doe             Age: 19\n\nOr if we just want a subset of the data, we can use an anonymous function to filter our results; (note that this is a linear / sequential scan with a filter)\n\n.. code-block:: python\n\n    >>> for doc in people.find(expression=lambda doc: doc['age'] > 21):\n    ...     print('Name: {name:20} Age:{age:3}'.format(**doc))\n    ...\n    Name: Joe Smith            Age: 22\n\n--------\nIndexing\n--------\n\nTransparent indexes are a key part of any database system, and I struggled for a while trying to decide which mechanism to use. On the one hand I wanted the functionality of being able to index tables by compound fields and functions, and on the other I just wanted to be able to simply index based on a single clean field. In the end I settled on the following;\n\n.. code-block:: python\n\n    >>> people.ensure('by_name', '{name}')\n    >>> people.ensure('by_age_name', '{age:03}{name}')\n\nIf you're really familiar with Python format strings, you're going to see fairly quickly what's going on here, essentially we're indexing by expression only, but the expression comes from a Python format string when supplied with the record in dict format. So you can't directly use a function to do anything with regards to key generation, but you can do an awful lot with the Python format mini-language. (and adding actual functions is relatively easy for anyone who can think of a must-have use-case)\n\nSo, once we have an index we can search using the index and also find records in order based on the index, so we can re-use find but this time give it an index to use;\n\n.. code-block:: python\n\n    >>> for doc in people.find('by_age_name'):\n    ...     print('Name: {name:20} Age:{age:3}'.format(**doc))\n    ...\n    Name: John Doe             Age: 19\n    Name: Fred Bloggs          Age: 21\n    Name: Joe Smith            Age: 22\n\nOr we can look for specific records;\n\n.. code-block:: python\n\n    >>> people.seek_one('by_name', {'name': 'Joe Smith'})\n    {'_id': b'58ed69211839fc5e5a57bc36', 'name': 'Joe Smith', 'age': 22}\n\nOr we can look for a range of records;\n\n.. code-block:: python\n\n    >>> for doc in people.range('by_name', {'name': 'J'}, {'name': 'K'}):\n    ...     print('Name: {name:20} Age:{age:3}'.format(**doc))\n    ...\n    Name: Joe Smith            Age: 22\n    Name: John Doe             Age: 19\n\n----------------\nUpdating Records\n----------------\n\nWe've already covered adding new records to the database, so that leaves us with updating and deleting records. How about this;\n\n.. code-block:: python\n\n    >>> person = people.seek_one('by_name', {'name': 'Joe Smith'})\n    >>> person['age'] += 1\n    >>> people.save(person)\n    >>> people.seek_one('by_name', {'name': 'Joe Smith'})\n    {'_id': b'58ed69211839fc5e5a57bc36', 'name': 'Joe Smith', 'age': 23}\n\nAnd to delete;\n\n.. code-block:: python\n\n    >>> person = people.seek_one('by_name', {'name': 'Fred Bloggs'})\n    >>> people.delete(person['_id'])\n    >>> for doc in people.find():\n    ...     print('Name: {name:20} Age:{age:3}'.format(**doc))\n    ...\n    Name: Joe Smith            Age: 23\n    Name: John Doe             Age: 19\n    >>>\n\nThere's a lot more to come, but so far it's looking pretty promising. On my workstation a for-loop based on a find yields around 200k results per second, and an append yields around 30k new items per second. This seems to be fairly respectable for a high level language database and seems to be much faster than Mongo when used with either Python or Node.\n\n.. code-block:: text\n\n    ** SINGLE Threaded benchmark **\n    ** Probably better throughput with multiple processes\n\n    * No Indecies\n      -     0: 5000 - Append Speed/sec = 48882\n      -  5000: 5000 - Append Speed/sec = 52778\n      - 10000: 5000 - Append Speed/sec = 52882\n    * Indexed by sid, day, hour\n      -     0: 5000 - Append Speed/sec = 34420\n      -  5000: 5000 - Append Speed/sec = 36096\n      - 10000: 5000 - Append Speed/sec = 35885\n    * Indexed by function\n      -     0: 5000 - Append Speed/sec = 39235\n      -  5000: 5000 - Append Speed/sec = 39822\n      - 10000: 5000 - Append Speed/sec = 41116\n    * Linear scan through most recent index\n      -     0:15000 - Read Speed/sec   = 234615\n\nORM - Object Relational Mapper\n==============================\n\nThe native PyMamba interface is not unlike Mongo in that it treats each record (or document) as a Python dictionary. For databases that involve single / unrelated tables, this is fine and the most efficient means to access data. If however you're mapping relationships between tables, as you might with a traditional SQL database, maintaining linkage tables can be a bit fiddly, and it you're used to something like SQLAlchemy, the standard interface may seem a little raw.\n\nTo this end we have a built-in mechanism for overlaying some structure onto our raw tables to give things a bit of an Alchemy feel. If you're not used to ORM's then this might look a bit like magic, but for SQLAlchemy users, you should feel right at home and hopefully wondering why SQLAlchemy isn't this easy ... ;-)\n\nCurrent Features\n----------------\n\nSo, what we're catering for at the moment;\n\n* Calculated fields\n\n  - Date\n\n  - Age\n\n  - Name\n\n  - UUID\n\n  - Custom\n\n* ManyToMany links between tables\n* Table pretty-printer\n* OneToMany links between tables [TODO]\n* Referential integrity control [TODO]\n* Link attributes [TODO]\n\nWe do have a little work left to do as you can see, but the heart of the ORM is up and running and seem to work fairly well.\n\nThere's a blog posting with more detail here. <`Article on ORM for NoSQL`__>.\n\n.. __: https://gareth.bult.co.uk/2017/09/14/orm_for_nosql/\n\n-----------------\nHow to use Models\n-----------------\n\nThe idea is that we wrap each table up in a dedicated class then we can create additional classes to link the (wrapped) tables together. Here's a very simple example;\n\n.. code-block:: python\n\n    from pymamba import Database\n    from pymamba.models import ManyToMany, Table\n    from pymamba.types import AgeType, DateType\n\n    class UserModel(Table):\n        _calculated = {\n            'age': AgeType('dob'),\n            'birthday': DateType('dob')\n        }\n        _display = [\n            {'name': 'forename', 'width': 20},\n            {'name': 'surname', 'width': 20},\n            {'name': 'birthday', 'width': 15},\n            {'name': 'age', 'width': 3}\n        ]\n\n    db = Database('my_db', {'env': {'map_size': 1024 * 1024 * 10}})\n    user_model = UserModel(table=db.table('users'))\n\nIf you save this to a file (demo.py) you should then be able to do the following;\n\n.. code-block:: python\n\n    >>> from demo import user_model\n    >>> import datetime\n    >>> user_model.add({'forename':'fred','surname':'bloggs','dob':datetime.date(1970,12,1)})\n    >>> user_model.list()\n    +----------------------+----------------------+-----------------+-----+\n    | forename             | surname              | dob             | age |\n    +----------------------+----------------------+-----------------+-----+\n    | fred                 | bloggs               |        28857600 |  46 |\n    +----------------------+----------------------+-----------------+-----+\n\nNote that age isn't a stored field, it's generated on the fly from the 'dob' field hence will dynamically change whenever the dob field is updated. Also, the list function is driven (by default) by the attributes listed in _display.\n\nAs it stands the date of birth isn't terribly readable, so we could add another field to the mix to get around this, in calculated add;\n\n.. code-block:: python\n\n    'birthday': DateType('dob')\n\nAnd change the display section to show birthday rather then dob, then try the above operation again and you should get (don't forget to add DateType to your imports);\n\n.. code-block:: python\n\n    >>> from demo import user_model\n    >>> user_model.list()\n    +----------------------+----------------------+-----------------+-----+\n    | forename             | surname              | birthday        | age |\n    +----------------------+----------------------+-----------------+-----+\n    | fred                 | bloggs               | 01/12/1970      |  46 |\n    +----------------------+----------------------+-----------------+-----+\n\nSo far this all looks relatively trivial, the real value comes in what it's doing under the hood. Let's try to update this data, take a look at the following;\n\n.. code-block:: python\n\n    >>> from demo import user_model\n    >>> user = list(user_model.find())[0]\n    >>> user.surname='Bloggs Updated'\n    >>> user.save()\n    >>> user_model.list()\n    +----------------------+----------------------+-----------------+-----+\n    | forename             | surname              | birthday        | age |\n    +----------------------+----------------------+-----------------+-----+\n    | fred                 | Bloggs Updated       | 01/12/1970      |  46 |\n    +----------------------+----------------------+-----------------+-----+\n\nThe .find() method for a model just returns all records (as an array) so all we're doing here is assigning 'user' to the first record in the table. Each field in the table is then accessible as an attribute (i.e. user.forename, user.surename, user.dob etc) which is a little more natural than updating a dict, then save updates changes in the model back to the actual table. Again relatively trivial, however this is quite neat;\n\n.. code-block:: python\n\n    >>> print(user.age, user.birthday)\n    46 01/12/1970\n\ni.e. when you access the model, you will see attributes that are generated on the fly in additional to any stored data, and (!) if you don't access them they're not generated so there's no overhead in having lots of rarely used calculated fields.\n\n------------------------\nHow to use Relationships\n------------------------\n\nSo this is where things get a little more interesting. In standard NoSQL, typically there is no real concept of table linkage, foreign keys or referential integrity. However, that doesn't mean the concepts are invalid or no longer needed, so, here is NoSQL with inter- table relationships, managed by a built-in ORM (!)\n\nFirst, let's start by defining a second table, we're going to make it really easy by just having an address table, then working on the premise that users can have multiple addresses, and that a number of users can live at each address.\n\n.. code-block:: python\n\n    class AddressModel(Table):\n\n        _display = [\n            {'name': 'address', 'width': 30},\n            {'name': 'postcode', 'width': 15}\n        ]\n\nAnd we will create a relationship between the UserModel and the AddressModel by adding this to our previous code;\n\n.. code-block:: python\n\n    address_model = AddressModel(table=db.table('addresses'))\n    links = ManyToMany(db, user_model, address_model)\n\nSo, starting up as before we can do this;\n\n.. code-block:: python\n\n    from demo import user_model, address_model, UserModel\n    import datetime\n    >>> user = user_model.add({'forename':'john','surname':'smith','dob':datetime.date(1971,12,1)})\n    >>> user.addresses.append({'address': 'address1', 'postcode': 'postcode1'})\n    >>> user.addresses.append({'address': 'address2', 'postcode': 'postcode2'})\n    >>> user.save()\n    >>> user_model.list()\n    +----------------------+----------------------+-----------------+-----+\n    | forename             | surname              | birthday        | age |\n    +----------------------+----------------------+-----------------+-----+\n    | john                 | smith                | 01/12/1971      |  45 |\n    +----------------------+----------------------+-----------------+-----+\n    >>> address_model.list()\n    +--------------------------------+-----------------+\n    | address                        | postcode        |\n    +--------------------------------+-----------------+\n    | address1                       | postcode1       |\n    | address2                       | postcode2       |\n    +--------------------------------+-----------------+\n\nSo there are some interesting things going on here, we have created a new instance of UserModel, then added two new addresses by appending to it's address property. Now the address property is a virtual field created by the \"ManyToMany\" link and not only is it populated from the address table, but it can also be used to append, update and delete entries in the address table. On further inspection we see;\n\n.. code-block:: python\n\n    >>> user\n    {'surname': 'smith', '_id': b'59b6860b1839fc4ee8c00596', 'forename': 'john', 'dob': datetime.date(1971, 12, 1)}\n    >>> user.addresses\n    [{'address': 'address1', 'postcode': 'postcode1', '_id': b'59b6860b1839fc4ee8c00597'}, {'address': 'address2', 'postcode': 'postcode2', '_id': b'59b6860b1839fc4ee8c00599'}]\n    >>> type(user.addresses[0])\n    <class 'pymamba.models.BaseModel'>\n\nAgain, virtual and calculated fields are only evaluated when reading through the users table, the cost of reading associated tables is only incurred if the linked attributes (addresses in this case) are accessed. Note that the addresses field is a list, but of type BaseModel, rather than of a raw dict.\n\n----------------------\nUpdating linked tables\n----------------------\n\nIn a similar fashion, we can do updates to the linked table;\n\n.. code-block:: python\n\n    >>> user = list(user_model.find())[0]\n    >>> user\n    {'surname': 'smith', '_id': b'59b6860b1839fc4ee8c00596', 'forename': 'john', 'dob': 60393600}\n    >>> user.addresses[1]\n    {'address': 'address2', 'postcode': 'postcode2', '_id': b'59b6860b1839fc4ee8c00599'}\n    >>> user.addresses[1].postcode = 'A new postcode'\n    >>> user.save()\n    >>> address_model.list()\n    +--------------------------------+-----------------+\n    | address                        | postcode        |\n    +--------------------------------+-----------------+\n    | address1                       | postcode1       |\n    | address2                       | A new postcode  |\n    +--------------------------------+-----------------+\n\n---------------------------------\nDeleting entries in linked tables\n---------------------------------\n\nAnd of course, we can delete in the same way, but be aware that this will only sever the link rather than deleting the address, so future references to addresses in this example will only show the user linked to one address, but a listing of the address table will show both addresses. Deleting target objects with a zero reference count will be an option when the referential integrity code is added.\n\n.. code-block:: python\n\n    >>> del user.addresses[0]\n    >>> user.save()\n    >>> user = list(user_model.find())[0]\n    >>> user.addresses\n    [{'address': 'address2', 'postcode': 'A new postcode', '_id': b'59b6860b1839fc4ee8c00599'}]\n\nIf we wanted to re-instate the relationship in this instance we could do;\n\n.. code-block:: python\n\n    >>> address = list(address_model.find())[0]\n    >>> address\n    {'_id': b'59b800e41839fc41593c9894', 'address': 'address1', 'postcode': 'postcode1'}\n    >>> user.addresses.append(address)\n    >>> user.save()\n    >>> user = list(user_model.find())[0]\n    >>> user.addresses\n    [{'_id': b'59b800e41839fc41593c9896', 'address': 'address2', 'postcode': 'A new postcode'}, {'_id': b'59b800e41839fc41593c9894', 'address': 'address1', 'postcode': 'postcode1'}]\n\nThe funny looking \"user = list(...)\" function is only being used to force a re-read on the database following an update. The user variable will still be instantiated and in theory a re-read should make no difference to it's value, but for testing, it's always good to be sure it's actually storing what you think it is.",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": 0,
      "last_month": 0,
      "last_week": 0
    },
    "home_page": "https://github.com/oddjobz/pynndb",
    "keywords": "pynndb,database,LMDB,python,ORM",
    "license": "MIT",
    "maintainer": "",
    "maintainer_email": "",
    "name": "pynndb",
    "platform": "",
    "project_url": "https://pypi.org/project/pynndb/",
    "release_url": "https://pypi.org/project/pynndb/0.9.2/",
    "requires_dist": [],
    "requires_python": "",
    "summary": "Database library for Python based on LMDB storage engine",
    "version": "0.9.2"
  },
  "releases": {
    "0.9.1": [
      {
        "comment_text": "",
        "digests": {
          "md5": "ce04f674bd99477e5e30136363197b9b",
          "sha256": "b0c08c3d31214cbd61b58e3259cfe0928af4f3a1a90fe43c41db61d9f905be55"
        },
        "downloads": -1,
        "filename": "pynndb-0.9.1.tar.gz",
        "has_sig": false,
        "md5_digest": "ce04f674bd99477e5e30136363197b9b",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 26939,
        "upload_time": "2018-01-11T16:14:14",
        "url": "https://files.pythonhosted.org/packages/00/f9/29fe632946e6f79cef2c45026713ac11993fbc960fa597937606bdab1e91/pynndb-0.9.1.tar.gz"
      }
    ],
    "0.9.2": [
      {
        "comment_text": "",
        "digests": {
          "md5": "677886fbd9e4ba976d86553f6e817b9f",
          "sha256": "18546f6e71242fc8704d6d022a3783ae37bfc96e7fb35e24964ce6b370fde701"
        },
        "downloads": -1,
        "filename": "pynndb-0.9.2.tar.gz",
        "has_sig": false,
        "md5_digest": "677886fbd9e4ba976d86553f6e817b9f",
        "packagetype": "sdist",
        "python_version": "source",
        "size": 26959,
        "upload_time": "2018-01-11T18:51:35",
        "url": "https://files.pythonhosted.org/packages/00/1b/58ff31b18901033cd8b170ca6d135a4cf3072d3ccf5bff36d9584c374919/pynndb-0.9.2.tar.gz"
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "md5": "677886fbd9e4ba976d86553f6e817b9f",
        "sha256": "18546f6e71242fc8704d6d022a3783ae37bfc96e7fb35e24964ce6b370fde701"
      },
      "downloads": -1,
      "filename": "pynndb-0.9.2.tar.gz",
      "has_sig": false,
      "md5_digest": "677886fbd9e4ba976d86553f6e817b9f",
      "packagetype": "sdist",
      "python_version": "source",
      "size": 26959,
      "upload_time": "2018-01-11T18:51:35",
      "url": "https://files.pythonhosted.org/packages/00/1b/58ff31b18901033cd8b170ca6d135a4cf3072d3ccf5bff36d9584c374919/pynndb-0.9.2.tar.gz"
    }
  ]
}